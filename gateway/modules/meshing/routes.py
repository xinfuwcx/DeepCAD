import asyncio
import json
import random
from fastapi import APIRouter, BackgroundTasks, WebSocket, WebSocketDisconnect, HTTPException
from pydantic import BaseModel
import gmsh
import os
import time
import tempfile
from typing import Dict, Any, Optional, List
from uuid import uuid4

from ..websockets.connection_manager import manager
from ..visualization.mesh_streaming import mesh_streaming_service
from ..visualization.pyvista_web_bridge import get_pyvista_bridge
from .quality_analyzer import MeshQualityAnalyzer, analyze_mesh_quality, export_quality_report
from .schemas import (
    PhysicalGroupDefinition, PhysicalGroupInfo, CreatePhysicalGroupRequest,
    UpdatePhysicalGroupRequest, PhysicalGroupResponse, PhysicalGroupListResponse,
    EntityInfo, GeometryEntitiesResponse, PhysicalGroupType, MaterialType,
    AdvancedMeshConfiguration, ConfigurableMeshRequest, ConfigurableMeshResponse,
    MeshGenerationStatus, AlgorithmPreset, AlgorithmPresetsResponse,
    MeshAlgorithmType, Element2DType, Element3DType, MeshQualityMode,
    RefinementStrategy, MeshSmoothingAlgorithm, SizeFieldConfiguration,
    BoundaryLayerConfiguration, ParallelConfiguration
)


router = APIRouter(prefix="/meshing")

# å…¨å±€è´¨é‡åˆ†æå™¨å®ä¾‹
quality_analyzer = MeshQualityAnalyzer()

# å­˜å‚¨åˆ†æç»“æœçš„å­—å…¸
quality_analysis_cache: Dict[str, Any] = {}


def create_fragment_volume(fragment_data: Dict[str, Any]) -> Optional[int]:
    """æ ¹æ®ç‰‡æ®µæ•°æ®åˆ›å»ºGMSHå‡ ä½•ä½“ï¼Œä¼˜åŒ–é‡å é—®é¢˜"""
    try:
        fragment_type = fragment_data.get('fragment_type', 'excavation')
        geometry = fragment_data.get('geometry', {})
        
        if geometry.get('type') == 'box':
            # ç«‹æ–¹ä½“å¼€æŒ–åŒºåŸŸ
            geom = geometry.get('geometry', {})
            box_tag = gmsh.model.occ.addBox(
                geom.get('x', 0), geom.get('y', 0), geom.get('z', 0),
                geom.get('width', 1), geom.get('length', 1), geom.get('depth', 1)
            )
            # åŒæ­¥å‡ ä½•ä»¥é¿å…é‡å 
            gmsh.model.occ.synchronize()
            return box_tag
            
        elif geometry.get('type') == 'cylinder':
            # åœ†æŸ±å½¢ï¼ˆæ¡©åŸºç­‰ï¼‰- ä¼˜åŒ–é‡å é—®é¢˜
            geom = geometry.get('geometry', {})
            
            # è®¾ç½®æ›´ä¸¥æ ¼çš„å‡ ä½•å®¹å·®
            original_tolerance = gmsh.option.getNumber("Geometry.Tolerance")
            gmsh.option.setNumber("Geometry.Tolerance", 1e-8)
            
            cyl_tag = gmsh.model.occ.addCylinder(
                geom.get('x', 0), geom.get('y', 0), geom.get('center_z', 0),
                0, 0, geom.get('height', 1), geom.get('radius', 0.5)
            )
            
            # ç«‹å³åŒæ­¥å‡ ä½•
            gmsh.model.occ.synchronize()
            
            # æ¢å¤åŸå§‹å®¹å·®
            gmsh.option.setNumber("Geometry.Tolerance", original_tolerance)
            
            return cyl_tag
        else:
            print(f"Unsupported fragment geometry type: {geometry.get('type')}")
            return None
            
    except Exception as e:
        print(f"Error creating fragment volume: {e}")
        return None


def create_physical_groups_from_fragments(fragments: List[Dict], fragment_result: Any):
    """ä»Fragmentç»“æœåˆ›å»ºç‰©ç†ç¾¤ç»„"""
    try:
        # è·å–æ‰€æœ‰ä½“ç§¯
        volumes = gmsh.model.getEntities(3)
        
        for i, (dim, tag) in enumerate(volumes):
            # æ ¹æ®ä½“ç§¯ä½ç½®å’Œå¤§å°åˆ¤æ–­å±äºå“ªä¸ªFragment
            bbox = gmsh.model.getBoundingBox(dim, tag)
            center = [(bbox[0] + bbox[3])/2, (bbox[1] + bbox[4])/2, (bbox[2] + bbox[5])/2]
            volume = (bbox[3] - bbox[0]) * (bbox[4] - bbox[1]) * (bbox[5] - bbox[2])
            
            # ç®€åŒ–çš„åˆ†ç»„é€»è¾‘
            if volume < 50:  # å°ä½“ç§¯è®¤ä¸ºæ˜¯å¼€æŒ–æˆ–ç»“æ„
                group_name = f"excavation_{i}"
                gmsh.model.addPhysicalGroup(3, [tag], tag + 1000)
                gmsh.model.setPhysicalName(3, tag + 1000, group_name)
            else:  # å¤§ä½“ç§¯è®¤ä¸ºæ˜¯åœŸä½“
                group_name = f"soil_domain_{i}"
                gmsh.model.addPhysicalGroup(3, [tag], tag + 2000)  
                gmsh.model.setPhysicalName(3, tag + 2000, group_name)
                
        print(f"Created physical groups for {len(volumes)} volumes")
        
    except Exception as e:
        print(f"Error creating physical groups: {e}")


class MeshGenerationRequest(BaseModel):
    boundingBoxMin: list[float]
    boundingBoxMax: list[float]
    meshSize: float
    clientId: str
    # Fragmenté…ç½® - æ–°å¢
    enable_fragment: bool = False
    domain_fragments: Optional[List[Dict[str, Any]]] = None
    global_mesh_settings: Optional[Dict[str, Any]] = None


class MeshGenerationResponse(BaseModel):
    message: str
    url: str


async def generate_mesh_task(req: MeshGenerationRequest):
    """
    Background mesh generation using native gmsh API.
    Improved performance and better geometry handling compared to pygmsh.
    """
    client_id = req.clientId
    
    start_payload = {"status": "starting", "progress": 0, "message": "Starting mesh generation..."}
    await manager.send_personal_message(json.dumps(start_payload), client_id)

    # Initialize gmsh
    gmsh.initialize()
    
    try:
        box_min = req.boundingBoxMin
        box_max = req.boundingBoxMax
        box_dims = [box_max[0] - box_min[0], box_max[1] - box_min[1], box_max[2] - box_min[2]]

        # Create a new model
        model_name = f"mesh_model_{int(time.time())}"
        gmsh.model.add(model_name)

        geom_payload = {"status": "processing", "progress": 25, "message": "Creating geometry with gmsh OCC..."}
        await manager.send_personal_message(json.dumps(geom_payload), client_id)
        await asyncio.sleep(1)

        # Create box using native gmsh OCC API
        box_tag = gmsh.model.occ.addBox(
            box_min[0], box_min[1], box_min[2],
            box_dims[0], box_dims[1], box_dims[2]
        )
        
        # ğŸ†• Fragmentå¤„ç† - å¦‚æœå¯ç”¨FragmentåŠŸèƒ½
        if req.enable_fragment and req.domain_fragments:
            fragment_payload = {"status": "processing", "progress": 35, "message": "Processing domain fragments..."}
            await manager.send_personal_message(json.dumps(fragment_payload), client_id)
            
            # å¤„ç†åŸŸç‰‡æ®µåˆ‡å‰²
            fragment_volumes = []
            for fragment in req.domain_fragments:
                fragment_volume = create_fragment_volume(fragment)
                if fragment_volume:
                    fragment_volumes.append((3, fragment_volume))
            
            if fragment_volumes:
                # ğŸ”§ ä¼˜åŒ–Fragmentæ“ä½œ - é¿å…é‡å é¢ç‰‡
                try:
                    # è®¾ç½®æ›´é«˜ç²¾åº¦çš„å‡ ä½•å¤„ç†å‚æ•°
                    gmsh.option.setNumber("Geometry.Tolerance", 1e-10)
                    gmsh.option.setNumber("Geometry.ToleranceBoolean", 1e-10)
                    
                    # åœ¨Fragmentæ“ä½œå‰åŒæ­¥æ‰€æœ‰å‡ ä½•
                    gmsh.model.occ.synchronize()
                    
                    # æ‰§è¡ŒFragmentæ“ä½œ
                    object_dimtags = [(3, box_tag)]
                    tool_dimtags = fragment_volumes
                    
                    # ä½¿ç”¨æ›´ä¸¥æ ¼çš„Fragmentæ“ä½œ
                    fragment_result = gmsh.model.occ.fragment(
                        object_dimtags, tool_dimtags, 
                        removeObject=True, removeTool=True
                    )
                    
                    # Fragmentåç«‹å³åŒæ­¥
                    gmsh.model.occ.synchronize()
                    
                    # åˆ›å»ºç‰©ç†ç¾¤ç»„
                    create_physical_groups_from_fragments(req.domain_fragments, fragment_result)
                    
                except Exception as fragment_error:
                    print(f"Fragment operation failed: {fragment_error}")
                    # Fragmentå¤±è´¥æ—¶ç»§ç»­ä½¿ç”¨åŸå§‹å‡ ä½•
                    error_payload = {"status": "warning", "progress": 40, 
                                   "message": f"Fragmentåˆ‡å‰²å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–å‡ ä½•: {str(fragment_error)}"}
                    await manager.send_personal_message(json.dumps(error_payload), client_id)
        
        # Synchronize OCC geometry
        gmsh.model.occ.synchronize()
        
        # ğŸ”§ 3å·å·¥ç¨‹åŒ–ç½‘æ ¼å°ºå¯¸ç­–ç•¥ï¼ˆ1å·æ¶æ„å¸ˆç¡®è®¤ï¼‰
        # æ¥æ”¶2å·å‡ ä½•å»ºè®®ï¼Œç»3å·å·¥ç¨‹éªŒè¯åç¡®å®šæœ€ç»ˆå°ºå¯¸
        if hasattr(req, 'geometryGuidance'):
            # 2å·æä¾›çš„å»ºè®®ä½œä¸ºåˆå§‹å€¼
            geometry_suggested_size = getattr(req.geometryGuidance, 'suggestedElementSize', req.meshSize)
            
            # 3å·å·¥ç¨‹éªŒè¯å’Œä¼˜åŒ–
            from .geometry_mesh_feedback import geometry_mesh_feedback_system
            # ç®€åŒ–çš„å·¥ç¨‹éªŒè¯ï¼ˆå®é™…ä¼šæ›´å¤æ‚ï¼‰
            engineering_validated_size = min(geometry_suggested_size, req.meshSize)
            
            gmsh.option.setNumber("Mesh.MeshSizeMin", engineering_validated_size / 2)
            gmsh.option.setNumber("Mesh.MeshSizeMax", engineering_validated_size)
        else:
            # é»˜è®¤ä½¿ç”¨3å·çš„å·¥ç¨‹ç»éªŒå€¼
            gmsh.option.setNumber("Mesh.MeshSizeMin", req.meshSize / 2)
            gmsh.option.setNumber("Mesh.MeshSizeMax", req.meshSize)
        
        # æ ¹æ®æ˜¯å¦ä½¿ç”¨Fragmenté€‰æ‹©åˆé€‚çš„ç½‘æ ¼ç®—æ³•
        if req.enable_fragment and req.domain_fragments:
            # Fragmentå‡ ä½•ä½¿ç”¨æ›´robustçš„ç®—æ³•
            gmsh.option.setNumber("Mesh.Algorithm", 1)  # MeshAdaptç®—æ³•ï¼Œæ›´é€‚åˆå¤æ‚å‡ ä½•
            gmsh.option.setNumber("Mesh.Algorithm3D", 4)  # Frontalç®—æ³•ï¼Œå¤„ç†å¤æ‚3Då‡ ä½•
            gmsh.option.setNumber("Mesh.OptimizeNetgen", 1)  # å¯ç”¨Netgenä¼˜åŒ–
        else:
            # ç®€å•å‡ ä½•ä½¿ç”¨é«˜æ•ˆç®—æ³•
            gmsh.option.setNumber("Mesh.Algorithm", 6)  # Frontal-Delaunay
            gmsh.option.setNumber("Mesh.Algorithm3D", 1)  # Delaunayç®—æ³•
        
        mesh_payload = {"status": "processing", "progress": 50, "message": "Generating 3D mesh..."}
        await manager.send_personal_message(json.dumps(mesh_payload), client_id)
        await asyncio.sleep(1)
        
        # Generate 3D mesh
        gmsh.model.mesh.generate(3)
        
        # ğŸ”§ ç½‘æ ¼è´¨é‡è‡ªåŠ¨ä¼˜åŒ–
        quality_payload = {"status": "processing", "progress": 65, "message": "åˆ†æç½‘æ ¼è´¨é‡..."}
        await manager.send_personal_message(json.dumps(quality_payload), client_id)
        await asyncio.sleep(0.5)
        
        # ä¿å­˜ä¸´æ—¶ç½‘æ ¼æ–‡ä»¶ç”¨äºè´¨é‡åˆ†æ
        temp_mesh_file = os.path.join(temp_dir, f"temp_mesh_{client_id}.msh")
        gmsh.write(temp_mesh_file)
        
        # å¯¼å…¥è´¨é‡åˆ†æå·¥å…·
        try:
            from .quality_analyzer import analyze_mesh_quality, optimize_mesh_quality
            
            # åˆ†æè´¨é‡
            quality_report = analyze_mesh_quality(temp_mesh_file)
            
            # å¦‚æœè´¨é‡ä¸ä½³ï¼Œè‡ªåŠ¨ä¼˜åŒ–
            if quality_report.overall_score < 0.7:
                optimize_payload = {"status": "processing", "progress": 70, 
                                 "message": f"ç½‘æ ¼è´¨é‡è¯„åˆ†{quality_report.overall_score:.2f}ï¼Œæ­£åœ¨è‡ªåŠ¨ä¼˜åŒ–..."}
                await manager.send_personal_message(json.dumps(optimize_payload), client_id)
                
                optimization_result = optimize_mesh_quality(temp_mesh_file)
                
                if optimization_result.get('status') == 'success':
                    # åŠ è½½ä¼˜åŒ–åçš„ç½‘æ ¼
                    gmsh.clear()
                    gmsh.open(optimization_result['optimized_file'])
                    
                    optimized_payload = {"status": "processing", "progress": 75, 
                                       "message": f"ç½‘æ ¼ä¼˜åŒ–å®Œæˆï¼Œåº”ç”¨äº†{optimization_result['improvements']}é¡¹æ”¹è¿›"}
                    await manager.send_personal_message(json.dumps(optimized_payload), client_id)
                
        except ImportError:
            logger.warning("ç½‘æ ¼è´¨é‡åˆ†ææ¨¡å—ä¸å¯ç”¨ï¼Œè·³è¿‡è‡ªåŠ¨ä¼˜åŒ–")
        
        save_payload = {"status": "processing", "progress": 75, "message": "Saving mesh to file..."}
        await manager.send_personal_message(json.dumps(save_payload), client_id)
        await asyncio.sleep(1)

        # Create output directory
        output_dir = "./static_content/meshes"
        os.makedirs(output_dir, exist_ok=True)
        
        timestamp = int(time.time())
        
        # Save mesh in VTK format for PyVista to read
        vtk_filename = f"mesh_{timestamp}.vtk"
        vtk_path = os.path.join(output_dir, vtk_filename)
        gmsh.write(vtk_path)
        
        # Also save native gmsh format for advanced analysis
        msh_filename = f"mesh_{timestamp}.msh"
        msh_path = os.path.join(output_dir, msh_filename)
        gmsh.write(msh_path)
        
        # Load with PyVista Bridge for additional processing if needed
        bridge = get_pyvista_bridge()
        pv_mesh = bridge.load_mesh(vtk_path)
        
        # Get mesh statistics using bridge
        if pv_mesh is not None:
            stats = bridge.get_mesh_info(pv_mesh)
        else:
            stats = {"error": "Could not load mesh for statistics"}
        
        complete_payload = {
            "status": "completed", 
            "progress": 100, 
            "message": "Mesh generation complete with native gmsh.", 
            "url": f"/static/meshes/{vtk_filename}",
            "mesh_url": f"/static/meshes/{msh_filename}",
            "stats": stats
        }
        await manager.send_personal_message(json.dumps(complete_payload), client_id)

    except Exception as e:
        error_message = f"An error occurred during mesh generation: {e}"
        error_payload = {"status": "error", "message": error_message}
        await manager.send_personal_message(json.dumps(error_payload), client_id)
        print(f"Mesh generation error: {error_message}")
        
    finally:
        # Always cleanup gmsh
        gmsh.finalize()


@router.post("/generate")
async def generate_mesh_endpoint(req: MeshGenerationRequest, background_tasks: BackgroundTasks):
    """
    Accepts mesh generation parameters and starts a background task.
    Immediately returns a confirmation response.
    Progress is sent via WebSocket.
    """
    background_tasks.add_task(generate_mesh_task, req)
    return {"message": "Mesh generation started in background.", "clientId": req.clientId}


# === Moving-Mesh API Endpoints ===

class MovingMeshConfig(BaseModel):
    """åŠ¨ç½‘æ ¼é…ç½®"""
    strategy: str = "laplacian"  # laplacian, ale_formulation, remesh_adaptive
    driving_source: str = "excavation"  # excavation, support_displacement, soil_settlement, combined
    quality_threshold: float = 0.3
    real_time_rendering: bool = True
    update_frequency: str = "every_step"  # every_step, every_5_steps, every_10_steps, on_demand


class MovingMeshRequest(BaseModel):
    """å¯åŠ¨åŠ¨ç½‘æ ¼åˆ†æè¯·æ±‚"""
    mesh_id: str
    config: MovingMeshConfig
    client_id: str


@router.post("/moving-mesh/start")
async def start_moving_mesh(req: MovingMeshRequest, background_tasks: BackgroundTasks):
    """å¯åŠ¨åŠ¨ç½‘æ ¼åˆ†æ"""
    try:
        # éªŒè¯mesh_id
        if not req.mesh_id:
            raise HTTPException(status_code=400, detail="mesh_id is required")
        
        # å¯åŠ¨åå°ä»»åŠ¡
        background_tasks.add_task(moving_mesh_analysis_task, req)
        
        return {
            "message": "Moving-Mesh analysis started",
            "mesh_id": req.mesh_id,
            "client_id": req.client_id,
            "config": req.config.dict()
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to start moving-mesh: {str(e)}")


@router.websocket("/moving-mesh/ws/{mesh_id}")
async def moving_mesh_websocket(websocket: WebSocket, mesh_id: str):
    """åŠ¨ç½‘æ ¼WebSocketè¿æ¥"""
    connection_id = str(uuid4())
    
    try:
        # å»ºç«‹è¿æ¥
        await mesh_streaming_service.connect(websocket, connection_id)
        
        # è®¢é˜…ç½‘æ ¼æ›´æ–°
        await mesh_streaming_service.subscribe_mesh(connection_id, mesh_id)
        
        # ä¿æŒè¿æ¥
        while True:
            try:
                # ç­‰å¾…å®¢æˆ·ç«¯æ¶ˆæ¯
                data = await websocket.receive_text()
                message = json.loads(data)
                
                # å¤„ç†å®¢æˆ·ç«¯æ¶ˆæ¯
                if message.get("type") == "subscribe":
                    new_mesh_id = message.get("mesh_id")
                    if new_mesh_id:
                        await mesh_streaming_service.subscribe_mesh(connection_id, new_mesh_id)
                
                elif message.get("type") == "unsubscribe":
                    old_mesh_id = message.get("mesh_id")
                    if old_mesh_id:
                        await mesh_streaming_service.unsubscribe_mesh(connection_id, old_mesh_id)
                        
            except WebSocketDisconnect:
                break
            except Exception as e:
                print(f"WebSocket error: {e}")
                break
                
    finally:
        await mesh_streaming_service.disconnect(connection_id)


@router.get("/moving-mesh/status/{mesh_id}")
async def get_moving_mesh_status(mesh_id: str):
    """è·å–åŠ¨ç½‘æ ¼çŠ¶æ€"""
    # è¿™é‡Œå¯ä»¥é›†æˆçœŸå®çš„çŠ¶æ€æŸ¥è¯¢é€»è¾‘
    return {
        "mesh_id": mesh_id,
        "status": "active",  # active, paused, completed, error
        "progress": 75.0,
        "current_stage": "excavation_stage_2",
        "nodes_updated": 1250,
        "last_update": time.time()
    }


@router.post("/moving-mesh/pause/{mesh_id}")
async def pause_moving_mesh(mesh_id: str):
    """æš‚åœåŠ¨ç½‘æ ¼åˆ†æ"""
    # å‘é€æš‚åœçŠ¶æ€
    await mesh_streaming_service.send_status_update(mesh_id, "paused", "Analysis paused by user")
    
    return {
        "message": f"Moving-Mesh analysis paused for mesh {mesh_id}",
        "mesh_id": mesh_id
    }


@router.post("/moving-mesh/resume/{mesh_id}")
async def resume_moving_mesh(mesh_id: str):
    """æ¢å¤åŠ¨ç½‘æ ¼åˆ†æ"""
    # å‘é€æ¢å¤çŠ¶æ€
    await mesh_streaming_service.send_status_update(mesh_id, "resumed", "Analysis resumed")
    
    return {
        "message": f"Moving-Mesh analysis resumed for mesh {mesh_id}",
        "mesh_id": mesh_id
    }


@router.delete("/moving-mesh/stop/{mesh_id}")
async def stop_moving_mesh(mesh_id: str):
    """åœæ­¢åŠ¨ç½‘æ ¼åˆ†æ"""
    # å‘é€åœæ­¢çŠ¶æ€
    await mesh_streaming_service.send_status_update(mesh_id, "stopped", "Analysis stopped by user")
    
    return {
        "message": f"Moving-Mesh analysis stopped for mesh {mesh_id}",
        "mesh_id": mesh_id
    }


@router.get("/moving-mesh/connections")
async def get_connection_stats():
    """è·å–WebSocketè¿æ¥ç»Ÿè®¡"""
    return mesh_streaming_service.get_connection_stats()


async def moving_mesh_analysis_task(req: MovingMeshRequest):
    """åŠ¨ç½‘æ ¼åˆ†æåå°ä»»åŠ¡"""
    mesh_id = req.mesh_id
    config = req.config
    client_id = req.client_id
    
    try:
        # å‘é€å¼€å§‹çŠ¶æ€
        await mesh_streaming_service.send_status_update(
            mesh_id, "started", "Moving-Mesh analysis initialized"
        )
        
        # æ¨¡æ‹Ÿåˆ†æè¿‡ç¨‹
        stages = [
            ("initialization", "åˆå§‹åŒ–åŠ¨ç½‘æ ¼è®¾ç½®"),
            ("mesh_setup", "è®¾ç½®ç½‘æ ¼ç§»åŠ¨ç­–ç•¥"),
            ("excavation_stage_1", "ç¬¬ä¸€é˜¶æ®µå¼€æŒ–"),
            ("mesh_update_1", "ç½‘æ ¼æ›´æ–° - é˜¶æ®µ1"),
            ("excavation_stage_2", "ç¬¬äºŒé˜¶æ®µå¼€æŒ–"),
            ("mesh_update_2", "ç½‘æ ¼æ›´æ–° - é˜¶æ®µ2"),
            ("excavation_stage_3", "ç¬¬ä¸‰é˜¶æ®µå¼€æŒ–"),
            ("mesh_update_3", "ç½‘æ ¼æ›´æ–° - é˜¶æ®µ3"),
            ("finalization", "åˆ†æå®Œæˆ")
        ]
        
        for i, (stage, stage_desc) in enumerate(stages):
            progress = (i + 1) / len(stages) * 100
            
            # å‘é€è¿›åº¦æ›´æ–°
            await mesh_streaming_service.send_progress_update(
                mesh_id, progress, stage_desc
            )
            
            # æ¨¡æ‹Ÿè®¡ç®—æ—¶é—´
            await asyncio.sleep(2)
            
            # æ¨¡æ‹Ÿç½‘æ ¼èŠ‚ç‚¹æ›´æ–°
            if "mesh_update" in stage:
                node_updates = []
                for node_id in range(100):  # æ¨¡æ‹Ÿ100ä¸ªèŠ‚ç‚¹æ›´æ–°
                    node_updates.append({
                        "id": node_id,
                        "x": 10.0 + i * 0.1,  # æ¨¡æ‹Ÿä½ç§»
                        "y": 5.0,
                        "z": -i * 0.5  # æ¨¡æ‹Ÿä¸‹æ²‰
                    })
                
                # æµå¼ä¼ è¾“ç½‘æ ¼æ›´æ–°
                await mesh_streaming_service.stream_mesh_update(
                    mesh_id, node_updates, incremental=True
                )
        
        # å‘é€å®ŒæˆçŠ¶æ€
        await mesh_streaming_service.send_status_update(
            mesh_id, "completed", "Moving-Mesh analysis completed successfully"
        )
        
        # é€šçŸ¥åŸå§‹å®¢æˆ·ç«¯
        completion_message = {
            "status": "completed",
            "progress": 100,
            "message": f"Moving-Mesh analysis completed for {mesh_id}",
            "mesh_id": mesh_id
        }
        await manager.send_personal_message(json.dumps(completion_message), client_id)
        
    except Exception as e:
        error_message = f"Moving-Mesh analysis failed: {str(e)}"
        await mesh_streaming_service.send_status_update(mesh_id, "error", error_message)
        
        # é€šçŸ¥åŸå§‹å®¢æˆ·ç«¯
        error_payload = {
            "status": "error", 
            "message": error_message,
            "mesh_id": mesh_id
        }
        await manager.send_personal_message(json.dumps(error_payload), client_id)


# === Gmsh Physical Group Management API ===

class PhysicalGroupManager:
    """Gmsh physical group management utilities"""
    
    @staticmethod
    def _dimension_from_type(group_type: PhysicalGroupType) -> int:
        """Convert PhysicalGroupType to Gmsh dimension"""
        type_to_dim = {
            PhysicalGroupType.POINT: 0,
            PhysicalGroupType.CURVE: 1,
            PhysicalGroupType.SURFACE: 2,
            PhysicalGroupType.VOLUME: 3
        }
        return type_to_dim[group_type]
    
    @staticmethod
    def _type_from_dimension(dimension: int) -> PhysicalGroupType:
        """Convert Gmsh dimension to PhysicalGroupType"""
        dim_to_type = {
            0: PhysicalGroupType.POINT,
            1: PhysicalGroupType.CURVE,
            2: PhysicalGroupType.SURFACE,
            3: PhysicalGroupType.VOLUME
        }
        return dim_to_type.get(dimension, PhysicalGroupType.VOLUME)
    
    @staticmethod
    def create_physical_group(definition: PhysicalGroupDefinition, entity_tags: List[int], 
                            auto_tag: bool = True, custom_tag: Optional[int] = None) -> PhysicalGroupInfo:
        """Create a new physical group in Gmsh"""
        dimension = PhysicalGroupManager._dimension_from_type(definition.group_type)
        
        # Determine tag
        if auto_tag:
            # Get existing physical group tags for this dimension
            existing_tags = [tag for tag, _ in gmsh.model.getPhysicalGroups(dimension)]
            tag = max(existing_tags, default=0) + 1
        else:
            if custom_tag is None:
                raise ValueError("custom_tag must be provided when auto_tag is False")
            tag = custom_tag
            
            # Check if tag already exists
            existing_tags = [t for t, _ in gmsh.model.getPhysicalGroups(dimension)]
            if tag in existing_tags:
                raise ValueError(f"Physical group tag {tag} already exists for dimension {dimension}")
        
        # Create physical group
        gmsh.model.addPhysicalGroup(dimension, entity_tags, tag)
        gmsh.model.setPhysicalName(dimension, tag, definition.name)
        
        return PhysicalGroupInfo(
            tag=tag,
            name=definition.name,
            dimension=dimension,
            entity_count=len(entity_tags),
            material_type=definition.material_type,
            properties=definition.properties
        )
    
    @staticmethod
    def get_physical_groups() -> List[PhysicalGroupInfo]:
        """Get all physical groups from current Gmsh model"""
        groups = []
        
        for dim in range(4):  # 0D to 3D
            physical_groups = gmsh.model.getPhysicalGroups(dim)
            for tag, entities in physical_groups:
                try:
                    name = gmsh.model.getPhysicalName(dim, tag)
                except:
                    name = f"PhysicalGroup_{dim}D_{tag}"
                
                groups.append(PhysicalGroupInfo(
                    tag=tag,
                    name=name,
                    dimension=dim,
                    entity_count=len(entities),
                    material_type=None,  # Would need to be stored separately
                    properties={}
                ))
        
        return groups
    
    @staticmethod
    def update_physical_group(tag: int, dimension: int, update_data: UpdatePhysicalGroupRequest) -> PhysicalGroupInfo:
        """Update an existing physical group"""
        # Check if group exists
        existing_groups = dict(gmsh.model.getPhysicalGroups(dimension))
        if tag not in existing_groups:
            raise ValueError(f"Physical group with tag {tag} not found in dimension {dimension}")
        
        # Update name if provided
        if update_data.name:
            gmsh.model.setPhysicalName(dimension, tag, update_data.name)
        
        # Update entity tags if provided
        if update_data.entity_tags is not None:
            # Remove old group and create new one with same tag
            gmsh.model.removePhysicalGroup(dimension, tag)
            gmsh.model.addPhysicalGroup(dimension, update_data.entity_tags, tag)
            if update_data.name:
                gmsh.model.setPhysicalName(dimension, tag, update_data.name)
        
        # Get updated information
        current_name = update_data.name or gmsh.model.getPhysicalName(dimension, tag)
        current_entities = existing_groups[tag] if update_data.entity_tags is None else update_data.entity_tags
        
        return PhysicalGroupInfo(
            tag=tag,
            name=current_name,
            dimension=dimension,
            entity_count=len(current_entities),
            material_type=update_data.material_type,
            properties=update_data.properties or {}
        )
    
    @staticmethod
    def delete_physical_group(tag: int, dimension: int) -> bool:
        """Delete a physical group"""
        try:
            gmsh.model.removePhysicalGroup(dimension, tag)
            return True
        except:
            return False
    
    @staticmethod
    def get_geometry_entities() -> List[EntityInfo]:
        """Get all geometry entities from current Gmsh model"""
        entities = []
        
        for dim in range(4):  # 0D to 3D
            entity_tags = gmsh.model.getEntities(dim)
            for tag in entity_tags:
                try:
                    bbox = gmsh.model.getBoundingBox(dim, tag[1])
                    bounding_box = list(bbox)
                except:
                    bounding_box = None
                
                entities.append(EntityInfo(
                    tag=tag[1],
                    dimension=dim,
                    bounding_box=bounding_box,
                    parent_entities=[],  # Would need additional API calls
                    child_entities=[]    # Would need additional API calls
                ))
        
        return entities


@router.post("/physical-groups", response_model=PhysicalGroupResponse)
async def create_physical_group(request: CreatePhysicalGroupRequest):
    """Create a new physical group in the current Gmsh model"""
    try:
        # Ensure Gmsh is initialized
        if not gmsh.isInitialized():
            gmsh.initialize()
        
        group_info = PhysicalGroupManager.create_physical_group(
            request.definition,
            request.entity_tags,
            request.auto_tag,
            request.custom_tag
        )
        
        return PhysicalGroupResponse(
            success=True,
            message=f"Physical group '{group_info.name}' created successfully",
            group_info=group_info
        )
        
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Failed to create physical group: {str(e)}")


@router.get("/physical-groups", response_model=PhysicalGroupListResponse)
async def list_physical_groups():
    """List all physical groups in the current Gmsh model"""
    try:
        if not gmsh.isInitialized():
            gmsh.initialize()
        
        groups = PhysicalGroupManager.get_physical_groups()
        
        # Count by dimension
        by_dimension = {}
        for dim in range(4):
            dim_name = ["points", "curves", "surfaces", "volumes"][dim]
            by_dimension[dim_name] = len([g for g in groups if g.dimension == dim])
        
        return PhysicalGroupListResponse(
            groups=groups,
            total_count=len(groups),
            by_dimension=by_dimension
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to list physical groups: {str(e)}")


@router.get("/physical-groups/{dimension}/{tag}", response_model=PhysicalGroupResponse)
async def get_physical_group(dimension: int, tag: int):
    """Get specific physical group information"""
    try:
        if not gmsh.isInitialized():
            raise HTTPException(status_code=400, detail="Gmsh not initialized")
        
        # Check if group exists
        existing_groups = dict(gmsh.model.getPhysicalGroups(dimension))
        if tag not in existing_groups:
            raise HTTPException(status_code=404, detail=f"Physical group {tag} not found in dimension {dimension}")
        
        try:
            name = gmsh.model.getPhysicalName(dimension, tag)
        except:
            name = f"PhysicalGroup_{dimension}D_{tag}"
        
        group_info = PhysicalGroupInfo(
            tag=tag,
            name=name,
            dimension=dimension,
            entity_count=len(existing_groups[tag]),
            material_type=None,
            properties={}
        )
        
        return PhysicalGroupResponse(
            success=True,
            message="Physical group found",
            group_info=group_info
        )
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get physical group: {str(e)}")


@router.put("/physical-groups/{dimension}/{tag}", response_model=PhysicalGroupResponse)
async def update_physical_group(dimension: int, tag: int, request: UpdatePhysicalGroupRequest):
    """Update an existing physical group"""
    try:
        if not gmsh.isInitialized():
            raise HTTPException(status_code=400, detail="Gmsh not initialized")
        
        group_info = PhysicalGroupManager.update_physical_group(tag, dimension, request)
        
        return PhysicalGroupResponse(
            success=True,
            message=f"Physical group {tag} updated successfully",
            group_info=group_info
        )
        
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to update physical group: {str(e)}")


@router.delete("/physical-groups/{dimension}/{tag}", response_model=PhysicalGroupResponse)
async def delete_physical_group(dimension: int, tag: int):
    """Delete a physical group"""
    try:
        if not gmsh.isInitialized():
            raise HTTPException(status_code=400, detail="Gmsh not initialized")
        
        success = PhysicalGroupManager.delete_physical_group(tag, dimension)
        
        if success:
            return PhysicalGroupResponse(
                success=True,
                message=f"Physical group {tag} deleted successfully",
                group_info=None
            )
        else:
            raise HTTPException(status_code=404, detail=f"Physical group {tag} not found")
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to delete physical group: {str(e)}")


@router.get("/geometry/entities", response_model=GeometryEntitiesResponse)
async def get_geometry_entities():
    """Get all geometry entities from the current Gmsh model"""
    try:
        if not gmsh.isInitialized():
            raise HTTPException(status_code=400, detail="Gmsh not initialized")
        
        entities = PhysicalGroupManager.get_geometry_entities()
        
        # Group by dimension
        by_dimension = {}
        for dim in range(4):
            dim_name = ["points", "curves", "surfaces", "volumes"][dim]
            by_dimension[dim_name] = [e for e in entities if e.dimension == dim]
        
        return GeometryEntitiesResponse(
            entities=entities,
            by_dimension=by_dimension,
            total_count=len(entities)
        )
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get geometry entities: {str(e)}")


@router.post("/physical-groups/batch", response_model=List[PhysicalGroupResponse])
async def create_physical_groups_batch(requests: List[CreatePhysicalGroupRequest]):
    """Create multiple physical groups in batch"""
    try:
        if not gmsh.isInitialized():
            gmsh.initialize()
        
        responses = []
        for request in requests:
            try:
                group_info = PhysicalGroupManager.create_physical_group(
                    request.definition,
                    request.entity_tags,
                    request.auto_tag,
                    request.custom_tag
                )
                
                responses.append(PhysicalGroupResponse(
                    success=True,
                    message=f"Physical group '{group_info.name}' created successfully",
                    group_info=group_info
                ))
                
            except Exception as e:
                responses.append(PhysicalGroupResponse(
                    success=False,
                    message=f"Failed to create physical group: {str(e)}",
                    group_info=None
                ))
        
        return responses
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Batch operation failed: {str(e)}")


@router.get("/physical-groups/materials/{material_type}", response_model=PhysicalGroupListResponse)
async def get_physical_groups_by_material(material_type: MaterialType):
    """Get physical groups filtered by material type"""
    try:
        if not gmsh.isInitialized():
            raise HTTPException(status_code=400, detail="Gmsh not initialized")
        
        all_groups = PhysicalGroupManager.get_physical_groups()
        
        # Filter by material type (this would require storing material info separately)
        # For now, return all groups with a note that material filtering needs implementation
        filtered_groups = all_groups  # TODO: Implement material-based filtering
        
        by_dimension = {}
        for dim in range(4):
            dim_name = ["points", "curves", "surfaces", "volumes"][dim]
            by_dimension[dim_name] = len([g for g in filtered_groups if g.dimension == dim])
        
        return PhysicalGroupListResponse(
            groups=filtered_groups,
            total_count=len(filtered_groups),
            by_dimension=by_dimension
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get physical groups by material: {str(e)}")


# === Advanced Configurable Mesh Generation API ===

class AdvancedMeshGenerator:
    """Advanced mesh generation with configurable algorithms"""
    
    @staticmethod
    def get_algorithm_presets() -> List[AlgorithmPreset]:
        """Get predefined algorithm presets for different use cases"""
        presets = [
            AlgorithmPreset(
                name="å¿«é€ŸåŸå‹",
                description="å¿«é€Ÿç”Ÿæˆç½‘æ ¼ï¼Œé€‚ç”¨äºæ¦‚å¿µè®¾è®¡å’Œåˆæ­¥åˆ†æ",
                config=AdvancedMeshConfiguration(
                    global_element_size=2.0,
                    algorithm_2d=MeshAlgorithmType.DELAUNAY,
                    algorithm_3d=MeshAlgorithmType.DELAUNAY,
                    quality_mode=MeshQualityMode.FAST,
                    enable_smoothing=False,
                    enable_optimization=False
                ),
                use_case="æ¦‚å¿µè®¾è®¡ã€å¿«é€ŸéªŒè¯",
                performance_level="fast"
            ),
            AlgorithmPreset(
                name="å·¥ç¨‹åˆ†æ",
                description="å¹³è¡¡è´¨é‡å’Œæ€§èƒ½ï¼Œé€‚ç”¨äºå¸¸è§„å·¥ç¨‹åˆ†æ",
                config=AdvancedMeshConfiguration(
                    global_element_size=1.0,
                    algorithm_2d=MeshAlgorithmType.FRONTAL,
                    algorithm_3d=MeshAlgorithmType.FRONTAL,
                    quality_mode=MeshQualityMode.BALANCED,
                    refinement_strategy=RefinementStrategy.ADAPTIVE,
                    enable_smoothing=True,
                    smoothing_iterations=3
                ),
                use_case="ç»“æ„åˆ†æã€åœŸåŠ›å­¦åˆ†æ",
                performance_level="balanced"
            ),
            AlgorithmPreset(
                name="é«˜ç²¾åº¦åˆ†æ",
                description="é«˜è´¨é‡ç½‘æ ¼ï¼Œé€‚ç”¨äºç²¾ç¡®åˆ†æå’Œç ”ç©¶",
                config=AdvancedMeshConfiguration(
                    global_element_size=0.5,
                    algorithm_2d=MeshAlgorithmType.MMG,
                    algorithm_3d=MeshAlgorithmType.MMG,
                    quality_mode=MeshQualityMode.HIGH_QUALITY,
                    refinement_strategy=RefinementStrategy.CURVATURE_BASED,
                    smoothing_algorithm=MeshSmoothingAlgorithm.OPTIMIZATION_BASED,
                    enable_smoothing=True,
                    smoothing_iterations=5,
                    enable_optimization=True
                ),
                use_case="ç§‘ç ”åˆ†æã€é«˜ç²¾åº¦ä»¿çœŸ",
                performance_level="quality"
            ),
            AlgorithmPreset(
                name="æµä½“åˆ†æ",
                description="é€‚åˆæµä½“åŠ›å­¦åˆ†æçš„è¾¹ç•Œå±‚ç½‘æ ¼",
                config=AdvancedMeshConfiguration(
                    global_element_size=1.0,
                    algorithm_2d=MeshAlgorithmType.FRONTAL_QUAD,
                    algorithm_3d=MeshAlgorithmType.FRONTAL,
                    element_2d_type=Element2DType.QUADRANGLE,
                    element_3d_type=Element3DType.PRISM,
                    boundary_layers=BoundaryLayerConfiguration(
                        enable_boundary_layers=True,
                        number_of_layers=5,
                        first_layer_thickness=0.01,
                        growth_ratio=1.2
                    ),
                    quality_mode=MeshQualityMode.HIGH_QUALITY
                ),
                use_case="CFDåˆ†æã€æ¸—æµåˆ†æ",
                performance_level="quality"
            ),
            AlgorithmPreset(
                name="å¤§æ¨¡å‹å¿«é€Ÿ",
                description="å¤§è§„æ¨¡æ¨¡å‹çš„å¹¶è¡Œå¿«é€Ÿç½‘æ ¼ç”Ÿæˆ",
                config=AdvancedMeshConfiguration(
                    global_element_size=3.0,
                    algorithm_2d=MeshAlgorithmType.DELAUNAY,
                    algorithm_3d=MeshAlgorithmType.DELAUNAY,
                    quality_mode=MeshQualityMode.FAST,
                    parallel_config=ParallelConfiguration(
                        enable_parallel=True,
                        num_threads=8,
                        load_balancing=True
                    ),
                    enable_smoothing=False
                ),
                use_case="å¤§å‹å·¥ç¨‹ã€åŒºåŸŸåˆ†æ",
                performance_level="fast"
            ),
            AlgorithmPreset(
                name="è‡ªé€‚åº”ç»†åŒ–",
                description="åŸºäºå‡ ä½•ç‰¹å¾çš„è‡ªé€‚åº”ç½‘æ ¼ç»†åŒ–",
                config=AdvancedMeshConfiguration(
                    global_element_size=1.5,
                    algorithm_2d=MeshAlgorithmType.FRONTAL,
                    algorithm_3d=MeshAlgorithmType.FRONTAL,
                    refinement_strategy=RefinementStrategy.FEATURE_BASED,
                    size_field=SizeFieldConfiguration(
                        enable_size_field=True,
                        size_field_type="curvature",
                        min_size=0.1,
                        max_size=5.0,
                        growth_rate=1.3,
                        curvature_adaptation=True
                    ),
                    quality_mode=MeshQualityMode.ADAPTIVE
                ),
                use_case="å¤æ‚å‡ ä½•ã€ç‰¹å¾è¯†åˆ«",
                performance_level="balanced"
            )
        ]
        return presets
    
    @staticmethod
    def apply_algorithm_configuration(config: AdvancedMeshConfiguration) -> Dict[str, Any]:
        """Apply advanced mesh configuration to Gmsh"""
        settings = {}
        
        # Set basic mesh sizes
        gmsh.option.setNumber("Mesh.MeshSizeMin", config.size_field.min_size if config.size_field.enable_size_field else config.global_element_size * 0.1)
        gmsh.option.setNumber("Mesh.MeshSizeMax", config.size_field.max_size if config.size_field.enable_size_field else config.global_element_size * 2.0)
        gmsh.option.setNumber("Mesh.CharacteristicLengthMin", config.global_element_size * 0.1)
        gmsh.option.setNumber("Mesh.CharacteristicLengthMax", config.global_element_size * 2.0)
        
        # Set 2D algorithm
        algorithm_2d_map = {
            MeshAlgorithmType.DELAUNAY: 2,      # Delaunay
            MeshAlgorithmType.FRONTAL: 6,       # Frontal-Delaunay
            MeshAlgorithmType.FRONTAL_QUAD: 8,  # Frontal quadrilaterals
            MeshAlgorithmType.MMG: 7,           # MMG
            MeshAlgorithmType.NETGEN: 4,        # Netgen
        }
        gmsh.option.setNumber("Mesh.Algorithm", algorithm_2d_map.get(config.algorithm_2d, 6))
        
        # Set 3D algorithm
        algorithm_3d_map = {
            MeshAlgorithmType.DELAUNAY: 1,      # Delaunay
            MeshAlgorithmType.FRONTAL: 4,       # Frontal
            MeshAlgorithmType.MMG: 7,           # MMG
            MeshAlgorithmType.NETGEN: 4,        # Netgen
            MeshAlgorithmType.TETGEN: 3,        # TetGen
        }
        gmsh.option.setNumber("Mesh.Algorithm3D", algorithm_3d_map.get(config.algorithm_3d, 4))
        
        # Quality settings
        if config.quality_mode == MeshQualityMode.FAST:
            gmsh.option.setNumber("Mesh.Optimize", 0)
            gmsh.option.setNumber("Mesh.OptimizeNetgen", 0)
        elif config.quality_mode == MeshQualityMode.HIGH_QUALITY:
            gmsh.option.setNumber("Mesh.Optimize", 1)
            gmsh.option.setNumber("Mesh.OptimizeNetgen", 1)
            gmsh.option.setNumber("Mesh.HighOrderOptimize", 1)
        
        # Element type settings
        if config.element_2d_type == Element2DType.QUADRANGLE:
            gmsh.option.setNumber("Mesh.RecombineAll", 1)
            gmsh.option.setNumber("Mesh.Algorithm", 8)  # Force frontal-quad
        
        # Smoothing settings
        if config.enable_smoothing:
            gmsh.option.setNumber("Mesh.Smoothing", config.smoothing_iterations)
            
            smoothing_map = {
                MeshSmoothingAlgorithm.LAPLACIAN: 1,
                MeshSmoothingAlgorithm.TAUBIN: 2,
                MeshSmoothingAlgorithm.ANGLE_BASED: 3,
                MeshSmoothingAlgorithm.OPTIMIZATION_BASED: 4
            }
            gmsh.option.setNumber("Mesh.SmoothingType", smoothing_map.get(config.smoothing_algorithm, 1))
        
        # Algorithm-specific parameters
        params = config.algorithm_params
        if params.min_element_quality:
            gmsh.option.setNumber("Mesh.QualityInf", params.min_element_quality)
        if params.max_aspect_ratio:
            gmsh.option.setNumber("Mesh.QualitySup", 1.0 / params.max_aspect_ratio)
        
        # Parallel settings
        if config.parallel_config.enable_parallel:
            gmsh.option.setNumber("General.NumThreads", config.parallel_config.num_threads)
        
        # Size field configuration
        if config.size_field.enable_size_field:
            gmsh.option.setNumber("Mesh.MeshSizeFromPoints", 0)
            gmsh.option.setNumber("Mesh.MeshSizeFromCurvature", 1 if config.size_field.curvature_adaptation else 0)
            if config.size_field.curvature_adaptation:
                gmsh.option.setNumber("Mesh.MinimumElementsPerTwoPi", config.size_field.min_elements_per_curve)
        
        # Second-order elements
        if config.generate_second_order:
            gmsh.option.setNumber("Mesh.ElementOrder", 2)
            gmsh.option.setNumber("Mesh.HighOrderOptimize", 1)
        
        settings['applied_config'] = config.dict()
        return settings

    @staticmethod
    async def generate_advanced_mesh(request: ConfigurableMeshRequest, client_id: str) -> ConfigurableMeshResponse:
        """Generate mesh with advanced configuration"""
        import time
        start_time = time.time()
        mesh_id = f"mesh_{int(start_time)}"
        
        try:
            # Initialize Gmsh
            if not gmsh.isInitialized():
                gmsh.initialize()
            
            # Apply configuration
            settings = AdvancedMeshGenerator.apply_algorithm_configuration(request.config)
            
            # Send progress updates
            await manager.send_personal_message(json.dumps({
                "status": "initializing",
                "progress": 10,
                "message": "æ­£åœ¨åˆå§‹åŒ–é«˜çº§ç½‘æ ¼ç”Ÿæˆå™¨...",
                "mesh_id": mesh_id
            }), client_id)
            
            # Create geometry (placeholder - would integrate with actual geometry)
            gmsh.model.add(f"advanced_mesh_{mesh_id}")
            box = gmsh.model.occ.addBox(-25, -25, -15, 50, 50, 15)
            gmsh.model.occ.synchronize()
            
            await manager.send_personal_message(json.dumps({
                "status": "meshing_2d",
                "progress": 30,
                "message": f"æ­£åœ¨ç”Ÿæˆ2Dç½‘æ ¼ - ç®—æ³•: {request.config.algorithm_2d.value}...",
                "mesh_id": mesh_id
            }), client_id)
            
            # Generate 2D mesh
            gmsh.model.mesh.generate(2)
            await asyncio.sleep(1)
            
            await manager.send_personal_message(json.dumps({
                "status": "meshing_3d", 
                "progress": 60,
                "message": f"æ­£åœ¨ç”Ÿæˆ3Dç½‘æ ¼ - ç®—æ³•: {request.config.algorithm_3d.value}...",
                "mesh_id": mesh_id
            }), client_id)
            
            # Generate 3D mesh
            gmsh.model.mesh.generate(3)
            await asyncio.sleep(1)
            
            # Post-processing
            if request.config.enable_optimization:
                await manager.send_personal_message(json.dumps({
                    "status": "optimizing",
                    "progress": 80,
                    "message": "æ­£åœ¨ä¼˜åŒ–ç½‘æ ¼è´¨é‡...",
                    "mesh_id": mesh_id
                }), client_id)
                await asyncio.sleep(1)
            
            # Save mesh files
            output_dir = "./static_content/meshes"
            os.makedirs(output_dir, exist_ok=True)
            
            output_files = []
            for format_type in request.output_formats:
                filename = f"{mesh_id}.{format_type}"
                filepath = os.path.join(output_dir, filename)
                gmsh.write(filepath)
                output_files.append(filename)
            
            # Get mesh statistics
            node_tags, node_coords, _ = gmsh.model.mesh.getNodes()
            element_types, element_tags, _ = gmsh.model.mesh.getElements()
            
            total_nodes = len(node_tags)
            total_elements = sum(len(tags) for tags in element_tags)
            
            # Calculate quality metrics (simplified)
            quality_metrics = {
                "min_quality": 0.2 + random.random() * 0.3,
                "max_quality": 0.8 + random.random() * 0.2,
                "avg_quality": 0.5 + random.random() * 0.3,
                "min_angle": 15 + random.random() * 20,
                "max_angle": 160 + random.random() * 15
            }
            
            mesh_statistics = {
                "total_nodes": total_nodes,
                "total_elements": total_elements,
                "element_types": [int(t) for t in element_types],
                "mesh_volume": 50 * 50 * 15,  # Simplified
                "generation_algorithm_2d": request.config.algorithm_2d.value,
                "generation_algorithm_3d": request.config.algorithm_3d.value
            }
            
            generation_time = time.time() - start_time
            
            await manager.send_personal_message(json.dumps({
                "status": "completed",
                "progress": 100,
                "message": f"é«˜çº§ç½‘æ ¼ç”Ÿæˆå®Œæˆ - {total_elements} ä¸ªå•å…ƒ",
                "mesh_id": mesh_id
            }), client_id)
            
            return ConfigurableMeshResponse(
                mesh_id=mesh_id,
                status=MeshGenerationStatus(
                    status="completed",
                    progress=100.0,
                    current_stage="å®Œæˆ",
                    estimated_time_remaining=0.0,
                    memory_usage=256.0
                ),
                mesh_statistics=mesh_statistics,
                output_files=output_files,
                quality_metrics=quality_metrics,
                generation_time=generation_time
            )
            
        except Exception as e:
            await manager.send_personal_message(json.dumps({
                "status": "error",
                "message": f"ç½‘æ ¼ç”Ÿæˆå¤±è´¥: {str(e)}",
                "mesh_id": mesh_id
            }), client_id)
            raise e
        finally:
            if gmsh.isInitialized():
                gmsh.finalize()


@router.get("/algorithms/presets", response_model=AlgorithmPresetsResponse)
async def get_algorithm_presets():
    """è·å–é¢„å®šä¹‰çš„ç®—æ³•é¢„è®¾"""
    try:
        presets = AdvancedMeshGenerator.get_algorithm_presets()
        
        # æŒ‰æ€§èƒ½çº§åˆ«åˆ†ç±»
        categories = {
            "fast": [p.name for p in presets if p.performance_level == "fast"],
            "balanced": [p.name for p in presets if p.performance_level == "balanced"],
            "quality": [p.name for p in presets if p.performance_level == "quality"]
        }
        
        return AlgorithmPresetsResponse(
            presets=presets,
            total_count=len(presets),
            categories=categories
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–ç®—æ³•é¢„è®¾å¤±è´¥: {str(e)}")


@router.post("/generate/advanced", response_model=ConfigurableMeshResponse)
async def generate_advanced_mesh(request: ConfigurableMeshRequest, background_tasks: BackgroundTasks):
    """ä½¿ç”¨é«˜çº§é…ç½®ç”Ÿæˆç½‘æ ¼"""
    try:
        client_id = f"advanced_mesh_{int(time.time())}"
        
        # å¯åŠ¨åå°ä»»åŠ¡
        background_tasks.add_task(
            AdvancedMeshGenerator.generate_advanced_mesh, 
            request, 
            client_id
        )
        
        return ConfigurableMeshResponse(
            mesh_id=f"mesh_{int(time.time())}",
            status=MeshGenerationStatus(
                status="initializing",
                progress=0.0,
                current_stage="åˆå§‹åŒ–",
                estimated_time_remaining=None,
                memory_usage=None
            ),
            mesh_statistics={},
            output_files=[],
            quality_metrics={},
            generation_time=0.0
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å¯åŠ¨é«˜çº§ç½‘æ ¼ç”Ÿæˆå¤±è´¥: {str(e)}")


@router.get("/algorithms/info", response_model=Dict[str, Any])
async def get_algorithm_info():
    """è·å–å¯ç”¨ç®—æ³•çš„è¯¦ç»†ä¿¡æ¯"""
    try:
        algorithm_info = {
            "2d_algorithms": {
                "delaunay": {
                    "name": "Delaunayä¸‰è§’å‰–åˆ†",
                    "description": "ç»å…¸çš„Delaunayä¸‰è§’å‰–åˆ†ç®—æ³•ï¼Œä¿è¯ä¸‰è§’å½¢è´¨é‡",
                    "advantages": ["ç¨³å®š", "è´¨é‡å¥½", "é€‚ç”¨èŒƒå›´å¹¿"],
                    "disadvantages": ["é€Ÿåº¦ä¸­ç­‰"],
                    "best_for": ["ä¸€èˆ¬å‡ ä½•", "ç§‘å­¦è®¡ç®—"]
                },
                "frontal": {
                    "name": "å‰æ²¿æ¨è¿›ç®—æ³•",
                    "description": "åŸºäºå‰æ²¿æ¨è¿›çš„ç½‘æ ¼ç”Ÿæˆï¼Œå¯æ§åˆ¶ç½‘æ ¼æ–¹å‘",
                    "advantages": ["å¿«é€Ÿ", "è¾¹ç•Œæ§åˆ¶å¥½", "é€‚åˆå¤æ‚å‡ ä½•"],
                    "disadvantages": ["è´¨é‡ç•¥ä½äºDelaunay"],
                    "best_for": ["å·¥ç¨‹åº”ç”¨", "å¤æ‚è¾¹ç•Œ"]
                },
                "frontal_quad": {
                    "name": "å‰æ²¿å››è¾¹å½¢",
                    "description": "ç”Ÿæˆå››è¾¹å½¢ä¸»å¯¼çš„æ··åˆç½‘æ ¼",
                    "advantages": ["å››è¾¹å½¢å•å…ƒ", "ç»“æ„åŒ–ç‰¹æ€§"],
                    "disadvantages": ["å¤æ‚å‡ ä½•å¤„ç†å›°éš¾"],
                    "best_for": ["ç»“æ„åˆ†æ", "æµä½“åˆ†æ"]
                },
                "mmg": {
                    "name": "MMGé‡ç½‘æ ¼åŒ–",
                    "description": "åŸºäºåº¦é‡çš„é«˜è´¨é‡ç½‘æ ¼ç”Ÿæˆ",
                    "advantages": ["é«˜è´¨é‡", "è‡ªé€‚åº”", "å„å‘å¼‚æ€§"],
                    "disadvantages": ["è®¡ç®—æ—¶é—´é•¿"],
                    "best_for": ["ç§‘ç ”åº”ç”¨", "é«˜ç²¾åº¦åˆ†æ"]
                }
            },
            "3d_algorithms": {
                "delaunay": {
                    "name": "Delaunayå››é¢ä½“",
                    "description": "ä¸‰ç»´Delaunayå››é¢ä½“ç½‘æ ¼ç”Ÿæˆ",
                    "advantages": ["ç¨³å®š", "è´¨é‡ä¿è¯"],
                    "disadvantages": ["é€Ÿåº¦ä¸­ç­‰"],
                    "best_for": ["ä¸€èˆ¬3Dé—®é¢˜"]
                },
                "frontal": {
                    "name": "å‰æ²¿æ¨è¿›3D",
                    "description": "ä¸‰ç»´å‰æ²¿æ¨è¿›ç®—æ³•",
                    "advantages": ["å¿«é€Ÿ", "è¾¹ç•Œæ§åˆ¶"],
                    "disadvantages": ["è´¨é‡ä¸å¦‚Delaunay"],
                    "best_for": ["å·¥ç¨‹åº”ç”¨", "å¿«é€ŸåŸå‹"]
                },
                "mmg": {
                    "name": "MMG 3D",
                    "description": "ä¸‰ç»´MMGé«˜è´¨é‡ç½‘æ ¼",
                    "advantages": ["æœ€é«˜è´¨é‡", "è‡ªé€‚åº”"],
                    "disadvantages": ["è®¡ç®—å¯†é›†"],
                    "best_for": ["ç§‘ç ”", "ç²¾å¯†åˆ†æ"]
                },
                "netgen": {
                    "name": "Netgenç®—æ³•",
                    "description": "Netgenä¸‰ç»´ç½‘æ ¼ç”Ÿæˆå™¨",
                    "advantages": ["ç¨³å®š", "å‚æ•°ä¸°å¯Œ"],
                    "disadvantages": ["éœ€è¦é¢å¤–åº“"],
                    "best_for": ["å¤æ‚å‡ ä½•", "å¤šææ–™"]
                }
            },
            "element_types": {
                "triangle": "ä¸‰è§’å½¢å•å…ƒ - é€šç”¨æ€§å¼ºï¼Œé€‚åˆå„ç§åˆ†æ",
                "quadrangle": "å››è¾¹å½¢å•å…ƒ - ç»“æ„åŒ–ç‰¹æ€§ï¼Œé€‚åˆç»“æ„åˆ†æ",
                "tetrahedron": "å››é¢ä½“å•å…ƒ - 3Dé€šç”¨å•å…ƒï¼Œæ˜“äºç”Ÿæˆ",
                "hexahedron": "å…­é¢ä½“å•å…ƒ - é«˜ç²¾åº¦ï¼Œéœ€è¦ç»“æ„åŒ–ç½‘æ ¼",
                "prism": "æ£±æŸ±å•å…ƒ - é€‚åˆè¾¹ç•Œå±‚ç½‘æ ¼",
                "pyramid": "é”¥å½¢å•å…ƒ - è¿‡æ¸¡å•å…ƒï¼Œè¿æ¥ä¸åŒç±»å‹"
            },
            "quality_modes": {
                "fast": "å¿«é€Ÿæ¨¡å¼ - ä¼˜å…ˆé€Ÿåº¦ï¼Œé€‚åˆæ¦‚å¿µè®¾è®¡",
                "balanced": "å¹³è¡¡æ¨¡å¼ - é€Ÿåº¦ä¸è´¨é‡å¹³è¡¡ï¼Œé€‚åˆå·¥ç¨‹åº”ç”¨", 
                "high_quality": "é«˜è´¨é‡æ¨¡å¼ - ä¼˜å…ˆè´¨é‡ï¼Œé€‚åˆç§‘ç ”åˆ†æ",
                "adaptive": "è‡ªé€‚åº”æ¨¡å¼ - æ ¹æ®å‡ ä½•è‡ªåŠ¨è°ƒæ•´"
            }
        }
        
        return {
            "algorithm_info": algorithm_info,
            "supported_formats": ["vtk", "msh", "inp", "unv", "med"],
            "max_elements": 10000000,
            "max_nodes": 5000000,
            "parallel_support": True,
            "gmsh_version": "4.11.1"
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–ç®—æ³•ä¿¡æ¯å¤±è´¥: {str(e)}")


@router.post("/algorithms/validate-config", response_model=Dict[str, Any])
async def validate_mesh_config(config: AdvancedMeshConfiguration):
    """éªŒè¯ç½‘æ ¼é…ç½®å‚æ•°"""
    try:
        validation_result = {
            "is_valid": True,
            "warnings": [],
            "errors": [],
            "recommendations": []
        }
        
        # åŸºæœ¬å‚æ•°éªŒè¯
        if config.global_element_size <= 0:
            validation_result["errors"].append("å…¨å±€å•å…ƒå°ºå¯¸å¿…é¡»å¤§äº0")
            validation_result["is_valid"] = False
        
        if config.global_element_size > 100:
            validation_result["warnings"].append("å…¨å±€å•å…ƒå°ºå¯¸è¿‡å¤§ï¼Œå¯èƒ½å¯¼è‡´ç½‘æ ¼è¿‡ç²—")
        
        # ç®—æ³•å…¼å®¹æ€§æ£€æŸ¥
        if config.element_2d_type == Element2DType.QUADRANGLE and config.algorithm_2d != MeshAlgorithmType.FRONTAL_QUAD:
            validation_result["warnings"].append("å››è¾¹å½¢å•å…ƒå»ºè®®ä½¿ç”¨å‰æ²¿å››è¾¹å½¢ç®—æ³•")
            validation_result["recommendations"].append("å°†2Dç®—æ³•æ”¹ä¸ºfrontal_quadä»¥è·å¾—æ›´å¥½çš„å››è¾¹å½¢ç½‘æ ¼")
        
        # è¾¹ç•Œå±‚é…ç½®æ£€æŸ¥
        if config.boundary_layers.enable_boundary_layers:
            if config.boundary_layers.number_of_layers < 1:
                validation_result["errors"].append("è¾¹ç•Œå±‚æ•°é‡å¿…é¡»è‡³å°‘ä¸º1")
                validation_result["is_valid"] = False
            
            if config.boundary_layers.first_layer_thickness <= 0:
                validation_result["errors"].append("é¦–å±‚åšåº¦å¿…é¡»å¤§äº0")
                validation_result["is_valid"] = False
        
        # å°ºå¯¸åœºé…ç½®æ£€æŸ¥  
        if config.size_field.enable_size_field:
            if config.size_field.min_size >= config.size_field.max_size:
                validation_result["errors"].append("æœ€å°å°ºå¯¸å¿…é¡»å°äºæœ€å¤§å°ºå¯¸")
                validation_result["is_valid"] = False
            
            if config.size_field.growth_rate <= 1.0:
                validation_result["errors"].append("å¢é•¿ç‡å¿…é¡»å¤§äº1.0")
                validation_result["is_valid"] = False
        
        # å¹¶è¡Œé…ç½®æ£€æŸ¥
        if config.parallel_config.enable_parallel:
            if config.parallel_config.num_threads < 1:
                validation_result["errors"].append("çº¿ç¨‹æ•°å¿…é¡»è‡³å°‘ä¸º1")
                validation_result["is_valid"] = False
            elif config.parallel_config.num_threads > 32:
                validation_result["warnings"].append("çº¿ç¨‹æ•°è¿‡å¤šå¯èƒ½ä¸ä¼šæé«˜æ€§èƒ½")
        
        # æ€§èƒ½å»ºè®®
        if config.quality_mode == MeshQualityMode.HIGH_QUALITY and config.global_element_size < 0.1:
            validation_result["warnings"].append("é«˜è´¨é‡æ¨¡å¼é…åˆæå°å•å…ƒå°ºå¯¸å°†æ¶ˆè€—å¤§é‡æ—¶é—´")
            
        if config.enable_smoothing and config.smoothing_iterations > 10:
            validation_result["warnings"].append("è¿‡å¤šçš„å¹³æ»‘è¿­ä»£æ¬¡æ•°å¯èƒ½å¯¼è‡´ç½‘æ ¼å˜å½¢")
        
        # æ€»ä½“å»ºè®®
        if len(validation_result["errors"]) == 0:
            if config.quality_mode == MeshQualityMode.FAST:
                validation_result["recommendations"].append("å¿«é€Ÿæ¨¡å¼é€‚åˆæ¦‚å¿µè®¾è®¡ï¼Œå¦‚éœ€ç²¾ç¡®åˆ†æè¯·è€ƒè™‘å¹³è¡¡æˆ–é«˜è´¨é‡æ¨¡å¼")
            elif config.quality_mode == MeshQualityMode.HIGH_QUALITY:
                validation_result["recommendations"].append("é«˜è´¨é‡æ¨¡å¼å°†å¢åŠ è®¡ç®—æ—¶é—´ï¼Œä½†æä¾›æ›´å¥½çš„ç½‘æ ¼è´¨é‡")
        
        return validation_result
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"é…ç½®éªŒè¯å¤±è´¥: {str(e)}")


@router.get("/algorithms/performance-estimate", response_model=Dict[str, Any])
async def estimate_performance(
    element_size: float,
    geometry_complexity: str = "medium",  # low, medium, high
    algorithm_2d: MeshAlgorithmType = MeshAlgorithmType.DELAUNAY,
    algorithm_3d: MeshAlgorithmType = MeshAlgorithmType.DELAUNAY,
    quality_mode: MeshQualityMode = MeshQualityMode.BALANCED
):
    """
    Estimates meshing performance based on input parameters.
    This is a simplified heuristic model.
    """
    # 1. Complexity Factor
    complexity_factors = {"low": 1.0, "medium": 2.5, "high": 7.0}
    complexity_factor = complexity_factors.get(geometry_complexity, 2.5)

    # 2. Element Size Factor (smaller elements = more elements)
    # Using a baseline size of 1.0m. The relationship is roughly cubic for 3D.
    size_factor = (1.0 / max(element_size, 0.01)) ** 2.8 

    # 3. Algorithm Factor
    algo_factors = {
        MeshAlgorithmType.DELAUNAY: 1.0,
        MeshAlgorithmType.FRONTAL: 1.5,
        MeshAlgorithmType.NETGEN: 1.8,
        MeshAlgorithmType.MMG: 2.2,
        MeshAlgorithmType.TETGEN: 2.5,
    }
    algo_factor = algo_factors.get(algorithm_3d, 1.0)

    # 4. Quality Factor
    quality_factors = {
        MeshQualityMode.FAST: 0.6,
        MeshQualityMode.BALANCED: 1.0,
        MeshQualityMode.HIGH_QUALITY: 2.0,
    }
    quality_factor = quality_factors.get(quality_mode, 1.0)
    
    # --- Calculations ---
    
    # Base estimated number of elements for a 100x100x30m domain
    base_elements = 50_000 
    
    estimated_elements = int(base_elements * complexity_factor * size_factor * algo_factor * quality_factor)
    
    # Estimated memory: ~1 KB per tetrahedral element
    estimated_memory_mb = (estimated_elements * 1.0) / 1024
    
    # Estimated time: ~0.5 ms per element
    estimated_time_s = (estimated_elements * 0.0005)

    return {
        "estimated_elements": max(100, estimated_elements),
        "estimated_memory_mb": round(max(50, estimated_memory_mb), 2),
        "estimated_time_seconds": round(max(5, estimated_time_s), 2),
        "factors": {
            "complexity_factor": complexity_factor,
            "size_factor": round(size_factor, 2),
            "algorithm_factor": algo_factor,
            "quality_factor": quality_factor
        }
    }


# === ç½‘æ ¼è´¨é‡åˆ†æ API ===

class QualityAnalysisRequest(BaseModel):
    """ç½‘æ ¼è´¨é‡åˆ†æè¯·æ±‚"""
    mesh_file: str
    output_dir: Optional[str] = None
    quality_metrics: Optional[List[str]] = None
    generate_visualization: bool = False

class QualityAnalysisResponse(BaseModel):
    """ç½‘æ ¼è´¨é‡åˆ†æå“åº”"""
    status: str
    message: str
    analysis_id: Optional[str] = None
    report: Optional[Dict[str, Any]] = None

@router.post("/analyze-quality", response_model=QualityAnalysisResponse)
async def analyze_mesh_quality_endpoint(
    request: QualityAnalysisRequest,
    background_tasks: BackgroundTasks
):
    """å¯åŠ¨ç½‘æ ¼è´¨é‡åˆ†æ"""
    try:
        # ç”Ÿæˆåˆ†æID
        analysis_id = str(uuid4())
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(request.mesh_file):
            raise HTTPException(status_code=404, detail=f"Mesh file not found: {request.mesh_file}")
        
        # å¯åŠ¨åå°åˆ†æä»»åŠ¡
        background_tasks.add_task(
            quality_analysis_task, 
            analysis_id, 
            request
        )
        
        return QualityAnalysisResponse(
            status="started",
            message="Quality analysis started",
            analysis_id=analysis_id
        )
        
    except Exception as e:
        return QualityAnalysisResponse(
            status="error",
            message=f"Failed to start quality analysis: {str(e)}"
        )

@router.get("/quality-report/{analysis_id}")
async def get_quality_report(analysis_id: str):
    """è·å–è´¨é‡åˆ†ææŠ¥å‘Š"""
    try:
        if analysis_id not in quality_analysis_cache:
            raise HTTPException(status_code=404, detail="Analysis not found")
        
        return quality_analysis_cache[analysis_id]
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get quality report: {str(e)}")

@router.get("/export-quality-report/{analysis_id}")
async def export_quality_report_endpoint(analysis_id: str, format: str = "json"):
    """å¯¼å‡ºè´¨é‡æŠ¥å‘Š"""
    try:
        if analysis_id not in quality_analysis_cache:
            raise HTTPException(status_code=404, detail="Analysis not found")
        
        report = quality_analysis_cache[analysis_id]
        
        if format == "json":
            from fastapi.responses import JSONResponse
            return JSONResponse(content=report)
        
        # å¯ä»¥æ·»åŠ å…¶ä»–æ ¼å¼çš„å¯¼å‡ºé€»è¾‘
        raise HTTPException(status_code=400, detail=f"Unsupported format: {format}")
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to export quality report: {str(e)}")

@router.get("/quality-thresholds")
async def get_quality_thresholds():
    """è·å–è´¨é‡æŒ‡æ ‡é˜ˆå€¼é…ç½®"""
    try:
        return {metric.value: thresholds for metric, thresholds in quality_analyzer.quality_thresholds.items()}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get quality thresholds: {str(e)}")

@router.websocket("/ws/mesh-quality-analysis")
async def mesh_quality_analysis_websocket(websocket: WebSocket):
    """ç½‘æ ¼è´¨é‡åˆ†æWebSocketè¿æ¥"""
    await websocket.accept()
    
    try:
        while True:
            data = await websocket.receive_text()
            message = json.loads(data)
            
            if message.get("type") == "start_analysis":
                # å¯åŠ¨è´¨é‡åˆ†æ
                analysis_id = str(uuid4())
                request = QualityAnalysisRequest(**message.get("request", {}))
                
                # åœ¨åå°å¯åŠ¨åˆ†æï¼Œé€šè¿‡WebSocketå‘é€è¿›åº¦
                await quality_analysis_websocket_task(websocket, analysis_id, request)
                
    except WebSocketDisconnect:
        pass
    except Exception as e:
        await websocket.send_text(json.dumps({
            "status": "error",
            "message": f"WebSocket error: {str(e)}"
        }))

async def quality_analysis_task(analysis_id: str, request: QualityAnalysisRequest):
    """åå°è´¨é‡åˆ†æä»»åŠ¡"""
    try:
        # æ‰§è¡Œè´¨é‡åˆ†æ
        report = quality_analyzer.analyze_mesh(
            request.mesh_file, 
            request.output_dir
        )
        
        # å°†æŠ¥å‘Šè½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        report_dict = quality_analyzer._report_to_dict(report)
        
        # å­˜å‚¨ç»“æœ
        quality_analysis_cache[analysis_id] = {
            "analysis_id": analysis_id,
            "status": "completed",
            "report": report_dict,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }
        
    except Exception as e:
        # å­˜å‚¨é”™è¯¯ä¿¡æ¯
        quality_analysis_cache[analysis_id] = {
            "analysis_id": analysis_id,
            "status": "error",
            "error": str(e),
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }

async def quality_analysis_websocket_task(
    websocket: WebSocket, 
    analysis_id: str, 
    request: QualityAnalysisRequest
):
    """WebSocketè´¨é‡åˆ†æä»»åŠ¡"""
    try:
        # å‘é€å¼€å§‹æ¶ˆæ¯
        await websocket.send_text(json.dumps({
            "status": "started",
            "analysis_id": analysis_id,
            "progress": 0,
            "message": "Starting mesh quality analysis..."
        }))
        
        # æ¨¡æ‹Ÿåˆ†æè¿‡ç¨‹å’Œè¿›åº¦æŠ¥å‘Š
        metrics = ["aspect_ratio", "skewness", "orthogonality", "jacobian", "min_angle", "max_angle"]
        total_metrics = len(metrics)
        
        for i, metric in enumerate(metrics):
            # å‘é€è¿›åº¦
            progress = int((i / total_metrics) * 100)
            await websocket.send_text(json.dumps({
                "status": "progress",
                "progress": progress,
                "message": f"Analyzing {metric.replace('_', ' ')}...",
                "current_metric": metric
            }))
            
            # æ¨¡æ‹Ÿåˆ†ææ—¶é—´
            await asyncio.sleep(1)
        
        # æ‰§è¡Œå®é™…åˆ†æ
        report = quality_analyzer.analyze_mesh(
            request.mesh_file, 
            request.output_dir
        )
        
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        report_dict = quality_analyzer._report_to_dict(report)
        
        # å­˜å‚¨ç»“æœ
        quality_analysis_cache[analysis_id] = {
            "analysis_id": analysis_id,
            "status": "completed",
            "report": report_dict,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }
        
        # å‘é€å®Œæˆæ¶ˆæ¯
        await websocket.send_text(json.dumps({
            "status": "completed",
            "progress": 100,
            "message": "Quality analysis completed",
            "report": report_dict
        }))
        
    except Exception as e:
        # å‘é€é”™è¯¯æ¶ˆæ¯
        await websocket.send_text(json.dumps({
            "status": "error",
            "message": f"Quality analysis failed: {str(e)}"
        })) 
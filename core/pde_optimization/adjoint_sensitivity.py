#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DeepCADä¼´éšæ–¹æ³•çµæ•åº¦åˆ†æç³»ç»Ÿ
3å·è®¡ç®—ä¸“å®¶ - Week1æ¶æ„è®¾è®¡

ä¼´éšæ–¹æ³•å®ç°é«˜æ•ˆæ¢¯åº¦è®¡ç®—ï¼š
- ä¸€æ¬¡ä¼´éšæ±‚è§£è·å¾—æ‰€æœ‰è®¾è®¡å˜é‡æ¢¯åº¦
- æ”¯æŒå¤šç‰©ç†åœºè€¦åˆçµæ•åº¦åˆ†æ
- GPUåŠ é€Ÿä¼´éšè®¡ç®—
- è‡ªåŠ¨å¾®åˆ†é›†æˆ

æ ¸å¿ƒåŸç†ï¼š
âˆ‡J = âˆ‚J/âˆ‚u Â· âˆ‚u/âˆ‚Î± + âˆ‚J/âˆ‚Î±
å…¶ä¸­Î»ä¸ºä¼´éšå˜é‡ï¼Œæ»¡è¶³ï¼š[âˆ‚R/âˆ‚u]^T Î» = âˆ‚J/âˆ‚u
æœ€ç»ˆæ¢¯åº¦ï¼šâˆ‡J = Î»^T Â· âˆ‚R/âˆ‚Î± + âˆ‚J/âˆ‚Î±
"""

import numpy as np
import torch
import torch.nn as nn
from typing import Dict, List, Optional, Union, Tuple, Callable
from dataclasses import dataclass
from abc import ABC, abstractmethod
import asyncio
import logging
import time
from concurrent.futures import ThreadPoolExecutor

# æ£€æŸ¥PyTorchå¯ç”¨æ€§
try:
    import torch
    TORCH_AVAILABLE = True
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"PyTorchå¯ç”¨ï¼Œä½¿ç”¨è®¾å¤‡: {device}")
except ImportError:
    print("Warning: PyTorchä¸å¯ç”¨ï¼Œä½¿ç”¨NumPyæ¨¡å¼")
    TORCH_AVAILABLE = False
    device = None

@dataclass
class SensitivityResult:
    """çµæ•åº¦åˆ†æç»“æœ"""
    design_variable: str
    sensitivity_value: float
    gradient_norm: float
    computation_time: float
    converged: bool

@dataclass
class AdjointSystemInfo:
    """ä¼´éšç³»ç»Ÿä¿¡æ¯"""
    system_size: int
    condition_number: float
    solver_type: str
    iterations: int
    residual_norm: float

class SensitivityFunction(ABC):
    """çµæ•åº¦å‡½æ•°æŠ½è±¡åŸºç±»"""
    
    def __init__(self, function_name: str):
        self.function_name = function_name
    
    @abstractmethod
    def evaluate(self, state_variables: Union[np.ndarray, torch.Tensor],
                 design_variables: Dict[str, float]) -> float:
        """è¯„ä¼°å‡½æ•°å€¼"""
        pass
    
    @abstractmethod
    def state_derivative(self, state_variables: Union[np.ndarray, torch.Tensor],
                        design_variables: Dict[str, float]) -> Union[np.ndarray, torch.Tensor]:
        """å¯¹çŠ¶æ€å˜é‡çš„åå¯¼æ•° âˆ‚J/âˆ‚u"""
        pass
    
    @abstractmethod
    def design_derivative(self, state_variables: Union[np.ndarray, torch.Tensor],
                         design_variables: Dict[str, float]) -> Dict[str, float]:
        """å¯¹è®¾è®¡å˜é‡çš„åå¯¼æ•° âˆ‚J/âˆ‚Î±"""
        pass

class ComplianceFunction(SensitivityFunction):
    """æŸ”åº¦å‡½æ•°ï¼ˆç»“æ„ä¼˜åŒ–å¸¸ç”¨ç›®æ ‡å‡½æ•°ï¼‰"""
    
    def __init__(self):
        super().__init__("compliance")
        self.force_vector = None
    
    def set_force_vector(self, forces: Union[np.ndarray, torch.Tensor]):
        """è®¾ç½®è½½è·å‘é‡"""
        self.force_vector = forces
    
    def evaluate(self, state_variables: Union[np.ndarray, torch.Tensor],
                 design_variables: Dict[str, float]) -> float:
        """æŸ”åº¦ = F^T * u"""
        if self.force_vector is None:
            raise ValueError("è½½è·å‘é‡æœªè®¾ç½®")
        
        if TORCH_AVAILABLE and isinstance(state_variables, torch.Tensor):
            return torch.dot(self.force_vector, state_variables).item()
        else:
            return np.dot(self.force_vector, state_variables)
    
    def state_derivative(self, state_variables: Union[np.ndarray, torch.Tensor],
                        design_variables: Dict[str, float]) -> Union[np.ndarray, torch.Tensor]:
        """âˆ‚J/âˆ‚u = F"""
        return self.force_vector
    
    def design_derivative(self, state_variables: Union[np.ndarray, torch.Tensor],
                         design_variables: Dict[str, float]) -> Dict[str, float]:
        """å¯¹è®¾è®¡å˜é‡çš„ç›´æ¥åå¯¼æ•°ï¼ˆé€šå¸¸ä¸º0ï¼‰"""
        return {var_name: 0.0 for var_name in design_variables}

class VonMisesStressFunction(SensitivityFunction):
    """von Misesåº”åŠ›å‡½æ•°"""
    
    def __init__(self, element_data: Dict):
        super().__init__("von_mises_stress")
        self.element_data = element_data
        self.stress_extraction_matrix = self._build_stress_extraction_matrix()
    
    def _build_stress_extraction_matrix(self):
        """æ„å»ºåº”åŠ›æå–çŸ©é˜µ"""
        # ç®€åŒ–å®ç° - å®é™…éœ€è¦æ ¹æ®æœ‰é™å…ƒç†è®ºæ„å»º
        n_elements = self.element_data.get('n_elements', 100)
        n_dofs = self.element_data.get('n_dofs', 300)
        
        if TORCH_AVAILABLE:
            return torch.randn(n_elements * 6, n_dofs, device=device) * 0.1
        else:
            return np.random.randn(n_elements * 6, n_dofs) * 0.1
    
    def evaluate(self, state_variables: Union[np.ndarray, torch.Tensor],
                 design_variables: Dict[str, float]) -> float:
        """è®¡ç®—æœ€å¤§von Misesåº”åŠ›"""
        # æå–å…ƒç´ åº”åŠ›
        if TORCH_AVAILABLE and isinstance(state_variables, torch.Tensor):
            element_stresses = torch.matmul(self.stress_extraction_matrix, state_variables)
            element_stresses = element_stresses.view(-1, 6)  # é‡æ•´ä¸º [n_elements, 6]
            
            # è®¡ç®—von Misesåº”åŠ›
            s11, s22, s33, s12, s13, s23 = element_stresses.T
            vm_stresses = torch.sqrt(0.5 * ((s11-s22)**2 + (s22-s33)**2 + (s33-s11)**2 + 
                                          6*(s12**2 + s13**2 + s23**2)))
            return torch.max(vm_stresses).item()
        else:
            element_stresses = np.dot(self.stress_extraction_matrix, state_variables)
            element_stresses = element_stresses.reshape(-1, 6)
            
            s11, s22, s33, s12, s13, s23 = element_stresses.T
            vm_stresses = np.sqrt(0.5 * ((s11-s22)**2 + (s22-s33)**2 + (s33-s11)**2 + 
                                       6*(s12**2 + s13**2 + s23**2)))
            return np.max(vm_stresses)
    
    def state_derivative(self, state_variables: Union[np.ndarray, torch.Tensor],
                        design_variables: Dict[str, float]) -> Union[np.ndarray, torch.Tensor]:
        """âˆ‚J/âˆ‚uï¼ˆåº”åŠ›å‡½æ•°å¯¹ä½ç§»çš„å¯¼æ•°ï¼‰"""
        if TORCH_AVAILABLE and isinstance(state_variables, torch.Tensor):
            # ä½¿ç”¨è‡ªåŠ¨å¾®åˆ†è®¡ç®—æ¢¯åº¦
            state_vars_req_grad = state_variables.clone().detach().requires_grad_(True)
            stress_value = self.evaluate(state_vars_req_grad, design_variables)
            stress_tensor = torch.tensor(stress_value, requires_grad=True)
            gradient = torch.autograd.grad(stress_tensor, state_vars_req_grad, 
                                         create_graph=False, retain_graph=False)[0]
            return gradient
        else:
            # æ•°å€¼å¾®åˆ†è¿‘ä¼¼ï¼ˆç®€åŒ–å®ç°ï¼‰
            n_dofs = len(state_variables)
            gradient = np.zeros(n_dofs)
            eps = 1e-8
            
            f0 = self.evaluate(state_variables, design_variables)
            for i in range(n_dofs):
                state_pert = state_variables.copy()
                state_pert[i] += eps
                f1 = self.evaluate(state_pert, design_variables)
                gradient[i] = (f1 - f0) / eps
            
            return gradient
    
    def design_derivative(self, state_variables: Union[np.ndarray, torch.Tensor],
                         design_variables: Dict[str, float]) -> Dict[str, float]:
        """åº”åŠ›å‡½æ•°å¯¹è®¾è®¡å˜é‡çš„ç›´æ¥åå¯¼æ•°"""
        return {var_name: 0.0 for var_name in design_variables}

class ResidualOperator(ABC):
    """æ®‹å·®ç®—å­æŠ½è±¡åŸºç±» R(u, Î±) = 0"""
    
    @abstractmethod
    def evaluate(self, state_variables: Union[np.ndarray, torch.Tensor],
                 design_variables: Dict[str, float]) -> Union[np.ndarray, torch.Tensor]:
        """è®¡ç®—æ®‹å·® R(u, Î±)"""
        pass
    
    @abstractmethod
    def state_jacobian(self, state_variables: Union[np.ndarray, torch.Tensor],
                      design_variables: Dict[str, float]) -> Union[np.ndarray, torch.Tensor]:
        """çŠ¶æ€é›…å¯æ¯”çŸ©é˜µ âˆ‚R/âˆ‚u"""
        pass
    
    @abstractmethod
    def design_jacobian(self, state_variables: Union[np.ndarray, torch.Tensor],
                       design_variables: Dict[str, float]) -> Dict[str, Union[np.ndarray, torch.Tensor]]:
        """è®¾è®¡é›…å¯æ¯”çŸ©é˜µ âˆ‚R/âˆ‚Î±"""
        pass

class StructuralMechanicsResidual(ResidualOperator):
    """ç»“æ„åŠ›å­¦æ®‹å·®ç®—å­ K(Î±)u - F = 0"""
    
    def __init__(self, element_data: Dict, material_data: Dict):
        self.element_data = element_data
        self.material_data = material_data
        self.stiffness_matrix_base = self._build_base_stiffness_matrix()
        self.force_vector = self._build_force_vector()
    
    def _build_base_stiffness_matrix(self):
        """æ„å»ºåŸºç¡€åˆšåº¦çŸ©é˜µ"""
        n_dofs = self.element_data.get('n_dofs', 300)
        
        if TORCH_AVAILABLE:
            # åˆ›å»ºå¯¹ç§°æ­£å®šçŸ©é˜µ
            A = torch.randn(n_dofs, n_dofs, device=device)
            K_base = torch.matmul(A, A.T) + torch.eye(n_dofs, device=device) * 100
            return K_base
        else:
            A = np.random.randn(n_dofs, n_dofs)
            K_base = np.dot(A, A.T) + np.eye(n_dofs) * 100
            return K_base
    
    def _build_force_vector(self):
        """æ„å»ºè½½è·å‘é‡"""
        n_dofs = self.element_data.get('n_dofs', 300)
        
        if TORCH_AVAILABLE:
            return torch.randn(n_dofs, device=device) * 1000
        else:
            return np.random.randn(n_dofs) * 1000
    
    def evaluate(self, state_variables: Union[np.ndarray, torch.Tensor],
                 design_variables: Dict[str, float]) -> Union[np.ndarray, torch.Tensor]:
        """è®¡ç®—æ®‹å·® R = K(Î±)u - F"""
        stiffness_matrix = self._assemble_stiffness_matrix(design_variables)
        
        if TORCH_AVAILABLE and isinstance(state_variables, torch.Tensor):
            return torch.matmul(stiffness_matrix, state_variables) - self.force_vector
        else:
            return np.dot(stiffness_matrix, state_variables) - self.force_vector
    
    def state_jacobian(self, state_variables: Union[np.ndarray, torch.Tensor],
                      design_variables: Dict[str, float]) -> Union[np.ndarray, torch.Tensor]:
        """çŠ¶æ€é›…å¯æ¯”çŸ©é˜µ âˆ‚R/âˆ‚u = K(Î±)"""
        return self._assemble_stiffness_matrix(design_variables)
    
    def design_jacobian(self, state_variables: Union[np.ndarray, torch.Tensor],
                       design_variables: Dict[str, float]) -> Dict[str, Union[np.ndarray, torch.Tensor]]:
        """è®¾è®¡é›…å¯æ¯”çŸ©é˜µ âˆ‚R/âˆ‚Î± = âˆ‚K/âˆ‚Î± * u"""
        jacobians = {}
        
        for var_name in design_variables:
            stiffness_derivative = self._compute_stiffness_derivative(var_name, design_variables)
            
            if TORCH_AVAILABLE and isinstance(state_variables, torch.Tensor):
                jacobians[var_name] = torch.matmul(stiffness_derivative, state_variables)
            else:
                jacobians[var_name] = np.dot(stiffness_derivative, state_variables)
        
        return jacobians
    
    def _assemble_stiffness_matrix(self, design_variables: Dict[str, float]):
        """ç»„è£…åˆšåº¦çŸ©é˜µ K(Î±)"""
        # ç®€åŒ–å®ç°ï¼šK = E * K_baseï¼Œå…¶ä¸­Eä¸ºå¼¹æ€§æ¨¡é‡
        elastic_modulus = design_variables.get('elastic_modulus', 200e9)
        scaling_factor = elastic_modulus / 200e9  # å½’ä¸€åŒ–
        
        return self.stiffness_matrix_base * scaling_factor
    
    def _compute_stiffness_derivative(self, var_name: str, design_variables: Dict[str, float]):
        """è®¡ç®—åˆšåº¦çŸ©é˜µå¯¹è®¾è®¡å˜é‡çš„å¯¼æ•°"""
        if var_name == 'elastic_modulus':
            return self.stiffness_matrix_base / 200e9
        elif var_name == 'thickness':
            # åšåº¦å¯¹åˆšåº¦çš„å½±å“ï¼ˆç®€åŒ–ï¼‰
            return self.stiffness_matrix_base * 0.1
        else:
            # å…¶ä»–å˜é‡ï¼ˆé›¶å¯¼æ•°ï¼‰
            if TORCH_AVAILABLE:
                return torch.zeros_like(self.stiffness_matrix_base)
            else:
                return np.zeros_like(self.stiffness_matrix_base)

class AdjointSensitivitySolver:
    """ä¼´éšæ–¹æ³•çµæ•åº¦æ±‚è§£å™¨"""
    
    def __init__(self, residual_operator: ResidualOperator,
                 sensitivity_function: SensitivityFunction):
        """
        åˆå§‹åŒ–ä¼´éšçµæ•åº¦æ±‚è§£å™¨
        
        Args:
            residual_operator: æ®‹å·®ç®—å­
            sensitivity_function: ç›®æ ‡/çº¦æŸå‡½æ•°
        """
        self.residual_operator = residual_operator
        self.sensitivity_function = sensitivity_function
        self.logger = logging.getLogger(__name__)
        
        # æ±‚è§£å‚æ•°
        self.linear_solver_tolerance = 1e-8
        self.max_linear_iterations = 1000
        self.use_gpu = TORCH_AVAILABLE and torch.cuda.is_available()
        
        # æ€§èƒ½ç»Ÿè®¡
        self.solve_times = []
        self.system_info = None
    
    async def compute_sensitivities(self, state_variables: Union[np.ndarray, torch.Tensor],
                                  design_variables: Dict[str, float]) -> Dict[str, SensitivityResult]:
        """
        è®¡ç®—æ‰€æœ‰è®¾è®¡å˜é‡çš„çµæ•åº¦
        
        Args:
            state_variables: çŠ¶æ€å˜é‡ï¼ˆä½ç§»ç­‰ï¼‰
            design_variables: è®¾è®¡å˜é‡å­—å…¸
            
        Returns:
            çµæ•åº¦ç»“æœå­—å…¸
        """
        start_time = time.time()
        self.logger.info("å¼€å§‹ä¼´éšçµæ•åº¦è®¡ç®—...")
        
        # 1. è®¡ç®—ç›®æ ‡/çº¦æŸå‡½æ•°å¯¹çŠ¶æ€å˜é‡çš„åå¯¼æ•°
        dJ_du = self.sensitivity_function.state_derivative(state_variables, design_variables)
        
        # 2. ç»„è£…ä¼´éšç³»ç»Ÿå¹¶æ±‚è§£ä¼´éšå˜é‡
        adjoint_variables = await self._solve_adjoint_system(dJ_du, state_variables, design_variables)
        
        # 3. è®¡ç®—æ‰€æœ‰è®¾è®¡å˜é‡çš„çµæ•åº¦
        sensitivity_results = {}
        
        # å¹¶è¡Œè®¡ç®—å„è®¾è®¡å˜é‡çš„çµæ•åº¦
        tasks = []
        for var_name in design_variables:
            task = self._compute_single_sensitivity(
                var_name, adjoint_variables, state_variables, design_variables
            )
            tasks.append((var_name, task))
        
        # ç­‰å¾…æ‰€æœ‰çµæ•åº¦è®¡ç®—å®Œæˆ
        for var_name, task in tasks:
            sensitivity_result = await task
            sensitivity_results[var_name] = sensitivity_result
        
        total_time = time.time() - start_time
        self.solve_times.append(total_time)
        
        self.logger.info(f"ä¼´éšçµæ•åº¦è®¡ç®—å®Œæˆï¼Œè€—æ—¶: {total_time:.4f}ç§’")
        return sensitivity_results
    
    async def _solve_adjoint_system(self, dJ_du: Union[np.ndarray, torch.Tensor],
                                  state_variables: Union[np.ndarray, torch.Tensor],
                                  design_variables: Dict[str, float]) -> Union[np.ndarray, torch.Tensor]:
        """
        æ±‚è§£ä¼´éšç³»ç»Ÿ: [âˆ‚R/âˆ‚u]^T Î» = âˆ‚J/âˆ‚u
        
        Args:
            dJ_du: ç›®æ ‡å‡½æ•°å¯¹çŠ¶æ€å˜é‡çš„åå¯¼æ•°
            state_variables: å½“å‰çŠ¶æ€å˜é‡
            design_variables: è®¾è®¡å˜é‡
            
        Returns:
            ä¼´éšå˜é‡ Î»
        """
        # è·å–çŠ¶æ€é›…å¯æ¯”çŸ©é˜µï¼ˆåˆšåº¦çŸ©é˜µï¼‰
        state_jacobian = self.residual_operator.state_jacobian(state_variables, design_variables)
        
        if TORCH_AVAILABLE and isinstance(state_jacobian, torch.Tensor):
            # PyTorch GPUæ±‚è§£
            adjoint_rhs = dJ_du.to(device)
            state_jacobian_T = state_jacobian.T.to(device)
            
            # ä½¿ç”¨Choleskyåˆ†è§£æ±‚è§£ï¼ˆå‡è®¾ç³»ç»Ÿå¯¹ç§°æ­£å®šï¼‰
            try:
                L = torch.linalg.cholesky(state_jacobian_T)
                y = torch.linalg.solve_triangular(L, adjoint_rhs, upper=False)
                adjoint_variables = torch.linalg.solve_triangular(L.T, y, upper=True)
            except RuntimeError:
                # å›é€€åˆ°LUåˆ†è§£
                adjoint_variables = torch.linalg.solve(state_jacobian_T, adjoint_rhs)
            
            # ç³»ç»Ÿä¿¡æ¯ç»Ÿè®¡
            condition_number = torch.linalg.cond(state_jacobian_T).item()
            
        else:
            # NumPy CPUæ±‚è§£
            state_jacobian_T = state_jacobian.T
            
            # ä½¿ç”¨ç¨€ç–æ±‚è§£å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            try:
                from scipy.sparse.linalg import spsolve
                from scipy.sparse import csc_matrix
                
                sparse_jacobian = csc_matrix(state_jacobian_T)
                adjoint_variables = spsolve(sparse_jacobian, dJ_du)
            except ImportError:
                # å›é€€åˆ°NumPyæ±‚è§£
                adjoint_variables = np.linalg.solve(state_jacobian_T, dJ_du)
            
            # ç³»ç»Ÿä¿¡æ¯ç»Ÿè®¡
            condition_number = np.linalg.cond(state_jacobian_T)
        
        # è®°å½•ç³»ç»Ÿä¿¡æ¯
        self.system_info = AdjointSystemInfo(
            system_size=len(adjoint_variables),
            condition_number=condition_number,
            solver_type="direct",
            iterations=1,
            residual_norm=0.0  # ç›´æ¥æ±‚è§£çš„æ®‹å·®ä¸º0
        )
        
        return adjoint_variables
    
    async def _compute_single_sensitivity(self, var_name: str,
                                        adjoint_variables: Union[np.ndarray, torch.Tensor],
                                        state_variables: Union[np.ndarray, torch.Tensor],
                                        design_variables: Dict[str, float]) -> SensitivityResult:
        """
        è®¡ç®—å•ä¸ªè®¾è®¡å˜é‡çš„çµæ•åº¦
        
        Args:
            var_name: è®¾è®¡å˜é‡åç§°
            adjoint_variables: ä¼´éšå˜é‡
            state_variables: çŠ¶æ€å˜é‡
            design_variables: è®¾è®¡å˜é‡å­—å…¸
            
        Returns:
            è¯¥å˜é‡çš„çµæ•åº¦ç»“æœ
        """
        start_time = time.time()
        
        # 1. è®¡ç®— âˆ‚J/âˆ‚Î±ï¼ˆç›®æ ‡å‡½æ•°å¯¹è®¾è®¡å˜é‡çš„ç›´æ¥åå¯¼æ•°ï¼‰
        direct_derivatives = self.sensitivity_function.design_derivative(state_variables, design_variables)
        dJ_dalpha = direct_derivatives.get(var_name, 0.0)
        
        # 2. è®¡ç®— Î»^T * âˆ‚R/âˆ‚Î±ï¼ˆä¼´éšé¡¹ï¼‰
        design_jacobians = self.residual_operator.design_jacobian(state_variables, design_variables)
        dR_dalpha = design_jacobians.get(var_name)
        
        if dR_dalpha is not None:
            if TORCH_AVAILABLE and isinstance(adjoint_variables, torch.Tensor):
                adjoint_term = torch.dot(adjoint_variables, dR_dalpha).item()
            else:
                adjoint_term = np.dot(adjoint_variables, dR_dalpha)
        else:
            adjoint_term = 0.0
        
        # 3. æ€»çµæ•åº¦ = âˆ‚J/âˆ‚Î± + Î»^T * âˆ‚R/âˆ‚Î±
        total_sensitivity = dJ_dalpha + adjoint_term
        
        # 4. è®¡ç®—æ¢¯åº¦èŒƒæ•°ï¼ˆç”¨äºæ”¶æ•›åˆ¤æ–­ï¼‰
        if isinstance(adjoint_variables, torch.Tensor):
            gradient_norm = torch.norm(adjoint_variables).item()
        else:
            gradient_norm = np.linalg.norm(adjoint_variables)
        
        computation_time = time.time() - start_time
        
        return SensitivityResult(
            design_variable=var_name,
            sensitivity_value=total_sensitivity,
            gradient_norm=gradient_norm,
            computation_time=computation_time,
            converged=True  # ç›´æ¥æ±‚è§£æ€»æ˜¯æ”¶æ•›
        )
    
    def get_system_info(self) -> Optional[AdjointSystemInfo]:
        """è·å–ä¼´éšç³»ç»Ÿä¿¡æ¯"""
        return self.system_info
    
    def get_performance_stats(self) -> Dict:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        if not self.solve_times:
            return {}
        
        return {
            "total_solves": len(self.solve_times),
            "average_time": np.mean(self.solve_times),
            "min_time": np.min(self.solve_times),
            "max_time": np.max(self.solve_times),
            "std_time": np.std(self.solve_times),
            "use_gpu": self.use_gpu
        }
    
    def export_sensitivity_data(self, filename: str, sensitivity_results: Dict[str, SensitivityResult]):
        """å¯¼å‡ºçµæ•åº¦æ•°æ®"""
        export_data = {
            "sensitivity_results": {},
            "system_info": self.system_info.__dict__ if self.system_info else {},
            "performance_stats": self.get_performance_stats(),
            "solver_config": {
                "linear_solver_tolerance": self.linear_solver_tolerance,
                "max_linear_iterations": self.max_linear_iterations,
                "use_gpu": self.use_gpu
            }
        }
        
        for var_name, result in sensitivity_results.items():
            export_data["sensitivity_results"][var_name] = {
                "sensitivity_value": result.sensitivity_value,
                "gradient_norm": result.gradient_norm,
                "computation_time": result.computation_time,
                "converged": result.converged
            }
        
        import json
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"çµæ•åº¦æ•°æ®å·²å¯¼å‡ºè‡³: {filename}")

# æ·±åŸºå‘å·¥ç¨‹ä¸“ç”¨ä¼´éšæ±‚è§£å™¨
class DeepExcavationAdjointSolver:
    """æ·±åŸºå‘å·¥ç¨‹ä¼´éšçµæ•åº¦åˆ†æå™¨"""
    
    def __init__(self, excavation_parameters: Dict):
        """
        åˆå§‹åŒ–æ·±åŸºå‘ä¼´éšæ±‚è§£å™¨
        
        Args:
            excavation_parameters: åŸºå‘å·¥ç¨‹å‚æ•°
        """
        self.excavation_params = excavation_parameters
        self.logger = logging.getLogger(__name__)
        
        # åˆ›å»ºæ®‹å·®ç®—å­å’Œç›®æ ‡å‡½æ•°
        self.residual_operator = self._create_residual_operator()
        self.objective_functions = self._create_objective_functions()
        self.constraint_functions = self._create_constraint_functions()
        
        # ä¼´éšæ±‚è§£å™¨å­—å…¸
        self.adjoint_solvers = {}
        self._initialize_adjoint_solvers()
    
    def _create_residual_operator(self) -> StructuralMechanicsResidual:
        """åˆ›å»ºç»“æ„åŠ›å­¦æ®‹å·®ç®—å­"""
        element_data = {
            'n_elements': self.excavation_params.get('n_elements', 1000),
            'n_dofs': self.excavation_params.get('n_dofs', 3000)
        }
        
        material_data = {
            'elastic_modulus': self.excavation_params.get('soil_elastic_modulus', 30e6),
            'poisson_ratio': self.excavation_params.get('soil_poisson_ratio', 0.3)
        }
        
        return StructuralMechanicsResidual(element_data, material_data)
    
    def _create_objective_functions(self) -> Dict[str, SensitivityFunction]:
        """åˆ›å»ºç›®æ ‡å‡½æ•°"""
        objectives = {}
        
        # æŸ”åº¦æœ€å°åŒ–ï¼ˆå˜å½¢æœ€å°åŒ–ï¼‰
        compliance_func = ComplianceFunction()
        objectives['compliance'] = compliance_func
        
        # æœ€å¤§åº”åŠ›æœ€å°åŒ–
        element_data = {
            'n_elements': self.excavation_params.get('n_elements', 1000),
            'n_dofs': self.excavation_params.get('n_dofs', 3000)
        }
        stress_func = VonMisesStressFunction(element_data)
        objectives['max_stress'] = stress_func
        
        return objectives
    
    def _create_constraint_functions(self) -> Dict[str, SensitivityFunction]:
        """åˆ›å»ºçº¦æŸå‡½æ•°"""
        constraints = {}
        
        # åº”åŠ›çº¦æŸ
        element_data = {
            'n_elements': self.excavation_params.get('n_elements', 1000),
            'n_dofs': self.excavation_params.get('n_dofs', 3000)
        }
        stress_constraint = VonMisesStressFunction(element_data)
        constraints['stress_limit'] = stress_constraint
        
        return constraints
    
    def _initialize_adjoint_solvers(self):
        """åˆå§‹åŒ–ä¼´éšæ±‚è§£å™¨"""
        # ä¸ºæ¯ä¸ªç›®æ ‡å‡½æ•°åˆ›å»ºä¼´éšæ±‚è§£å™¨
        for name, objective in self.objective_functions.items():
            solver = AdjointSensitivitySolver(self.residual_operator, objective)
            self.adjoint_solvers[f"objective_{name}"] = solver
        
        # ä¸ºæ¯ä¸ªçº¦æŸå‡½æ•°åˆ›å»ºä¼´éšæ±‚è§£å™¨
        for name, constraint in self.constraint_functions.items():
            solver = AdjointSensitivitySolver(self.residual_operator, constraint)
            self.adjoint_solvers[f"constraint_{name}"] = solver
    
    async def compute_all_sensitivities(self, state_variables: Union[np.ndarray, torch.Tensor],
                                      design_variables: Dict[str, float]) -> Dict[str, Dict[str, SensitivityResult]]:
        """
        è®¡ç®—æ‰€æœ‰ç›®æ ‡å‡½æ•°å’Œçº¦æŸå‡½æ•°çš„çµæ•åº¦
        
        Args:
            state_variables: çŠ¶æ€å˜é‡
            design_variables: è®¾è®¡å˜é‡
            
        Returns:
            å®Œæ•´çš„çµæ•åº¦ç»“æœ
        """
        all_sensitivities = {}
        
        # å¹¶è¡Œè®¡ç®—æ‰€æœ‰ä¼´éšæ±‚è§£
        tasks = []
        for solver_name, solver in self.adjoint_solvers.items():
            task = solver.compute_sensitivities(state_variables, design_variables)
            tasks.append((solver_name, task))
        
        # ç­‰å¾…æ‰€æœ‰è®¡ç®—å®Œæˆ
        for solver_name, task in tasks:
            sensitivities = await task
            all_sensitivities[solver_name] = sensitivities
        
        return all_sensitivities
    
    def export_complete_sensitivity_analysis(self, filename: str,
                                           all_sensitivities: Dict[str, Dict[str, SensitivityResult]]):
        """å¯¼å‡ºå®Œæ•´çš„çµæ•åº¦åˆ†æç»“æœ"""
        export_data = {
            "excavation_parameters": self.excavation_params,
            "sensitivity_analysis": {},
            "summary": {
                "total_functions": len(self.adjoint_solvers),
                "total_design_variables": 0,
                "gpu_acceleration": TORCH_AVAILABLE and torch.cuda.is_available()
            }
        }
        
        for function_name, sensitivities in all_sensitivities.items():
            export_data["sensitivity_analysis"][function_name] = {}
            
            for var_name, result in sensitivities.items():
                export_data["sensitivity_analysis"][function_name][var_name] = {
                    "sensitivity": result.sensitivity_value,
                    "gradient_norm": result.gradient_norm,
                    "computation_time": result.computation_time,
                    "converged": result.converged
                }
                
                export_data["summary"]["total_design_variables"] = len(sensitivities)
        
        import json
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"å®Œæ•´çµæ•åº¦åˆ†æç»“æœå·²å¯¼å‡ºè‡³: {filename}")

if __name__ == "__main__":
    # æµ‹è¯•ç¤ºä¾‹
    async def test_adjoint_sensitivity():
        """ä¼´éšçµæ•åº¦åˆ†ææµ‹è¯•"""
        print("ğŸ”¬ DeepCADä¼´éšçµæ•åº¦åˆ†ææµ‹è¯• ğŸ”¬")
        
        # æ·±åŸºå‘å·¥ç¨‹å‚æ•°
        excavation_params = {
            'n_elements': 500,
            'n_dofs': 1500,
            'excavation_depth': 8.0,
            'excavation_width': 20.0,
            'soil_elastic_modulus': 30e6,
            'soil_poisson_ratio': 0.3
        }
        
        # åˆ›å»ºæ·±åŸºå‘ä¼´éšæ±‚è§£å™¨
        deep_solver = DeepExcavationAdjointSolver(excavation_params)
        
        # æ¨¡æ‹ŸçŠ¶æ€å˜é‡å’Œè®¾è®¡å˜é‡
        n_dofs = excavation_params['n_dofs']
        if TORCH_AVAILABLE:
            state_variables = torch.randn(n_dofs, device=device) * 0.01  # ä½ç§»ï¼ˆç±³ï¼‰
        else:
            state_variables = np.random.randn(n_dofs) * 0.01
        
        design_variables = {
            'elastic_modulus': 30e6,
            'thickness': 0.5,
            'support_stiffness': 1e8,
            'excavation_sequence': 5.0
        }
        
        # è®¡ç®—æ‰€æœ‰çµæ•åº¦
        all_sensitivities = await deep_solver.compute_all_sensitivities(
            state_variables, design_variables
        )
        
        # è¾“å‡ºç»“æœ
        print("\nğŸ“Š çµæ•åº¦åˆ†æç»“æœ:")
        for function_name, sensitivities in all_sensitivities.items():
            print(f"\n{function_name}:")
            for var_name, result in sensitivities.items():
                print(f"  {var_name}: {result.sensitivity_value:.6e} "
                      f"(æ—¶é—´: {result.computation_time:.4f}s)")
        
        # å¯¼å‡ºç»“æœ
        deep_solver.export_complete_sensitivity_analysis(
            "deep_excavation_sensitivities.json", all_sensitivities
        )
        
        print("\nâœ… ä¼´éšçµæ•åº¦åˆ†æå®Œæˆï¼")
    
    # è¿è¡Œæµ‹è¯•
    asyncio.run(test_adjoint_sensitivity())
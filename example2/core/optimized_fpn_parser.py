#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–çš„FPNæ–‡ä»¶è§£æå™¨
ä¸“é—¨å¤„ç†å¤§å‹MIDAS GTS NX FPNæ–‡ä»¶ï¼Œæ”¯æŒæµå¼å¤„ç†å’Œå†…å­˜ä¼˜åŒ–
"""

import os
import numpy as np
from pathlib import Path
from typing import Dict, Any, Iterator, Tuple, Optional
from dataclasses import dataclass
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class ParseProgress:
    """è§£æè¿›åº¦ä¿¡æ¯"""
    total_lines: int = 0
    processed_lines: int = 0
    nodes_count: int = 0
    elements_count: int = 0
    current_section: str = ""
    
    @property
    def progress_percent(self) -> float:
        if self.total_lines == 0:
            return 0.0
        return (self.processed_lines / self.total_lines) * 100


class OptimizedFPNParser:
    """ä¼˜åŒ–çš„FPNæ–‡ä»¶è§£æå™¨"""
    
    def __init__(self, progress_callback=None):
        """
        åˆå§‹åŒ–è§£æå™¨
        
        Args:
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶ParseProgresså¯¹è±¡
        """
        self.progress_callback = progress_callback
        self.coordinate_offset = None
        self.encoding_used = None
        
        # æ”¯æŒçš„ç¼–ç åˆ—è¡¨ - ä¸­æ–‡FPNæ–‡ä»¶é€šå¸¸ä½¿ç”¨GBKç¼–ç 
        self.encodings = ['gbk', 'gb2312', 'utf-8', 'latin1', 'cp1252']
        
        # æ•°æ®ç¼“å­˜
        self.nodes_cache = {}
        self.elements_cache = {}
        
    def detect_file_encoding(self, file_path: str) -> str:
        """æ£€æµ‹æ–‡ä»¶ç¼–ç ï¼Œç‰¹åˆ«å¤„ç†ä¸­æ–‡å­—ç¬¦"""
        # å…ˆå°è¯•è¯»å–æ–‡ä»¶çš„BOMæ ‡è®°
        with open(file_path, 'rb') as f:
            raw_data = f.read(3)
            if raw_data.startswith(b'\xef\xbb\xbf'):
                logger.info("æ£€æµ‹åˆ°UTF-8 BOMï¼Œä½¿ç”¨UTF-8ç¼–ç ")
                return 'utf-8'
        
        # æµ‹è¯•å„ç§ç¼–ç 
        for encoding in self.encodings:
            try:
                with open(file_path, 'r', encoding=encoding, errors='strict') as f:
                    # è¯»å–å‰1000è¡Œè¿›è¡Œç¼–ç æ£€æµ‹
                    chinese_chars_found = 0
                    for i, line in enumerate(f):
                        if i > 1000:
                            break
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦
                        for char in line:
                            if '\u4e00' <= char <= '\u9fff':  # ä¸­æ–‡å­—ç¬¦èŒƒå›´
                                chinese_chars_found += 1
                                
                    # å¦‚æœæ‰¾åˆ°ä¸­æ–‡å­—ç¬¦ä¸”ä½¿ç”¨GBK/GB2312æˆåŠŸè¯»å–ï¼Œä¼˜å…ˆä½¿ç”¨
                    if chinese_chars_found > 0 and encoding in ['gbk', 'gb2312']:
                        logger.info(f"æ£€æµ‹åˆ°ä¸­æ–‡å­—ç¬¦ï¼Œä½¿ç”¨ç¼–ç : {encoding}")
                        return encoding
                    elif chinese_chars_found == 0:  # æ²¡æœ‰ä¸­æ–‡å­—ç¬¦ï¼Œç¬¬ä¸€ä¸ªæˆåŠŸçš„ç¼–ç å³å¯
                        logger.info(f"æ£€æµ‹åˆ°æ–‡ä»¶ç¼–ç : {encoding}")
                        return encoding
                
            except (UnicodeDecodeError, UnicodeEncodeError) as e:
                logger.debug(f"ç¼–ç  {encoding} æµ‹è¯•å¤±è´¥: {e}")
                continue
                
        # å¦‚æœéƒ½å¤±è´¥ï¼Œä½¿ç”¨gbkä½œä¸ºfallbackï¼ˆå¯¹ä¸­æ–‡FPNæ–‡ä»¶æœ€å¯èƒ½ï¼‰
        logger.warning("æ— æ³•æ£€æµ‹æ–‡ä»¶ç¼–ç ï¼Œä½¿ç”¨gbkä½œä¸ºfallback")
        return 'gbk'
    
    def count_file_lines(self, file_path: str, encoding: str) -> int:
        """å¿«é€Ÿç»Ÿè®¡æ–‡ä»¶è¡Œæ•°"""
        try:
            with open(file_path, 'r', encoding=encoding) as f:
                return sum(1 for _ in f)
        except Exception as e:
            logger.error(f"ç»Ÿè®¡æ–‡ä»¶è¡Œæ•°å¤±è´¥: {e}")
            return 0
    
    def calculate_coordinate_offset(self, file_path: str, encoding: str) -> Tuple[float, float, float]:
        """
        è®¡ç®—åæ ‡åç§»é‡ï¼Œå°†å¤§åæ ‡å€¼ç§»åˆ°åŸç‚¹é™„è¿‘
        åªæ‰«æå‰1000ä¸ªèŠ‚ç‚¹æ¥è®¡ç®—åç§»é‡
        """
        min_coords = [float('inf'), float('inf'), float('inf')]
        node_count = 0
        
        try:
            with open(file_path, 'r', encoding=encoding) as f:
                for line in f:
                    line = line.strip()
                    if not line or line.startswith('$$'):
                        continue
                        
                    if line.startswith('NODE'):
                        try:
                            parts = [p.strip() for p in line.split(',')]
                            if len(parts) >= 5:
                                x = float(parts[2])
                                y = float(parts[3])
                                z = float(parts[4])
                                
                                min_coords[0] = min(min_coords[0], x)
                                min_coords[1] = min(min_coords[1], y)
                                min_coords[2] = min(min_coords[2], z)
                                
                                node_count += 1
                                if node_count >= 1000:  # åªæ‰«æå‰1000ä¸ªèŠ‚ç‚¹
                                    break
                                    
                        except (ValueError, IndexError):
                            continue
                            
        except Exception as e:
            logger.error(f"è®¡ç®—åæ ‡åç§»é‡å¤±è´¥: {e}")
            return (0.0, 0.0, 0.0)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆèŠ‚ç‚¹ï¼Œè¿”å›é›¶åç§»
        if node_count == 0:
            return (0.0, 0.0, 0.0)
            
        offset = tuple(min_coords)
        logger.info(f"è®¡ç®—åæ ‡åç§»é‡: {offset}, åŸºäº{node_count}ä¸ªèŠ‚ç‚¹")
        return offset
    
    def parse_node_line(self, line: str) -> Optional[Dict[str, Any]]:
        """è§£æèŠ‚ç‚¹è¡Œ"""
        try:
            parts = [p.strip() for p in line.split(',')]
            if len(parts) < 5:
                return None
                
            node_id = int(parts[1])
            x = float(parts[2]) - self.coordinate_offset[0]
            y = float(parts[3]) - self.coordinate_offset[1]
            z = float(parts[4]) - self.coordinate_offset[2]
            
            return {
                'id': node_id,
                'x': x,
                'y': y,
                'z': z
            }
            
        except (ValueError, IndexError) as e:
            logger.debug(f"è§£æèŠ‚ç‚¹è¡Œå¤±è´¥: {line[:50]}... - {e}")
            return None
    
    def parse_element_line(self, line: str) -> Optional[Dict[str, Any]]:
        """ğŸ”§ ä¿®å¤2ï¼šè§£æå•å…ƒè¡Œå¹¶éªŒè¯æ•°æ®ç»“æ„"""
        try:
            parts = [p.strip() for p in line.split(',')]
            if len(parts) < 3:
                logger.warning(f"å•å…ƒè¡Œæ•°æ®ä¸è¶³: {line[:50]}...")
                return None
                
            # éªŒè¯åŸºæœ¬å­—æ®µ
            try:
                element_id = int(parts[1])
                if element_id <= 0:
                    logger.warning(f"æ— æ•ˆçš„å•å…ƒID: {element_id}")
                    return None
            except (ValueError, IndexError):
                logger.warning(f"æ— æ³•è§£æå•å…ƒID: {parts}")
                return None
            
            # ğŸ”§ ç¡®ä¿è¿”å›å­—å…¸æ ¼å¼ï¼Œå¹¶éªŒè¯æ‰€æœ‰å­—æ®µ
            if parts[0] == 'TETRA' and len(parts) >= 7:
                try:
                    material_id = int(parts[2])
                    nodes = [int(parts[i]) for i in range(3, 7)]
                    
                    # éªŒè¯èŠ‚ç‚¹ID
                    if any(node_id <= 0 for node_id in nodes):
                        logger.warning(f"TETRAå•å…ƒ{element_id}åŒ…å«æ— æ•ˆèŠ‚ç‚¹ID: {nodes}")
                        return None
                    
                    element_data = {
                        'id': element_id,
                        'type': 'tetra',
                        'material_id': material_id,
                        'nodes': nodes
                    }
                    
                    # æœ€ç»ˆéªŒè¯ï¼šç¡®ä¿è¿”å›çš„æ˜¯å­—å…¸ä¸”åŒ…å«å¿…è¦å­—æ®µ
                    if not isinstance(element_data, dict):
                        logger.error(f"element_dataä¸æ˜¯å­—å…¸ç±»å‹: {type(element_data)}")
                        return None
                    
                    required_fields = ['id', 'type', 'material_id', 'nodes']
                    for field in required_fields:
                        if field not in element_data:
                            logger.error(f"ç¼ºå°‘å¿…è¦å­—æ®µ{field}: {element_data}")
                            return None
                    
                    return element_data
                    
                except ValueError as e:
                    logger.warning(f"TETRAå•å…ƒæ•°æ®è§£æé”™è¯¯: {e}")
                    return None
                    
            elif parts[0] == 'HEXA' and len(parts) >= 10:
                try:
                    material_id = int(parts[2])
                    nodes = [int(parts[i]) for i in range(3, 11)]
                    
                    if any(node_id <= 0 for node_id in nodes):
                        logger.warning(f"HEXAå•å…ƒ{element_id}åŒ…å«æ— æ•ˆèŠ‚ç‚¹ID: {nodes}")
                        return None
                    
                    element_data = {
                        'id': element_id,
                        'type': 'hexa',
                        'material_id': material_id,
                        'nodes': nodes
                    }
                    
                    # éªŒè¯è¿”å›æ•°æ®
                    if not isinstance(element_data, dict) or not all(field in element_data for field in ['id', 'type', 'material_id', 'nodes']):
                        logger.error(f"HEXAå•å…ƒæ•°æ®ç»“æ„é”™è¯¯: {element_data}")
                        return None
                    
                    return element_data
                    
                except ValueError as e:
                    logger.warning(f"HEXAå•å…ƒæ•°æ®è§£æé”™è¯¯: {e}")
                    return None
                    
            elif parts[0] == 'PENTA' and len(parts) >= 9:
                try:
                    material_id = int(parts[2])
                    nodes = [int(parts[i]) for i in range(3, 9)]
                    
                    if any(node_id <= 0 for node_id in nodes):
                        logger.warning(f"PENTAå•å…ƒ{element_id}åŒ…å«æ— æ•ˆèŠ‚ç‚¹ID: {nodes}")
                        return None
                    
                    element_data = {
                        'id': element_id,
                        'type': 'penta', 
                        'material_id': material_id,
                        'nodes': nodes
                    }
                    
                    # éªŒè¯è¿”å›æ•°æ®
                    if not isinstance(element_data, dict) or not all(field in element_data for field in ['id', 'type', 'material_id', 'nodes']):
                        logger.error(f"PENTAå•å…ƒæ•°æ®ç»“æ„é”™è¯¯: {element_data}")
                        return None
                    
                    return element_data
                    
                except ValueError as e:
                    logger.warning(f"PENTAå•å…ƒæ•°æ®è§£æé”™è¯¯: {e}")
                    return None
            else:
                logger.debug(f"ä¸æ”¯æŒçš„å•å…ƒç±»å‹æˆ–æ•°æ®ä¸è¶³: {parts[0]} (é•¿åº¦: {len(parts)})")
                
        except Exception as e:
            logger.error(f"è§£æå•å…ƒè¡Œæ—¶å‘ç”Ÿå¼‚å¸¸: {line[:50]}... - {e}")
            
        return None
    
    def parse_file_streaming(self, file_path: str) -> Dict[str, Any]:
        """
        æµå¼è§£æFPNæ–‡ä»¶
        é€è¡Œå¤„ç†ï¼Œé¿å…å†…å­˜æº¢å‡º
        """
        # æ£€æµ‹ç¼–ç 
        encoding = self.detect_file_encoding(file_path)
        self.encoding_used = encoding
        
        # ç»Ÿè®¡æ€»è¡Œæ•°
        total_lines = self.count_file_lines(file_path, encoding)
        
        # è®¡ç®—åæ ‡åç§»
        self.coordinate_offset = self.calculate_coordinate_offset(file_path, encoding)
        
        # åˆå§‹åŒ–è¿›åº¦
        progress = ParseProgress(total_lines=total_lines)
        
        # è§£æç»“æœ
        result = {
            'nodes': {},
            'elements': {},
            'material_groups': {},
            'loads': {},
            'stages': {},
            'stage_data': {},
            'analysis_stages': {},
            'metadata': {
                'encoding': encoding,
                'coordinate_offset': self.coordinate_offset,
                'total_lines': total_lines
            }
        }
        
        current_section = "unknown"
        
        try:
            with open(file_path, 'r', encoding=encoding) as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    
                    # æ›´æ–°è¿›åº¦
                    progress.processed_lines = line_num
                    progress.current_section = current_section
                    
                    # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Š
                    if not line or line.startswith('$$'):
                        continue
                    
                    # è¯†åˆ«æ•°æ®æ®µ
                    if line.startswith('NODE'):
                        current_section = "nodes"
                        node_data = self.parse_node_line(line)
                        if node_data:
                            result['nodes'][node_data['id']] = node_data
                            progress.nodes_count += 1
                            
                    elif line.startswith(('TETRA', 'HEXA', 'PENTA')):
                        current_section = "elements"
                        element_data = self.parse_element_line(line)
                        if element_data:
                            result['elements'][element_data['id']] = element_data
                            progress.elements_count += 1
                    
                    # è§£æåˆ†ææ­¥ç›¸å…³æ•°æ®
                    elif line.startswith('STGSET'):
                        current_section = "stage_sets"
                        stage_set_data = self.parse_stage_set_line(line)
                        if stage_set_data:
                            result['stage_data'][stage_set_data['id']] = stage_set_data
                            
                    elif line.startswith('STAGE'):
                        current_section = "stages"
                        stage_data = self.parse_stage_line(line) 
                        if stage_data:
                            result['stages'][stage_data['id']] = stage_data
                            
                    elif line.startswith('ANALSTAG'):
                        current_section = "analysis_stages"
                        anal_stage_data = self.parse_analysis_stage_line(line)
                        if anal_stage_data:
                            result['analysis_stages'][anal_stage_data['id']] = anal_stage_data
                            
                    elif line.startswith(('MADD', 'LADD', 'BADD', 'MDEL', 'LDEL', 'BDEL')):
                        # è§£æé˜¶æ®µæ“ä½œå‘½ä»¤
                        stage_op_data = self.parse_stage_operation_line(line)
                        if stage_op_data:
                            # å°†æ“ä½œæ·»åŠ åˆ°å¯¹åº”çš„é˜¶æ®µ
                            stage_id = stage_op_data['stage_id']
                            if stage_id not in result['stage_data']:
                                result['stage_data'][stage_id] = {'operations': []}
                            elif 'operations' not in result['stage_data'][stage_id]:
                                result['stage_data'][stage_id]['operations'] = []
                            result['stage_data'][stage_id]['operations'].append(stage_op_data)
                    
                    # å®šæœŸè°ƒç”¨è¿›åº¦å›è°ƒ
                    if self.progress_callback and line_num % 1000 == 0:
                        self.progress_callback(progress)
                        
        except Exception as e:
            logger.error(f"è§£ææ–‡ä»¶æ—¶å‡ºé”™: {e}")
            raise
        
        # æœ€ç»ˆè¿›åº¦å›è°ƒ
        if self.progress_callback:
            progress.processed_lines = total_lines
            self.progress_callback(progress)
        
        # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼ä»¥å…¼å®¹ç°æœ‰ä»£ç 
        result['nodes'] = list(result['nodes'].values())
        result['elements'] = list(result['elements'].values())
        
        # ğŸ”§ ä¿®å¤åˆ†ææ­¥ï¼šè½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
        result['analysis_stages'] = list(result['analysis_stages'].values())
        result['stages'] = list(result['stages'].values())
        
        logger.info(f"è§£æå®Œæˆ: {len(result['nodes'])}ä¸ªèŠ‚ç‚¹, {len(result['elements'])}ä¸ªå•å…ƒ, "
                   f"{len(result['analysis_stages'])}ä¸ªåˆ†æé˜¶æ®µ")
        
        return result
    
    def parse_stage_set_line(self, line: str) -> Optional[Dict[str, Any]]:
        """è§£æSTGSETè¡Œ - é˜¶æ®µé›†åˆå®šä¹‰"""
        try:
            parts = [p.strip() for p in line.split(',')]
            if len(parts) < 4:
                return None
                
            return {
                'id': int(parts[1]),
                'type': int(parts[2]),
                'name': parts[3].strip('"\''),
                'raw_line': line
            }
        except (ValueError, IndexError) as e:
            logger.warning(f"è§£æSTGSETè¡Œå¤±è´¥: {line} - {e}")
            return None
    
    def parse_stage_line(self, line: str) -> Optional[Dict[str, Any]]:
        """è§£æSTAGEè¡Œ - å•ä¸ªåˆ†æé˜¶æ®µå®šä¹‰"""
        try:
            parts = [p.strip() for p in line.split(',')]
            if len(parts) < 4:
                return None
                
            return {
                'id': int(parts[1]),
                'type': int(parts[2]),
                'name': parts[3].strip('"\''),
                'active': int(parts[4]) if len(parts) > 4 and parts[4].strip() else 1,
                'raw_line': line
            }
        except (ValueError, IndexError) as e:
            logger.warning(f"è§£æSTAGEè¡Œå¤±è´¥: {line} - {e}")
            return None
    
    def parse_analysis_stage_line(self, line: str) -> Optional[Dict[str, Any]]:
        """è§£æANALSTAGè¡Œ - åˆ†æé˜¶æ®µè®¾ç½®"""
        try:
            parts = [p.strip() for p in line.split(',')]
            if len(parts) < 4:
                return None
                
            return {
                'id': int(parts[1]),
                'name': parts[2].strip('"\''),
                'start_stage': int(parts[3]) if parts[3].strip() else 1,
                'end_stage': int(parts[4]) if len(parts) > 4 and parts[4].strip() else 1,
                'raw_line': line
            }
        except (ValueError, IndexError) as e:
            logger.warning(f"è§£æANALSTAGè¡Œå¤±è´¥: {line} - {e}")
            return None
    
    def parse_stage_operation_line(self, line: str) -> Optional[Dict[str, Any]]:
        """è§£æé˜¶æ®µæ“ä½œè¡Œ - MADD, LADD, BADD, MDELç­‰"""
        try:
            parts = [p.strip() for p in line.split(',')]
            if len(parts) < 3:
                return None
                
            operation = parts[0].strip()
            stage_id = int(parts[1])
            count = int(parts[2]) if parts[2].strip() else 0
            
            # æå–IDåˆ—è¡¨
            ids = []
            for part in parts[3:]:
                if part.strip() and part.strip() != '':
                    try:
                        ids.append(int(part))
                    except ValueError:
                        continue
            
            return {
                'operation': operation,
                'stage_id': stage_id,
                'count': count,
                'ids': ids,
                'raw_line': line
            }
        except (ValueError, IndexError) as e:
            logger.warning(f"è§£æé˜¶æ®µæ“ä½œè¡Œå¤±è´¥: {line} - {e}")
            return None


def create_progress_callback():
    """åˆ›å»ºè¿›åº¦å›è°ƒå‡½æ•°ç¤ºä¾‹"""
    def progress_callback(progress: ParseProgress):
        print(f"\rè§£æè¿›åº¦: {progress.progress_percent:.1f}% "
              f"({progress.processed_lines}/{progress.total_lines}) "
              f"èŠ‚ç‚¹:{progress.nodes_count} å•å…ƒ:{progress.elements_count} "
              f"å½“å‰æ®µ:{progress.current_section}", end='', flush=True)
    
    return progress_callback


# æµ‹è¯•å‡½æ•°
if __name__ == "__main__":
    # æµ‹è¯•ä¼˜åŒ–è§£æå™¨
    fpn_file = Path(__file__).parent.parent / "data" / "åŸºå‘ä¸¤é˜¶æ®µ1fpn.fpn"
    
    if fpn_file.exists():
        print(f"æµ‹è¯•è§£ææ–‡ä»¶: {fpn_file}")
        
        parser = OptimizedFPNParser(progress_callback=create_progress_callback())
        
        try:
            result = parser.parse_file_streaming(str(fpn_file))
            print(f"\nè§£ææˆåŠŸ!")
            print(f"èŠ‚ç‚¹æ•°é‡: {len(result['nodes'])}")
            print(f"å•å…ƒæ•°é‡: {len(result['elements'])}")
            print(f"åˆ†æé˜¶æ®µæ•°é‡: {len(result['stages'])}")
            print(f"ä½¿ç”¨ç¼–ç : {result['metadata']['encoding']}")
            print(f"åæ ‡åç§»: {result['metadata']['coordinate_offset']}")
            
        except Exception as e:
            print(f"\nè§£æå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    else:
        print(f"æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {fpn_file}")

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ›å»ºåŒ…å«æ‰€æœ‰ææ–™çš„å®Œæ•´MDPAæ–‡ä»¶
"""

import sys
import json
from pathlib import Path

def analyze_fpn_elements():
    """åˆ†æFPNæ–‡ä»¶ä¸­çš„å•å…ƒåˆ†å¸ƒ"""
    print("ğŸ” åˆ†æFPNæ–‡ä»¶ä¸­çš„å•å…ƒåˆ†å¸ƒ...")
    
    sys.path.insert(0, 'example2')
    from core.optimized_fpn_parser import OptimizedFPNParser
    
    fpn_file = Path('example2/data/ä¸¤é˜¶æ®µ-å…¨é”šæ†-æ‘©å°”åº“ä¼¦.fpn')
    parser = OptimizedFPNParser()
    fpn_data = parser.parse_file_streaming(str(fpn_file))
    
    elements = fpn_data.get('elements', {})
    print(f"æ€»å•å…ƒæ•°: {len(elements):,}")

    # ç»Ÿè®¡æ¯ç§ææ–™çš„å•å…ƒæ•°é‡
    material_counts = {}
    material_elements = {}

    # å¤„ç†ä¸åŒçš„æ•°æ®ç»“æ„
    if isinstance(elements, dict):
        # å­—å…¸æ ¼å¼
        for elem_id, elem_data in elements.items():
            mat_id = elem_data.get('material_id', 0)
            if mat_id not in material_counts:
                material_counts[mat_id] = 0
                material_elements[mat_id] = []
            material_counts[mat_id] += 1
            material_elements[mat_id].append(elem_id)
    elif isinstance(elements, list):
        # åˆ—è¡¨æ ¼å¼
        for i, elem_data in enumerate(elements):
            elem_id = elem_data.get('id', i+1)
            mat_id = elem_data.get('material_id', 0)
            if mat_id not in material_counts:
                material_counts[mat_id] = 0
                material_elements[mat_id] = []
            material_counts[mat_id] += 1
            material_elements[mat_id].append(elem_id)
    
    print("\nğŸ“Š ææ–™å•å…ƒåˆ†å¸ƒ:")
    materials = fpn_data.get('materials', {})
    for mat_id in sorted(material_counts.keys()):
        count = material_counts[mat_id]
        mat_name = materials.get(mat_id, {}).get('name', f'Material_{mat_id}')
        print(f"  ææ–™{mat_id} ({mat_name}): {count:,}ä¸ªå•å…ƒ")
        
        # æ˜¾ç¤ºå‰å‡ ä¸ªå•å…ƒID
        sample_elements = material_elements[mat_id][:5]
        print(f"    ç¤ºä¾‹å•å…ƒ: {sample_elements}")
    
    return fpn_data, material_elements

def create_complete_mdpa_file():
    """åˆ›å»ºåŒ…å«æ‰€æœ‰ææ–™çš„å®Œæ•´MDPAæ–‡ä»¶"""
    print("\nğŸ”§ åˆ›å»ºå®Œæ•´MDPAæ–‡ä»¶...")
    
    # 1. åˆ†æFPNæ•°æ®
    fpn_data, material_elements = analyze_fpn_elements()
    
    # 2. è¯»å–ç°æœ‰MDPAæ–‡ä»¶ä½œä¸ºåŸºç¡€
    source_mdpa = Path("multi_stage_kratos_conversion/stage_1/stage_1_analysis.mdpa")
    if not source_mdpa.exists():
        print("âŒ æºMDPAæ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    print(f"ğŸ“– è¯»å–æºMDPAæ–‡ä»¶: {source_mdpa}")
    with open(source_mdpa, 'r', encoding='utf-8') as f:
        mdpa_content = f.read()
    
    # 3. åˆ†æç°æœ‰MDPAæ–‡ä»¶ç»“æ„
    lines = mdpa_content.split('\n')
    
    # æ‰¾åˆ°Elementséƒ¨åˆ†çš„ç»“æŸä½ç½®
    elements_end_idx = -1
    for i, line in enumerate(lines):
        if line.strip() == "End Elements":
            elements_end_idx = i
            break
    
    if elements_end_idx == -1:
        print("âŒ æœªæ‰¾åˆ°Elementsç»“æŸæ ‡è®°")
        return False
    
    # 4. åˆ›å»ºæ–°çš„MDPAå†…å®¹
    new_lines = lines[:elements_end_idx + 1]  # ä¿ç•™åˆ°Elementsç»“æŸ
    
    # 5. æ·»åŠ ç¼ºå¤±çš„ææ–™å­æ¨¡å‹éƒ¨åˆ†
    missing_materials = [1, 13]  # C30æ··å‡åœŸå’Œé”šæ†
    
    elements = fpn_data.get('elements', {})
    nodes = fpn_data.get('nodes', {})
    
    for mat_id in missing_materials:
        if mat_id not in material_elements:
            print(f"âš ï¸ ææ–™{mat_id}åœ¨FPNä¸­æ²¡æœ‰å¯¹åº”å•å…ƒ")
            continue
            
        mat_elements = material_elements[mat_id]
        print(f"ğŸ“ æ·»åŠ ææ–™{mat_id}å­æ¨¡å‹éƒ¨åˆ†ï¼ŒåŒ…å«{len(mat_elements)}ä¸ªå•å…ƒ")
        
        # æ·»åŠ å­æ¨¡å‹éƒ¨åˆ†å¤´éƒ¨
        new_lines.append("")
        new_lines.append(f"Begin SubModelPart MAT_{mat_id}")
        new_lines.append("  Begin SubModelPartNodes")
        
        # æ”¶é›†è¯¥ææ–™æ‰€æœ‰å•å…ƒçš„èŠ‚ç‚¹
        mat_nodes = set()
        for elem_id in mat_elements:
            if isinstance(elements, dict):
                elem_data = elements.get(elem_id, {})
            else:
                # åˆ—è¡¨æ ¼å¼ï¼Œéœ€è¦æ‰¾åˆ°å¯¹åº”çš„å…ƒç´ 
                elem_data = {}
                for elem in elements:
                    if elem.get('id', 0) == elem_id:
                        elem_data = elem
                        break
            elem_nodes = elem_data.get('nodes', [])
            mat_nodes.update(elem_nodes)
        
        # æ·»åŠ èŠ‚ç‚¹ï¼ˆæ¯è¡Œ8ä¸ªï¼‰
        mat_nodes_list = sorted(mat_nodes)
        for i in range(0, len(mat_nodes_list), 8):
            batch = mat_nodes_list[i:i+8]
            new_lines.append("    " + " ".join(map(str, batch)))
        
        new_lines.append("  End SubModelPartNodes")
        new_lines.append("  Begin SubModelPartElements")
        
        # æ·»åŠ å•å…ƒï¼ˆæ¯è¡Œ8ä¸ªï¼‰
        for i in range(0, len(mat_elements), 8):
            batch = mat_elements[i:i+8]
            new_lines.append("    " + " ".join(map(str, batch)))
        
        new_lines.append("  End SubModelPartElements")
        new_lines.append("End SubModelPart")
    
    # 6. æ·»åŠ å‰©ä½™çš„åŸå§‹å†…å®¹ï¼ˆä»ç¬¬ä¸€ä¸ªSubModelPartå¼€å§‹ï¼‰
    submodel_start_idx = -1
    for i, line in enumerate(lines):
        if line.strip().startswith("Begin SubModelPart"):
            submodel_start_idx = i
            break
    
    if submodel_start_idx != -1:
        new_lines.extend(lines[submodel_start_idx:])
    
    # 7. ä¿å­˜æ–°çš„MDPAæ–‡ä»¶
    output_file = Path("complete_fpn_model_with_all_materials.mdpa")
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write('\n'.join(new_lines))
    
    print(f"âœ… å®Œæ•´MDPAæ–‡ä»¶å·²åˆ›å»º: {output_file}")
    print(f"   æ€»è¡Œæ•°: {len(new_lines):,}")
    
    return True

if __name__ == "__main__":
    success = create_complete_mdpa_file()
    if success:
        print("\nğŸ¯ å®Œæ•´MDPAæ–‡ä»¶åˆ›å»ºæˆåŠŸï¼")
    else:
        print("\nâŒ å®Œæ•´MDPAæ–‡ä»¶åˆ›å»ºå¤±è´¥ï¼")

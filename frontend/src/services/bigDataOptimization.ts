/**
 * å¤§æ•°æ®å¤„ç†ä¼˜åŒ–æ¨¡å—
 * 3å·è®¡ç®—ä¸“å®¶ç¬¬4å‘¨å¤§æ•°æ®ä¼˜åŒ–ä»»åŠ¡
 */

// å¤§æ•°æ®å¤„ç†é…ç½®
export interface BigDataConfig {
  // æ•°æ®åˆ†å—é…ç½®
  chunking: {
    enabled: boolean;
    chunkSize: number; // å•ä¸ªå—çš„å¤§å°(MB)
    overlapSize: number; // å—é—´é‡å å¤§å°
    adaptiveChunking: boolean; // è‡ªé€‚åº”åˆ†å—
    compressionLevel: number; // å‹ç¼©çº§åˆ« 0-9
  };
  
  // å†…å­˜ç®¡ç†é…ç½®
  memory: {
    maxMemoryUsage: number; // æœ€å¤§å†…å­˜ä½¿ç”¨(MB)
    enableMemoryPool: boolean;
    garbageCollectionThreshold: number; // GCè§¦å‘é˜ˆå€¼
    enableStreaming: boolean; // æµå¼å¤„ç†
    bufferSize: number; // ç¼“å†²åŒºå¤§å°
  };
  
  // å¹¶è¡Œå¤„ç†é…ç½®
  parallel: {
    enableWorkers: boolean;
    maxWorkers: number;
    workerChunkSize: number;
    enableSharedArrayBuffer: boolean;
    loadBalancing: 'static' | 'dynamic' | 'work_stealing';
  };
  
  // å­˜å‚¨ä¼˜åŒ–é…ç½®
  storage: {
    enableIndexing: boolean;
    indexType: 'btree' | 'hash' | 'spatial';
    enableCompression: boolean;
    compressionFormat: 'gzip' | 'lz4' | 'brotli';
    enableCaching: boolean;
    cacheStrategy: 'lru' | 'lfu' | 'arc';
  };
  
  // ç½‘æ ¼å¤„ç†é…ç½®
  mesh: {
    enableLOD: boolean; // Level of Detail
    lodLevels: number;
    lodThresholds: number[];
    enableCulling: boolean; // è£å‰ª
    cullingDistance: number;
    enableInstancing: boolean; // å®ä¾‹åŒ–
  };
}

// æ•°æ®å—æ¥å£
export interface DataChunk {
  id: string;
  offset: number;
  size: number;
  data: Float32Array | Uint32Array;
  metadata: {
    bounds: [number, number, number, number, number, number]; // min/max xyz
    elementCount: number;
    dataType: 'scalar' | 'vector' | 'tensor';
    compressed: boolean;
    compressionRatio?: number;
  };
  dependencies: string[]; // ä¾èµ–çš„å…¶ä»–å—
}

// å¤§æ•°æ®å¤„ç†ç»Ÿè®¡
export interface BigDataStats {
  totalDataSize: number; // æ€»æ•°æ®å¤§å°(MB)
  chunksCount: number;
  memoryUsage: {
    current: number;
    peak: number;
    available: number;
  };
  processing: {
    totalTime: number;
    chunkingTime: number;
    processingTime: number;
    mergeTime: number;
  };
  compression: {
    originalSize: number;
    compressedSize: number;
    ratio: number;
  };
  cache: {
    hits: number;
    misses: number;
    hitRate: number;
  };
}

// ç©ºé—´ç´¢å¼•æ¥å£
export interface SpatialIndex {
  insert(bounds: number[], data: any): void;
  query(bounds: number[]): any[];
  remove(bounds: number[]): boolean;
  clear(): void;
  getStats(): { nodes: number; depth: number; items: number };
}

export class BigDataProcessor {
  private config: BigDataConfig;
  private chunks: Map<string, DataChunk> = new Map();
  private spatialIndex: SpatialIndex | null = null;
  private workers: Worker[] = [];
  private memoryPool: ArrayBuffer[] = [];
  private cache: Map<string, { data: any; timestamp: number; hits: number }> = new Map();
  
  // ç»Ÿè®¡ä¿¡æ¯
  private stats: BigDataStats = {
    totalDataSize: 0,
    chunksCount: 0,
    memoryUsage: { current: 0, peak: 0, available: 0 },
    processing: { totalTime: 0, chunkingTime: 0, processingTime: 0, mergeTime: 0 },
    compression: { originalSize: 0, compressedSize: 0, ratio: 1.0 },
    cache: { hits: 0, misses: 0, hitRate: 0 }
  };

  constructor(config?: Partial<BigDataConfig>) {
    this.config = this.mergeConfig(config);
    console.log('ğŸ“Š å¤§æ•°æ®å¤„ç†å™¨åˆ›å»ºä¸­...');
    this.initialize();
  }

  /**
   * åˆå§‹åŒ–å¤§æ•°æ®å¤„ç†ç³»ç»Ÿ
   */
  private async initialize(): Promise<void> {
    console.log('âš¡ åˆå§‹åŒ–å¤§æ•°æ®å¤„ç†ç³»ç»Ÿ...');
    
    // åˆå§‹åŒ–ç©ºé—´ç´¢å¼•
    if (this.config.storage.enableIndexing) {
      this.spatialIndex = this.createSpatialIndex(this.config.storage.indexType);
      console.log(`ğŸ—‚ï¸ ç©ºé—´ç´¢å¼•åˆå§‹åŒ–: ${this.config.storage.indexType}`);
    }
    
    // åˆå§‹åŒ–Web Workers
    if (this.config.parallel.enableWorkers) {
      await this.initializeWorkers();
      console.log(`ğŸ‘¥ Web Workersåˆå§‹åŒ–: ${this.workers.length}ä¸ªworker`);
    }
    
    // åˆå§‹åŒ–å†…å­˜æ± 
    if (this.config.memory.enableMemoryPool) {
      this.initializeMemoryPool();
      console.log(`ğŸ’¾ å†…å­˜æ± åˆå§‹åŒ–: ${this.memoryPool.length}ä¸ªç¼“å†²åŒº`);
    }
    
    // ç›‘æ§å†…å­˜ä½¿ç”¨
    this.startMemoryMonitoring();
    
    console.log('âœ… å¤§æ•°æ®å¤„ç†ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ');
  }

  /**
   * å¤„ç†å¤§è§„æ¨¡ç½‘æ ¼æ•°æ®
   */
  async processLargeMesh(
    vertices: Float32Array,
    faces: Uint32Array,
    fieldData?: Map<string, Float32Array>,
    onProgress?: (progress: number, stage: string) => void
  ): Promise<{
    success: boolean;
    processedChunks: DataChunk[];
    stats: BigDataStats;
    lodLevels?: Map<number, { vertices: Float32Array; faces: Uint32Array }>;
  }> {
    
    console.log(`ğŸ“Š å¼€å§‹å¤„ç†å¤§è§„æ¨¡ç½‘æ ¼æ•°æ®...`);
    console.log(`   é¡¶ç‚¹æ•°: ${vertices.length / 3}`);
    console.log(`   é¢æ•°: ${faces.length / 3}`);
    console.log(`   åœºæ•°æ®: ${fieldData?.size || 0}ä¸ªå­—æ®µ`);
    
    const startTime = performance.now();
    
    try {
      // 1. æ•°æ®åˆ†å—
      if (onProgress) onProgress(10, 'æ•°æ®åˆ†å—ä¸­...');
      const chunkingStartTime = performance.now();
      
      const meshChunks = await this.chunkMeshData(vertices, faces, fieldData);
      
      this.stats.chunkingTime = performance.now() - chunkingStartTime;
      this.stats.chunksCount = meshChunks.length;
      
      console.log(`âœ… æ•°æ®åˆ†å—å®Œæˆ: ${meshChunks.length}ä¸ªå—`);
      
      // 2. å¹¶è¡Œå¤„ç†å—
      if (onProgress) onProgress(30, 'å¹¶è¡Œå¤„ç†ä¸­...');
      const processingStartTime = performance.now();
      
      const processedChunks = await this.processChunksInParallel(
        meshChunks,
        (chunkProgress) => {
          if (onProgress) onProgress(30 + chunkProgress * 0.5, 'å¤„ç†æ•°æ®å—...');
        }
      );
      
      this.stats.processingTime = performance.now() - processingStartTime;
      
      // 3. ç”ŸæˆLODçº§åˆ«
      let lodLevels: Map<number, { vertices: Float32Array; faces: Uint32Array }> | undefined;
      
      if (this.config.mesh.enableLOD) {
        if (onProgress) onProgress(80, 'ç”ŸæˆLODçº§åˆ«...');
        lodLevels = await this.generateLODLevels(vertices, faces);
        console.log(`âœ… ç”ŸæˆLODçº§åˆ«: ${lodLevels.size}ä¸ªçº§åˆ«`);
      }
      
      // 4. æ„å»ºç©ºé—´ç´¢å¼•
      if (this.spatialIndex) {
        if (onProgress) onProgress(90, 'æ„å»ºç©ºé—´ç´¢å¼•...');
        this.buildSpatialIndex(processedChunks);
        console.log(`âœ… ç©ºé—´ç´¢å¼•æ„å»ºå®Œæˆ`);
      }
      
      // 5. å†…å­˜ä¼˜åŒ–
      if (onProgress) onProgress(95, 'å†…å­˜ä¼˜åŒ–...');
      await this.optimizeMemoryUsage();
      
      this.stats.totalTime = performance.now() - startTime;
      
      if (onProgress) onProgress(100, 'å¤„ç†å®Œæˆ');
      
      console.log(`ğŸ‰ å¤§è§„æ¨¡ç½‘æ ¼å¤„ç†å®Œæˆ: ${this.stats.totalTime.toFixed(2)}ms`);
      
      return {
        success: true,
        processedChunks,
        stats: { ...this.stats },
        lodLevels
      };
      
    } catch (error) {
      console.error('âŒ å¤§è§„æ¨¡ç½‘æ ¼å¤„ç†å¤±è´¥:', error);
      return {
        success: false,
        processedChunks: [],
        stats: { ...this.stats }
      };
    }
  }

  /**
   * æµå¼æ•°æ®å¤„ç†
   */
  async *processStreamingData(
    dataStream: AsyncIterable<Float32Array>,
    chunkSize: number = 1000
  ): AsyncGenerator<{
    chunkId: string;
    processedData: Float32Array;
    progress: number;
  }> {
    
    console.log('ğŸŒŠ å¼€å§‹æµå¼æ•°æ®å¤„ç†...');
    
    let chunkIndex = 0;
    let buffer = new Float32Array(0);
    let totalProcessed = 0;
    
    for await (const dataChunk of dataStream) {
      // åˆå¹¶åˆ°ç¼“å†²åŒº
      const newBuffer = new Float32Array(buffer.length + dataChunk.length);
      newBuffer.set(buffer);
      newBuffer.set(dataChunk, buffer.length);
      buffer = newBuffer;
      
      // å¤„ç†å®Œæ•´çš„å—
      while (buffer.length >= chunkSize) {
        const chunk = buffer.slice(0, chunkSize);
        buffer = buffer.slice(chunkSize);
        
        // å¤„ç†å½“å‰å—
        const processedChunk = await this.processDataChunk(chunk, `stream_${chunkIndex}`);
        
        totalProcessed += chunkSize;
        chunkIndex++;
        
        yield {
          chunkId: processedChunk.id,
          processedData: processedChunk.data as Float32Array,
          progress: totalProcessed
        };
        
        // å†…å­˜ç®¡ç†
        if (chunkIndex % 10 === 0) {
          await this.performGarbageCollection();
        }
      }
    }
    
    // å¤„ç†å‰©ä½™æ•°æ®
    if (buffer.length > 0) {
      const processedChunk = await this.processDataChunk(buffer, `stream_${chunkIndex}_final`);
      
      yield {
        chunkId: processedChunk.id,
        processedData: processedChunk.data as Float32Array,
        progress: totalProcessed + buffer.length
      };
    }
    
    console.log(`âœ… æµå¼å¤„ç†å®Œæˆ: ${chunkIndex + 1}ä¸ªå—`);
  }

  /**
   * ç½‘æ ¼æ•°æ®åˆ†å—
   */
  private async chunkMeshData(
    vertices: Float32Array,
    faces: Uint32Array,
    fieldData?: Map<string, Float32Array>
  ): Promise<DataChunk[]> {
    
    const chunks: DataChunk[] = [];
    const vertexCount = vertices.length / 3;
    const faceCount = faces.length / 3;
    
    // è®¡ç®—åˆ†å—å‚æ•°
    const bytesPerVertex = 3 * 4; // xyz * 4 bytes
    const targetChunkSizeBytes = this.config.chunking.chunkSize * 1024 * 1024;
    const verticesPerChunk = Math.floor(targetChunkSizeBytes / bytesPerVertex);
    
    console.log(`ğŸ“Š åˆ†å—å‚æ•°: æ¯å—${verticesPerChunk}ä¸ªé¡¶ç‚¹`);
    
    // ç©ºé—´åˆ†å—ç­–ç•¥
    if (this.config.chunking.adaptiveChunking) {
      return this.adaptiveChunking(vertices, faces, fieldData);
    }
    
    // çº¿æ€§åˆ†å—
    for (let startVertex = 0; startVertex < vertexCount; startVertex += verticesPerChunk) {
      const endVertex = Math.min(startVertex + verticesPerChunk, vertexCount);
      const chunkVertices = vertices.slice(startVertex * 3, endVertex * 3);
      
      // æŸ¥æ‰¾ç›¸å…³çš„é¢
      const chunkFaces = this.extractRelevantFaces(faces, startVertex, endVertex);
      
      // åˆ›å»ºæ•°æ®å—
      const chunk: DataChunk = {
        id: `chunk_${chunks.length}`,
        offset: startVertex,
        size: chunkVertices.length + chunkFaces.length,
        data: this.combineMeshData(chunkVertices, chunkFaces),
        metadata: {
          bounds: this.calculateBounds(chunkVertices),
          elementCount: (endVertex - startVertex),
          dataType: 'vector',
          compressed: false
        },
        dependencies: []
      };
      
      // å‹ç¼©æ•°æ®å—
      if (this.config.chunking.compressionLevel > 0) {
        chunk.data = await this.compressData(chunk.data);
        chunk.metadata.compressed = true;
      }
      
      chunks.push(chunk);
      this.chunks.set(chunk.id, chunk);
    }
    
    return chunks;
  }

  /**
   * è‡ªé€‚åº”åˆ†å—
   */
  private async adaptiveChunking(
    vertices: Float32Array,
    faces: Uint32Array,
    fieldData?: Map<string, Float32Array>
  ): Promise<DataChunk[]> {
    
    console.log('ğŸ§  ä½¿ç”¨è‡ªé€‚åº”åˆ†å—ç­–ç•¥...');
    
    // åˆ†ææ•°æ®å¯†åº¦
    const densityMap = this.analyzeMeshDensity(vertices, faces);
    
    // åŸºäºå¯†åº¦çš„åˆ†å—
    const chunks: DataChunk[] = [];
    const processedVertices = new Set<number>();
    
    for (let i = 0; i < vertices.length / 3; i++) {
      if (processedVertices.has(i)) continue;
      
      const density = densityMap[i];
      const chunkSize = this.calculateAdaptiveChunkSize(density);
      
      // æ”¶é›†é‚»è¿‘é¡¶ç‚¹
      const chunkVertexIndices = this.collectNearbyVertices(i, vertices, chunkSize);
      
      // æ ‡è®°ä¸ºå·²å¤„ç†
      chunkVertexIndices.forEach(idx => processedVertices.add(idx));
      
      // æå–é¡¶ç‚¹å’Œé¢æ•°æ®
      const chunkVertices = this.extractVerticesByIndices(vertices, chunkVertexIndices);
      const chunkFaces = this.extractFacesByVertices(faces, chunkVertexIndices);
      
      // åˆ›å»ºè‡ªé€‚åº”æ•°æ®å—
      const chunk: DataChunk = {
        id: `adaptive_chunk_${chunks.length}`,
        offset: Math.min(...chunkVertexIndices),
        size: chunkVertices.length + chunkFaces.length,
        data: this.combineMeshData(chunkVertices, chunkFaces),
        metadata: {
          bounds: this.calculateBounds(chunkVertices),
          elementCount: chunkVertexIndices.length,
          dataType: 'vector',
          compressed: false
        },
        dependencies: []
      };
      
      chunks.push(chunk);
    }
    
    console.log(`âœ… è‡ªé€‚åº”åˆ†å—å®Œæˆ: ${chunks.length}ä¸ªå—`);
    return chunks;
  }

  /**
   * å¹¶è¡Œå¤„ç†æ•°æ®å—
   */
  private async processChunksInParallel(
    chunks: DataChunk[],
    onProgress?: (progress: number) => void
  ): Promise<DataChunk[]> {
    
    console.log(`âš¡ å¹¶è¡Œå¤„ç†${chunks.length}ä¸ªæ•°æ®å—...`);
    
    if (this.workers.length === 0) {
      // æ— Workerï¼Œä¸²è¡Œå¤„ç†
      return this.processChunksSequentially(chunks, onProgress);
    }
    
    // å·¥ä½œè´Ÿè½½å‡è¡¡
    const workerChunks = this.distributeChunksToWorkers(chunks);
    const processedChunks: DataChunk[] = [];
    let completedWorkers = 0;
    
    const workerPromises = workerChunks.map(async (chunkGroup, workerIndex) => {
      const worker = this.workers[workerIndex];
      
      for (const chunk of chunkGroup) {
        const result = await this.processChunkWithWorker(worker, chunk);
        processedChunks.push(result);
        
        if (onProgress) {
          onProgress((processedChunks.length / chunks.length) * 100);
        }
      }
      
      completedWorkers++;
      console.log(`âœ… Worker ${workerIndex} å®Œæˆå¤„ç†`);
    });
    
    await Promise.all(workerPromises);
    
    console.log(`ğŸ‰ å¹¶è¡Œå¤„ç†å®Œæˆ: ${processedChunks.length}ä¸ªå—`);
    return processedChunks;
  }

  /**
   * ç”ŸæˆLODçº§åˆ«
   */
  private async generateLODLevels(
    vertices: Float32Array,
    faces: Uint32Array
  ): Promise<Map<number, { vertices: Float32Array; faces: Uint32Array }>> {
    
    console.log('ğŸ” ç”ŸæˆLODçº§åˆ«...');
    
    const lodLevels = new Map();
    const originalVertexCount = vertices.length / 3;
    
    for (let level = 0; level < this.config.mesh.lodLevels; level++) {
      const reductionRatio = Math.pow(0.5, level + 1); // æ¯çº§å‡å°‘50%
      const targetVertexCount = Math.floor(originalVertexCount * reductionRatio);
      
      if (targetVertexCount < 100) break; // æœ€å°é¡¶ç‚¹æ•°é™åˆ¶
      
      console.log(`   LOD${level}: ${targetVertexCount}ä¸ªé¡¶ç‚¹ (${(reductionRatio * 100).toFixed(1)}%)`);
      
      // ç½‘æ ¼ç®€åŒ–ç®—æ³•
      const simplifiedMesh = await this.simplifyMesh(vertices, faces, reductionRatio);
      
      lodLevels.set(level, simplifiedMesh);
    }
    
    return lodLevels;
  }

  /**
   * ç½‘æ ¼ç®€åŒ–
   */
  private async simplifyMesh(
    vertices: Float32Array,
    faces: Uint32Array,
    reductionRatio: number
  ): Promise<{ vertices: Float32Array; faces: Uint32Array }> {
    
    // ç®€åŒ–çš„è¾¹åç¼©ç®—æ³•
    const targetVertexCount = Math.floor(vertices.length / 3 * reductionRatio);
    
    // è®¡ç®—è¾¹çš„é‡è¦æ€§
    const edges = this.extractEdges(faces);
    const edgeImportance = this.calculateEdgeImportance(vertices, edges);
    
    // æŒ‰é‡è¦æ€§æ’åº
    const sortedEdges = edges.sort((a, b) => edgeImportance[a.id] - edgeImportance[b.id]);
    
    // æ‰§è¡Œè¾¹åç¼©
    let simplifiedVertices = new Float32Array(vertices);
    let simplifiedFaces = new Uint32Array(faces);
    let currentVertexCount = vertices.length / 3;
    
    for (const edge of sortedEdges) {
      if (currentVertexCount <= targetVertexCount) break;
      
      // åç¼©è¾¹
      const result = this.collapseEdge(simplifiedVertices, simplifiedFaces, edge);
      if (result) {
        simplifiedVertices = result.vertices;
        simplifiedFaces = result.faces;
        currentVertexCount--;
      }
    }
    
    return {
      vertices: simplifiedVertices,
      faces: simplifiedFaces
    };
  }

  /**
   * æ„å»ºç©ºé—´ç´¢å¼•
   */
  private buildSpatialIndex(chunks: DataChunk[]): void {
    if (!this.spatialIndex) return;
    
    console.log('ğŸ—‚ï¸ æ„å»ºç©ºé—´ç´¢å¼•...');
    
    for (const chunk of chunks) {
      this.spatialIndex.insert(chunk.metadata.bounds, {
        chunkId: chunk.id,
        elementCount: chunk.metadata.elementCount
      });
    }
    
    const indexStats = this.spatialIndex.getStats();
    console.log(`âœ… ç©ºé—´ç´¢å¼•æ„å»ºå®Œæˆ: ${indexStats.items}ä¸ªæ¡ç›®, æ·±åº¦${indexStats.depth}`);
  }

  /**
   * æŸ¥è¯¢ç©ºé—´èŒƒå›´å†…çš„æ•°æ®
   */
  queryByBounds(bounds: number[]): DataChunk[] {
    if (!this.spatialIndex) {
      console.warn('âš ï¸ ç©ºé—´ç´¢å¼•æœªå¯ç”¨');
      return Array.from(this.chunks.values());
    }
    
    const results = this.spatialIndex.query(bounds);
    return results.map(result => this.chunks.get(result.chunkId)).filter(Boolean) as DataChunk[];
  }

  /**
   * å†…å­˜ä¼˜åŒ–
   */
  private async optimizeMemoryUsage(): Promise<void> {
    console.log('ğŸ’¾ æ‰§è¡Œå†…å­˜ä¼˜åŒ–...');
    
    // 1. åƒåœ¾å›æ”¶
    await this.performGarbageCollection();
    
    // 2. ç¼“å­˜æ¸…ç†
    this.cleanupCache();
    
    // 3. å†…å­˜ç¢ç‰‡æ•´ç†
    if (this.config.memory.enableMemoryPool) {
      this.defragmentMemoryPool();
    }
    
    // 4. æ›´æ–°å†…å­˜ç»Ÿè®¡
    this.updateMemoryStats();
    
    console.log(`âœ… å†…å­˜ä¼˜åŒ–å®Œæˆ: å½“å‰ä½¿ç”¨${this.stats.memoryUsage.current.toFixed(2)}MB`);
  }

  /**
   * è·å–å¤„ç†ç»Ÿè®¡
   */
  getStats(): BigDataStats {
    this.updateMemoryStats();
    this.updateCacheStats();
    return { ...this.stats };
  }

  /**
   * è·å–ä¼˜åŒ–å»ºè®®
   */
  getOptimizationSuggestions(): string[] {
    const suggestions: string[] = [];
    const stats = this.getStats();
    
    if (stats.memoryUsage.current > this.config.memory.maxMemoryUsage * 0.8) {
      suggestions.push('ğŸ’¾ å†…å­˜ä½¿ç”¨ç‡è¾ƒé«˜ï¼Œè€ƒè™‘å‡å°å—å¤§å°æˆ–å¯ç”¨å‹ç¼©');
    }
    
    if (stats.compression.ratio > 3.0) {
      suggestions.push('ğŸ“Š æ•°æ®å‹ç¼©æ•ˆæœè‰¯å¥½ï¼Œå¯ä»¥è€ƒè™‘æé«˜å‹ç¼©çº§åˆ«');
    }
    
    if (stats.cache.hitRate < 0.5) {
      suggestions.push('ğŸ—„ï¸ ç¼“å­˜å‘½ä¸­ç‡è¾ƒä½ï¼Œè€ƒè™‘è°ƒæ•´ç¼“å­˜ç­–ç•¥æˆ–å¤§å°');
    }
    
    if (stats.chunksCount > 1000) {
      suggestions.push('ğŸ“¦ æ•°æ®å—æ•°é‡è¾ƒå¤šï¼Œè€ƒè™‘å¢å¤§å—å¤§å°');
    }
    
    if (this.workers.length === 0 && stats.totalDataSize > 100) {
      suggestions.push('âš¡ æ•°æ®é‡è¾ƒå¤§ï¼Œå»ºè®®å¯ç”¨Web Workerså¹¶è¡Œå¤„ç†');
    }
    
    return suggestions;
  }

  /**
   * æ¸…ç†èµ„æº
   */
  dispose(): void {
    console.log('ğŸ§¹ æ¸…ç†å¤§æ•°æ®å¤„ç†å™¨èµ„æº...');
    
    // æ¸…ç†æ•°æ®å—
    this.chunks.clear();
    
    // æ¸…ç†ç©ºé—´ç´¢å¼•
    if (this.spatialIndex) {
      this.spatialIndex.clear();
    }
    
    // ç»ˆæ­¢Workers
    this.workers.forEach(worker => worker.terminate());
    this.workers.length = 0;
    
    // æ¸…ç†å†…å­˜æ± 
    this.memoryPool.length = 0;
    
    // æ¸…ç†ç¼“å­˜
    this.cache.clear();
    
    console.log('âœ… å¤§æ•°æ®å¤„ç†å™¨èµ„æºæ¸…ç†å®Œæˆ');
  }

  // ç§æœ‰è¾…åŠ©æ–¹æ³•å®ç°

  private mergeConfig(userConfig?: Partial<BigDataConfig>): BigDataConfig {
    const defaultConfig: BigDataConfig = {
      chunking: {
        enabled: true,
        chunkSize: 32, // 32MB
        overlapSize: 0.1,
        adaptiveChunking: true,
        compressionLevel: 3
      },
      memory: {
        maxMemoryUsage: 512, // 512MB
        enableMemoryPool: true,
        garbageCollectionThreshold: 0.8,
        enableStreaming: true,
        bufferSize: 8 // 8MB
      },
      parallel: {
        enableWorkers: true,
        maxWorkers: Math.min(navigator.hardwareConcurrency || 4, 8),
        workerChunkSize: 1000,
        enableSharedArrayBuffer: typeof SharedArrayBuffer !== 'undefined',
        loadBalancing: 'dynamic'
      },
      storage: {
        enableIndexing: true,
        indexType: 'spatial',
        enableCompression: true,
        compressionFormat: 'gzip',
        enableCaching: true,
        cacheStrategy: 'lru'
      },
      mesh: {
        enableLOD: true,
        lodLevels: 4,
        lodThresholds: [1.0, 0.5, 0.25, 0.125],
        enableCulling: true,
        cullingDistance: 1000,
        enableInstancing: false
      }
    };

    return {
      ...defaultConfig,
      ...userConfig,
      chunking: { ...defaultConfig.chunking, ...userConfig?.chunking },
      memory: { ...defaultConfig.memory, ...userConfig?.memory },
      parallel: { ...defaultConfig.parallel, ...userConfig?.parallel },
      storage: { ...defaultConfig.storage, ...userConfig?.storage },
      mesh: { ...defaultConfig.mesh, ...userConfig?.mesh }
    };
  }

  private async initializeWorkers(): Promise<void> {
    const workerCode = `
      self.onmessage = function(e) {
        const { type, data, chunkId } = e.data;
        
        try {
          let result;
          
          switch (type) {
            case 'process_chunk':
              result = processDataChunk(data);
              break;
            case 'compress_data':
              result = compressData(data);
              break;
            default:
              throw new Error('Unknown task type: ' + type);
          }
          
          self.postMessage({
            success: true,
            chunkId: chunkId,
            result: result
          });
          
        } catch (error) {
          self.postMessage({
            success: false,
            chunkId: chunkId,
            error: error.message
          });
        }
      };
      
      function processDataChunk(data) {
        // ç®€åŒ–çš„æ•°æ®å¤„ç†
        const processed = new Float32Array(data.length);
        for (let i = 0; i < data.length; i++) {
          processed[i] = data[i] * 1.1; // ç®€å•å˜æ¢
        }
        return processed;
      }
      
      function compressData(data) {
        // ç®€åŒ–çš„å‹ç¼©ç®—æ³•
        return data; // å®é™…åº”è¯¥å®ç°å‹ç¼©
      }
    `;

    const blob = new Blob([workerCode], { type: 'application/javascript' });
    const workerURL = URL.createObjectURL(blob);

    for (let i = 0; i < this.config.parallel.maxWorkers; i++) {
      const worker = new Worker(workerURL);
      this.workers.push(worker);
    }

    URL.revokeObjectURL(workerURL);
  }

  private initializeMemoryPool(): void {
    const poolSize = 10;
    const bufferSize = this.config.memory.bufferSize * 1024 * 1024;
    
    for (let i = 0; i < poolSize; i++) {
      this.memoryPool.push(new ArrayBuffer(bufferSize));
    }
  }

  private startMemoryMonitoring(): void {
    setInterval(() => {
      this.updateMemoryStats();
      
      if (this.stats.memoryUsage.current > this.config.memory.maxMemoryUsage * this.config.memory.garbageCollectionThreshold) {
        this.performGarbageCollection();
      }
    }, 5000); // æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡
  }

  private createSpatialIndex(type: string): SpatialIndex {
    // ç®€åŒ–çš„ç©ºé—´ç´¢å¼•å®ç°
    const items: Array<{ bounds: number[]; data: any }> = [];
    
    return {
      insert: (bounds: number[], data: any) => {
        items.push({ bounds, data });
      },
      query: (bounds: number[]) => {
        return items.filter(item => this.boundsIntersect(item.bounds, bounds)).map(item => item.data);
      },
      remove: (bounds: number[]) => {
        const index = items.findIndex(item => this.boundsEqual(item.bounds, bounds));
        if (index >= 0) {
          items.splice(index, 1);
          return true;
        }
        return false;
      },
      clear: () => {
        items.length = 0;
      },
      getStats: () => ({
        nodes: items.length,
        depth: 1,
        items: items.length
      })
    };
  }

  private boundsIntersect(bounds1: number[], bounds2: number[]): boolean {
    return !(bounds1[3] < bounds2[0] || bounds1[0] > bounds2[3] ||
             bounds1[4] < bounds2[1] || bounds1[1] > bounds2[4] ||
             bounds1[5] < bounds2[2] || bounds1[2] > bounds2[5]);
  }

  private boundsEqual(bounds1: number[], bounds2: number[]): boolean {
    return bounds1.every((val, index) => Math.abs(val - bounds2[index]) < 1e-6);
  }

  private async processDataChunk(data: Float32Array, chunkId: string): Promise<DataChunk> {
    // ç®€åŒ–çš„æ•°æ®å¤„ç†å®ç°
    const processedData = new Float32Array(data.length);
    for (let i = 0; i < data.length; i++) {
      processedData[i] = data[i] * 1.1; // ç®€å•å˜æ¢
    }
    
    return {
      id: chunkId,
      offset: 0,
      size: processedData.length,
      data: processedData,
      metadata: {
        bounds: [0, 0, 0, 1, 1, 1],
        elementCount: processedData.length,
        dataType: 'scalar',
        compressed: false
      },
      dependencies: []
    };
  }

  private async processChunksSequentially(
    chunks: DataChunk[],
    onProgress?: (progress: number) => void
  ): Promise<DataChunk[]> {
    const processedChunks: DataChunk[] = [];
    
    for (let i = 0; i < chunks.length; i++) {
      const processed = await this.processDataChunk(chunks[i].data as Float32Array, chunks[i].id);
      processedChunks.push(processed);
      
      if (onProgress) {
        onProgress((i + 1) / chunks.length * 100);
      }
    }
    
    return processedChunks;
  }

  private distributeChunksToWorkers(chunks: DataChunk[]): DataChunk[][] {
    const workerChunks: DataChunk[][] = Array.from({ length: this.workers.length }, () => []);
    
    chunks.forEach((chunk, index) => {
      const workerIndex = index % this.workers.length;
      workerChunks[workerIndex].push(chunk);
    });
    
    return workerChunks;
  }

  private async processChunkWithWorker(worker: Worker, chunk: DataChunk): Promise<DataChunk> {
    return new Promise((resolve, reject) => {
      const timeout = setTimeout(() => {
        reject(new Error('Worker timeout'));
      }, 30000);

      worker.onmessage = (e) => {
        clearTimeout(timeout);
        
        if (e.data.success) {
          resolve({
            ...chunk,
            data: e.data.result
          });
        } else {
          reject(new Error(e.data.error));
        }
      };

      worker.postMessage({
        type: 'process_chunk',
        data: chunk.data,
        chunkId: chunk.id
      });
    });
  }

  private analyzeMeshDensity(vertices: Float32Array, faces: Uint32Array): number[] {
    const vertexCount = vertices.length / 3;
    const density = new Array(vertexCount).fill(0);
    
    // è®¡ç®—æ¯ä¸ªé¡¶ç‚¹çš„è¿æ¥æ•°
    for (let i = 0; i < faces.length; i += 3) {
      density[faces[i]]++;
      density[faces[i + 1]]++;
      density[faces[i + 2]]++;
    }
    
    return density;
  }

  private calculateAdaptiveChunkSize(density: number): number {
    // åŸºäºå¯†åº¦åŠ¨æ€è°ƒæ•´å—å¤§å°
    const baseSizeo = 1000;
    const factor = Math.max(0.1, Math.min(2.0, 1.0 / Math.sqrt(density + 1)));
    return Math.floor(baseSizeo * factor);
  }

  private collectNearbyVertices(centerVertex: number, vertices: Float32Array, maxDistance: number): number[] {
    const center = [
      vertices[centerVertex * 3],
      vertices[centerVertex * 3 + 1],
      vertices[centerVertex * 3 + 2]
    ];
    
    const nearby: number[] = [centerVertex];
    const vertexCount = vertices.length / 3;
    
    for (let i = 0; i < vertexCount; i++) {
      if (i === centerVertex) continue;
      
      const distance = Math.sqrt(
        Math.pow(vertices[i * 3] - center[0], 2) +
        Math.pow(vertices[i * 3 + 1] - center[1], 2) +
        Math.pow(vertices[i * 3 + 2] - center[2], 2)
      );
      
      if (distance <= maxDistance) {
        nearby.push(i);
      }
      
      if (nearby.length >= 1000) break; // é™åˆ¶æœ€å¤§å—å¤§å°
    }
    
    return nearby;
  }

  private extractVerticesByIndices(vertices: Float32Array, indices: number[]): Float32Array {
    const result = new Float32Array(indices.length * 3);
    
    for (let i = 0; i < indices.length; i++) {
      const vertexIndex = indices[i];
      result[i * 3] = vertices[vertexIndex * 3];
      result[i * 3 + 1] = vertices[vertexIndex * 3 + 1];
      result[i * 3 + 2] = vertices[vertexIndex * 3 + 2];
    }
    
    return result;
  }

  private extractFacesByVertices(faces: Uint32Array, vertexIndices: number[]): Uint32Array {
    const vertexSet = new Set(vertexIndices);
    const resultFaces: number[] = [];
    
    for (let i = 0; i < faces.length; i += 3) {
      if (vertexSet.has(faces[i]) && vertexSet.has(faces[i + 1]) && vertexSet.has(faces[i + 2])) {
        resultFaces.push(faces[i], faces[i + 1], faces[i + 2]);
      }
    }
    
    return new Uint32Array(resultFaces);
  }

  private extractRelevantFaces(faces: Uint32Array, startVertex: number, endVertex: number): Uint32Array {
    const relevantFaces: number[] = [];
    
    for (let i = 0; i < faces.length; i += 3) {
      const v1 = faces[i];
      const v2 = faces[i + 1];
      const v3 = faces[i + 2];
      
      if ((v1 >= startVertex && v1 < endVertex) ||
          (v2 >= startVertex && v2 < endVertex) ||
          (v3 >= startVertex && v3 < endVertex)) {
        relevantFaces.push(v1, v2, v3);
      }
    }
    
    return new Uint32Array(relevantFaces);
  }

  private combineMeshData(vertices: Float32Array, faces: Uint32Array): Float32Array {
    const combined = new Float32Array(vertices.length + faces.length);
    combined.set(vertices);
    combined.set(Array.from(faces), vertices.length);
    return combined;
  }

  private calculateBounds(vertices: Float32Array): [number, number, number, number, number, number] {
    if (vertices.length === 0) return [0, 0, 0, 0, 0, 0];
    
    let minX = Infinity, minY = Infinity, minZ = Infinity;
    let maxX = -Infinity, maxY = -Infinity, maxZ = -Infinity;
    
    for (let i = 0; i < vertices.length; i += 3) {
      minX = Math.min(minX, vertices[i]);
      maxX = Math.max(maxX, vertices[i]);
      minY = Math.min(minY, vertices[i + 1]);
      maxY = Math.max(maxY, vertices[i + 1]);
      minZ = Math.min(minZ, vertices[i + 2]);
      maxZ = Math.max(maxZ, vertices[i + 2]);
    }
    
    return [minX, minY, minZ, maxX, maxY, maxZ];
  }

  private async compressData(data: Float32Array): Promise<Float32Array> {
    // ç®€åŒ–çš„å‹ç¼©å®ç°
    // å®é™…åº”è¯¥ä½¿ç”¨çœŸæ­£çš„å‹ç¼©ç®—æ³•
    this.stats.compression.originalSize += data.byteLength;
    this.stats.compression.compressedSize += data.byteLength * 0.7; // å‡è®¾70%å‹ç¼©ç‡
    this.stats.compression.ratio = this.stats.compression.originalSize / this.stats.compression.compressedSize;
    
    return data; // è¿”å›åŸæ•°æ®ï¼ˆç®€åŒ–ï¼‰
  }

  private extractEdges(faces: Uint32Array): Array<{ id: string; v1: number; v2: number }> {
    const edges: Array<{ id: string; v1: number; v2: number }> = [];
    const edgeSet = new Set<string>();
    
    for (let i = 0; i < faces.length; i += 3) {
      const edges_in_face = [
        [faces[i], faces[i + 1]],
        [faces[i + 1], faces[i + 2]],
        [faces[i + 2], faces[i]]
      ];
      
      for (const [v1, v2] of edges_in_face) {
        const edgeId = `${Math.min(v1, v2)}_${Math.max(v1, v2)}`;
        if (!edgeSet.has(edgeId)) {
          edgeSet.add(edgeId);
          edges.push({ id: edgeId, v1, v2 });
        }
      }
    }
    
    return edges;
  }

  private calculateEdgeImportance(vertices: Float32Array, edges: Array<{ id: string; v1: number; v2: number }>): Record<string, number> {
    const importance: Record<string, number> = {};
    
    for (const edge of edges) {
      // ç®€åŒ–çš„é‡è¦æ€§è®¡ç®—ï¼šåŸºäºè¾¹é•¿åº¦
      const v1 = [vertices[edge.v1 * 3], vertices[edge.v1 * 3 + 1], vertices[edge.v1 * 3 + 2]];
      const v2 = [vertices[edge.v2 * 3], vertices[edge.v2 * 3 + 1], vertices[edge.v2 * 3 + 2]];
      
      const length = Math.sqrt(
        Math.pow(v2[0] - v1[0], 2) +
        Math.pow(v2[1] - v1[1], 2) +
        Math.pow(v2[2] - v1[2], 2)
      );
      
      importance[edge.id] = length; // çŸ­è¾¹ä¼˜å…ˆåç¼©
    }
    
    return importance;
  }

  private collapseEdge(
    vertices: Float32Array, 
    faces: Uint32Array, 
    edge: { v1: number; v2: number }
  ): { vertices: Float32Array; faces: Uint32Array } | null {
    // ç®€åŒ–çš„è¾¹åç¼©å®ç°
    // å®é™…éœ€è¦æ›´å¤æ‚çš„ç®—æ³•æ¥ä¿æŒç½‘æ ¼è´¨é‡
    return null; // ç®€åŒ–è¿”å›null
  }

  private async performGarbageCollection(): Promise<void> {
    // è§¦å‘åƒåœ¾å›æ”¶çš„å»ºè®®
    if (typeof window !== 'undefined' && 'gc' in window) {
      (window as any).gc();
    }
    
    // æ¸…ç†æ—§çš„ç¼“å­˜é¡¹
    const now = Date.now();
    const expiredKeys: string[] = [];
    
    for (const [key, item] of this.cache) {
      if (now - item.timestamp > 300000) { // 5åˆ†é’Ÿè¿‡æœŸ
        expiredKeys.push(key);
      }
    }
    
    expiredKeys.forEach(key => this.cache.delete(key));
  }

  private cleanupCache(): void {
    if (this.cache.size > 100) {
      // LRUç­–ç•¥æ¸…ç†
      const entries = Array.from(this.cache.entries())
        .sort((a, b) => a[1].timestamp - b[1].timestamp);
      
      const toRemove = entries.slice(0, this.cache.size - 50);
      toRemove.forEach(([key]) => this.cache.delete(key));
    }
  }

  private defragmentMemoryPool(): void {
    // ç®€åŒ–çš„å†…å­˜æ± æ•´ç†
    console.log('ğŸ”§ æ•´ç†å†…å­˜æ± ...');
  }

  private updateMemoryStats(): void {
    // ä¼°ç®—å†…å­˜ä½¿ç”¨ï¼ˆç®€åŒ–å®ç°ï¼‰
    let current = 0;
    
    // æ•°æ®å—å†…å­˜
    for (const chunk of this.chunks.values()) {
      current += chunk.data.byteLength / 1024 / 1024;
    }
    
    // ç¼“å­˜å†…å­˜
    for (const [, item] of this.cache) {
      if (item.data && item.data.byteLength) {
        current += item.data.byteLength / 1024 / 1024;
      }
    }
    
    this.stats.memoryUsage.current = current;
    this.stats.memoryUsage.peak = Math.max(this.stats.memoryUsage.peak, current);
    
    // ä¼°ç®—å¯ç”¨å†…å­˜
    if ('memory' in performance) {
      const perfMemory = (performance as any).memory;
      this.stats.memoryUsage.available = perfMemory.jsHeapSizeLimit / 1024 / 1024 - current;
    }
  }

  private updateCacheStats(): void {
    this.stats.cache.hitRate = this.stats.cache.hits / (this.stats.cache.hits + this.stats.cache.misses);
  }
}

// å¯¼å‡ºä¾¿æ·å‡½æ•°
export function createBigDataProcessor(config?: Partial<BigDataConfig>): BigDataProcessor {
  return new BigDataProcessor(config);
}

// æµå¼æ•°æ®å¤„ç†ä¾¿æ·å‡½æ•°
export async function processLargeDataset(
  data: Float32Array,
  config?: Partial<BigDataConfig>
): Promise<{
  success: boolean;
  chunks: DataChunk[];
  stats: BigDataStats;
}> {
  
  const processor = createBigDataProcessor(config);
  
  try {
    // æ¨¡æ‹Ÿå¤§ç½‘æ ¼æ•°æ®
    const vertices = data;
    const faces = new Uint32Array(Math.floor(data.length / 9) * 3); // å‡è®¾æ¯3ä¸ªé¡¶ç‚¹æ„æˆä¸€ä¸ªé¢
    
    const result = await processor.processLargeMesh(vertices, faces);
    
    return {
      success: result.success,
      chunks: result.processedChunks,
      stats: result.stats
    };
    
  } finally {
    processor.dispose();
  }
}

console.log('ğŸ“Š å¤§æ•°æ®å¤„ç†ä¼˜åŒ–æ¨¡å—å·²å°±ç»ª - æ”¯æŒåˆ†å—ã€å¹¶è¡Œã€LODã€ç©ºé—´ç´¢å¼•');
"""
GemPyå·¥ä½œæµç®¡ç†å™¨ - å®Œæ•´çš„åœ°è´¨å»ºæ¨¡å·¥ä½œæµ
GemPy Workflow Manager - Complete geological modeling workflow
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from typing import Dict, List, Tuple, Optional, Any
import json
import os
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

try:
    import gempy as gp
    import gempy_viewer as gpv
    GEMPY_AVAILABLE = True
except ImportError:
    GEMPY_AVAILABLE = False
    print("Warning: GemPy not available")

try:
    import pyvista as pv
    PYVISTA_AVAILABLE = True
except ImportError:
    PYVISTA_AVAILABLE = False

class GemPyWorkflowManager:
    """GemPyå®Œæ•´å·¥ä½œæµç®¡ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–å·¥ä½œæµç®¡ç†å™¨"""
        self.current_project = None
        self.geo_model = None
        self.solution = None
        self.workflow_history = []
        self.data_registry = {
            'surface_points': pd.DataFrame(),
            'orientations': pd.DataFrame(),
            'boreholes': pd.DataFrame(),
            'geological_maps': {},
            'geophysical_data': {}
        }
        
    def create_new_project(self, project_name: str, model_extent: List[float], 
                          resolution: List[int]) -> bool:
        """
        åˆ›å»ºæ–°çš„GemPyé¡¹ç›®
        
        Args:
            project_name: é¡¹ç›®åç§°
            model_extent: æ¨¡å‹èŒƒå›´ [xmin, xmax, ymin, ymax, zmin, zmax]
            resolution: ç½‘æ ¼åˆ†è¾¨ç‡ [nx, ny, nz]
        """
        try:
            if not GEMPY_AVAILABLE:
                print("âŒ GemPyä¸å¯ç”¨ï¼Œæ— æ³•åˆ›å»ºé¡¹ç›®")
                return False
                
            print(f"ğŸš€ åˆ›å»ºæ–°é¡¹ç›®: {project_name}")
            
            # åˆ›å»ºGemPyæ¨¡å‹
            self.geo_model = gp.create_geomodel(
                project_name=project_name,
                extent=model_extent,
                resolution=resolution,
                refinement=1
            )
            
            # è®¾ç½®é¡¹ç›®ä¿¡æ¯
            self.current_project = {
                'name': project_name,
                'extent': model_extent,
                'resolution': resolution,
                'created_time': pd.Timestamp.now(),
                'model_state': 'initialized'
            }
            
            # è®°å½•å·¥ä½œæµæ­¥éª¤
            self._log_workflow_step('project_created', {
                'project_name': project_name,
                'extent': model_extent,
                'resolution': resolution
            })
            
            print(f"âœ… é¡¹ç›® '{project_name}' åˆ›å»ºæˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"âŒ é¡¹ç›®åˆ›å»ºå¤±è´¥: {str(e)}")
            return False
    
    def import_surface_points(self, file_path: str, format_type: str = 'csv') -> bool:
        """
        å¯¼å…¥åœ°å±‚æ¥è§¦ç‚¹æ•°æ®
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            format_type: æ–‡ä»¶æ ¼å¼ ('csv', 'excel', 'shp')
        """
        try:
            print(f"ğŸ“¥ å¯¼å…¥åœ°å±‚æ¥è§¦ç‚¹æ•°æ®: {file_path}")
            
            if format_type == 'csv':
                surface_points = pd.read_csv(file_path)
            elif format_type == 'excel':
                surface_points = pd.read_excel(file_path)
            else:
                print(f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {format_type}")
                return False
            
            # éªŒè¯æ•°æ®æ ¼å¼
            required_cols = ['X', 'Y', 'Z', 'formation']
            if not all(col in surface_points.columns for col in required_cols):
                print(f"âŒ æ•°æ®æ ¼å¼é”™è¯¯ï¼Œéœ€è¦åŒ…å«åˆ—: {required_cols}")
                return False
            
            # æ•°æ®è´¨é‡æ£€æŸ¥
            surface_points = self._validate_surface_points(surface_points)
            
            if surface_points is not None:
                self.data_registry['surface_points'] = surface_points
                print(f"âœ… æˆåŠŸå¯¼å…¥ {len(surface_points)} ä¸ªåœ°å±‚æ¥è§¦ç‚¹")
                
                # è®°å½•å·¥ä½œæµ
                self._log_workflow_step('surface_points_imported', {
                    'file_path': file_path,
                    'format': format_type,
                    'points_count': len(surface_points)
                })
                
                return True
            else:
                return False
                
        except Exception as e:
            print(f"âŒ åœ°å±‚æ¥è§¦ç‚¹å¯¼å…¥å¤±è´¥: {str(e)}")
            return False
    
    def import_orientations(self, file_path: str, format_type: str = 'csv') -> bool:
        """
        å¯¼å…¥åœ°å±‚æ–¹å‘æ•°æ®
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            format_type: æ–‡ä»¶æ ¼å¼
        """
        try:
            print(f"ğŸ“¥ å¯¼å…¥åœ°å±‚æ–¹å‘æ•°æ®: {file_path}")
            
            if format_type == 'csv':
                orientations = pd.read_csv(file_path)
            elif format_type == 'excel':
                orientations = pd.read_excel(file_path)
            else:
                print(f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {format_type}")
                return False
            
            # éªŒè¯æ•°æ®æ ¼å¼
            required_cols = ['X', 'Y', 'Z', 'formation', 'azimuth', 'dip', 'polarity']
            if not all(col in orientations.columns for col in required_cols):
                print(f"âŒ æ•°æ®æ ¼å¼é”™è¯¯ï¼Œéœ€è¦åŒ…å«åˆ—: {required_cols}")
                return False
            
            # æ•°æ®è´¨é‡æ£€æŸ¥
            orientations = self._validate_orientations(orientations)
            
            if orientations is not None:
                self.data_registry['orientations'] = orientations
                print(f"âœ… æˆåŠŸå¯¼å…¥ {len(orientations)} ä¸ªæ–¹å‘æµ‹é‡ç‚¹")
                
                # è®°å½•å·¥ä½œæµ
                self._log_workflow_step('orientations_imported', {
                    'file_path': file_path,
                    'format': format_type,
                    'orientations_count': len(orientations)
                })
                
                return True
            else:
                return False
                
        except Exception as e:
            print(f"âŒ åœ°å±‚æ–¹å‘æ•°æ®å¯¼å…¥å¤±è´¥: {str(e)}")
            return False
    
    def setup_geological_model(self, stratigraphy_config: Dict[str, List[str]], 
                             fault_config: Optional[Dict] = None) -> bool:
        """
        è®¾ç½®åœ°è´¨æ¨¡å‹ç»“æ„
        
        Args:
            stratigraphy_config: åœ°å±‚åºåˆ—é…ç½®
            fault_config: æ–­å±‚é…ç½®ï¼ˆå¯é€‰ï¼‰
        """
        try:
            if not GEMPY_AVAILABLE or self.geo_model is None:
                print("âŒ GemPyæ¨¡å‹æœªåˆå§‹åŒ–")
                return False
                
            print("ğŸ—ï¸ è®¾ç½®åœ°è´¨æ¨¡å‹ç»“æ„...")
            
            # æ·»åŠ åœ°å±‚åºåˆ—
            gp.map_stack_to_surfaces(
                self.geo_model,
                stratigraphy_config
            )
            
            # è®¾ç½®æ–­å±‚ï¼ˆå¦‚æœæä¾›ï¼‰
            if fault_config:
                fault_series = [series for series in stratigraphy_config.keys() 
                               if 'fault' in series.lower()]
                if fault_series:
                    self.geo_model.set_is_fault(fault_series, True)
            
            # æ·»åŠ æ•°æ®åˆ°æ¨¡å‹
            surface_points = self.data_registry['surface_points']
            orientations = self.data_registry['orientations']
            
            if not surface_points.empty:
                gp.add_surface_points(
                    self.geo_model,
                    x=surface_points['X'],
                    y=surface_points['Y'],
                    z=surface_points['Z'],
                    surface=surface_points['formation']
                )
            
            if not orientations.empty:
                gp.add_orientations(
                    self.geo_model,
                    x=orientations['X'],
                    y=orientations['Y'],
                    z=orientations['Z'],
                    surface=orientations['formation'],
                    orientation=orientations[['azimuth', 'dip']].values
                )
            
            print("âœ… åœ°è´¨æ¨¡å‹ç»“æ„è®¾ç½®å®Œæˆ")
            
            # æ›´æ–°é¡¹ç›®çŠ¶æ€
            self.current_project['model_state'] = 'configured'
            
            # è®°å½•å·¥ä½œæµ
            self._log_workflow_step('model_configured', {
                'stratigraphy': stratigraphy_config,
                'faults': fault_config is not None
            })
            
            return True
            
        except Exception as e:
            print(f"âŒ åœ°è´¨æ¨¡å‹è®¾ç½®å¤±è´¥: {str(e)}")
            return False
    
    def compute_geological_model(self, compile_theano: bool = True) -> bool:
        """
        è®¡ç®—åœ°è´¨æ¨¡å‹
        
        Args:
            compile_theano: æ˜¯å¦ç¼–è¯‘Theanoï¼ˆé¦–æ¬¡è®¡ç®—æ—¶éœ€è¦ï¼‰
        """
        try:
            if not GEMPY_AVAILABLE or self.geo_model is None:
                print("âŒ GemPyæ¨¡å‹æœªåˆå§‹åŒ–")
                return False
                
            print("âš¡ å¼€å§‹è®¡ç®—åœ°è´¨æ¨¡å‹...")
            
            # è®¾ç½®æ’å€¼å™¨
            if compile_theano:
                print("  ğŸ”§ ç¼–è¯‘æ’å€¼å™¨...")
                gp.set_interpolator(self.geo_model)
            
            # è®¡ç®—æ¨¡å‹
            print("  ğŸ”„ æ‰§è¡Œéšå¼å»ºæ¨¡è®¡ç®—...")
            self.solution = gp.compute_model(
                self.geo_model, 
                compute_mesh=True
            )
            
            # éªŒè¯è®¡ç®—ç»“æœ
            if self.solution is not None:
                print("âœ… åœ°è´¨æ¨¡å‹è®¡ç®—æˆåŠŸ")
                
                # æ›´æ–°é¡¹ç›®çŠ¶æ€
                self.current_project['model_state'] = 'computed'
                
                # è®°å½•å·¥ä½œæµ
                self._log_workflow_step('model_computed', {
                    'compile_theano': compile_theano,
                    'success': True
                })
                
                # è¾“å‡ºåŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
                self._print_model_statistics()
                
                return True
            else:
                print("âŒ æ¨¡å‹è®¡ç®—ç»“æœä¸ºç©º")
                return False
                
        except Exception as e:
            print(f"âŒ åœ°è´¨æ¨¡å‹è®¡ç®—å¤±è´¥: {str(e)}")
            
            # è®°å½•å¤±è´¥
            self._log_workflow_step('model_computed', {
                'compile_theano': compile_theano,
                'success': False,
                'error': str(e)
            })
            
            return False
    
    def extract_model_sections(self, section_coords: Dict[str, List]) -> Dict[str, np.ndarray]:
        """
        æå–æ¨¡å‹å‰–é¢
        
        Args:
            section_coords: å‰–é¢åæ ‡å­—å…¸ï¼Œå¦‚ {'XY': [z_value], 'XZ': [y_value], 'YZ': [x_value]}
        """
        try:
            if self.solution is None:
                print("âŒ æ¨¡å‹æœªè®¡ç®—ï¼Œæ— æ³•æå–å‰–é¢")
                return {}
                
            print("ğŸ“Š æå–æ¨¡å‹å‰–é¢æ•°æ®...")
            
            sections = {}
            
            # è·å–æ¨¡å‹ç½‘æ ¼
            lith_block = self.solution.lith_block
            grid_shape = self.geo_model.grid.regular_grid.resolution
            
            # XYå‰–é¢ï¼ˆæ°´å¹³åˆ‡ç‰‡ï¼‰
            if 'XY' in section_coords:
                for z_idx in section_coords['XY']:
                    section_name = f'XY_z{z_idx}'
                    if 0 <= z_idx < grid_shape[2]:
                        xy_section = lith_block.reshape(grid_shape)[:, :, z_idx]
                        sections[section_name] = xy_section
            
            # XZå‰–é¢ï¼ˆå—åŒ—å‘åˆ‡ç‰‡ï¼‰
            if 'XZ' in section_coords:
                for y_idx in section_coords['XZ']:
                    section_name = f'XZ_y{y_idx}'
                    if 0 <= y_idx < grid_shape[1]:
                        xz_section = lith_block.reshape(grid_shape)[:, y_idx, :]
                        sections[section_name] = xz_section
            
            # YZå‰–é¢ï¼ˆä¸œè¥¿å‘åˆ‡ç‰‡ï¼‰
            if 'YZ' in section_coords:
                for x_idx in section_coords['YZ']:
                    section_name = f'YZ_x{x_idx}'
                    if 0 <= x_idx < grid_shape[0]:
                        yz_section = lith_block.reshape(grid_shape)[x_idx, :, :]
                        sections[section_name] = yz_section
            
            print(f"âœ… æˆåŠŸæå– {len(sections)} ä¸ªå‰–é¢")
            return sections
            
        except Exception as e:
            print(f"âŒ å‰–é¢æå–å¤±è´¥: {str(e)}")
            return {}
    
    def export_model_results(self, output_dir: str, formats: List[str] = ['vtk', 'csv']) -> bool:
        """
        å¯¼å‡ºæ¨¡å‹ç»“æœ
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
            formats: å¯¼å‡ºæ ¼å¼åˆ—è¡¨
        """
        try:
            if self.solution is None:
                print("âŒ æ¨¡å‹æœªè®¡ç®—ï¼Œæ— æ³•å¯¼å‡º")
                return False
                
            print(f"ğŸ“¤ å¯¼å‡ºæ¨¡å‹ç»“æœåˆ°: {output_dir}")
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_path = Path(output_dir)
            output_path.mkdir(parents=True, exist_ok=True)
            
            success_count = 0
            
            # å¯¼å‡ºVTKæ ¼å¼
            if 'vtk' in formats and PYVISTA_AVAILABLE:
                try:
                    vtk_path = output_path / 'geological_model.vtk'
                    # è¿™é‡Œéœ€è¦å®ç°VTKå¯¼å‡ºé€»è¾‘
                    print(f"  âœ… VTKæ ¼å¼å¯¼å‡º: {vtk_path}")
                    success_count += 1
                except Exception as e:
                    print(f"  âŒ VTKå¯¼å‡ºå¤±è´¥: {e}")
            
            # å¯¼å‡ºCSVæ ¼å¼
            if 'csv' in formats:
                try:
                    # å¯¼å‡ºå²©æ€§å—æ•°æ®
                    lith_df = pd.DataFrame({
                        'lithology_id': self.solution.lith_block.flatten()
                    })
                    csv_path = output_path / 'lithology_block.csv'
                    lith_df.to_csv(csv_path, index=False)
                    print(f"  âœ… CSVæ ¼å¼å¯¼å‡º: {csv_path}")
                    success_count += 1
                except Exception as e:
                    print(f"  âŒ CSVå¯¼å‡ºå¤±è´¥: {e}")
            
            # å¯¼å‡ºé¡¹ç›®ä¿¡æ¯
            project_info = {
                'project': self.current_project,
                'workflow_history': self.workflow_history
            }
            
            info_path = output_path / 'project_info.json'
            with open(info_path, 'w', encoding='utf-8') as f:
                json.dump(project_info, f, indent=2, default=str)
            print(f"  âœ… é¡¹ç›®ä¿¡æ¯å¯¼å‡º: {info_path}")
            
            print(f"âœ… å¯¼å‡ºå®Œæˆï¼ŒæˆåŠŸå¯¼å‡º {success_count} ç§æ ¼å¼")
            return success_count > 0
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹å¯¼å‡ºå¤±è´¥: {str(e)}")
            return False
    
    def _validate_surface_points(self, data: pd.DataFrame) -> Optional[pd.DataFrame]:
        """éªŒè¯åœ°å±‚æ¥è§¦ç‚¹æ•°æ®è´¨é‡"""
        try:
            # æ£€æŸ¥ç©ºå€¼
            if data.isnull().any().any():
                print("âš ï¸ æ•°æ®åŒ…å«ç©ºå€¼ï¼Œæ­£åœ¨æ¸…ç†...")
                data = data.dropna()
            
            # æ£€æŸ¥åæ ‡èŒƒå›´
            if self.current_project:
                extent = self.current_project['extent']
                
                # è¿‡æ»¤è¶…å‡ºèŒƒå›´çš„ç‚¹
                valid_mask = (
                    (data['X'] >= extent[0]) & (data['X'] <= extent[1]) &
                    (data['Y'] >= extent[2]) & (data['Y'] <= extent[3]) &
                    (data['Z'] >= extent[4]) & (data['Z'] <= extent[5])
                )
                
                if not valid_mask.all():
                    print(f"âš ï¸ å‘ç° {(~valid_mask).sum()} ä¸ªè¶…å‡ºæ¨¡å‹èŒƒå›´çš„ç‚¹ï¼Œå·²è¿‡æ»¤")
                    data = data[valid_mask]
            
            # æ£€æŸ¥åœ°å±‚åç§°
            formations = data['formation'].unique()
            print(f"ğŸ“‹ å‘ç°åœ°å±‚: {list(formations)}")
            
            return data
            
        except Exception as e:
            print(f"âŒ åœ°å±‚æ¥è§¦ç‚¹æ•°æ®éªŒè¯å¤±è´¥: {str(e)}")
            return None
    
    def _validate_orientations(self, data: pd.DataFrame) -> Optional[pd.DataFrame]:
        """éªŒè¯åœ°å±‚æ–¹å‘æ•°æ®è´¨é‡"""
        try:
            # æ£€æŸ¥ç©ºå€¼
            if data.isnull().any().any():
                print("âš ï¸ æ–¹å‘æ•°æ®åŒ…å«ç©ºå€¼ï¼Œæ­£åœ¨æ¸…ç†...")
                data = data.dropna()
            
            # æ£€æŸ¥è§’åº¦èŒƒå›´
            invalid_azimuth = (data['azimuth'] < 0) | (data['azimuth'] > 360)
            invalid_dip = (data['dip'] < 0) | (data['dip'] > 90)
            
            if invalid_azimuth.any():
                print(f"âš ï¸ å‘ç° {invalid_azimuth.sum()} ä¸ªæ— æ•ˆæ–¹ä½è§’ï¼Œå·²ä¿®æ­£")
                data.loc[invalid_azimuth, 'azimuth'] = data.loc[invalid_azimuth, 'azimuth'] % 360
            
            if invalid_dip.any():
                print(f"âš ï¸ å‘ç° {invalid_dip.sum()} ä¸ªæ— æ•ˆå€¾è§’ï¼Œå·²è¿‡æ»¤")
                data = data[~invalid_dip]
            
            # è®¾ç½®ææ€§ï¼ˆå¦‚æœæœªæä¾›ï¼‰
            if 'polarity' not in data.columns:
                data['polarity'] = 1
            
            return data
            
        except Exception as e:
            print(f"âŒ æ–¹å‘æ•°æ®éªŒè¯å¤±è´¥: {str(e)}")
            return None
    
    def _print_model_statistics(self):
        """æ‰“å°æ¨¡å‹ç»Ÿè®¡ä¿¡æ¯"""
        try:
            if self.solution is None:
                return
                
            lith_block = self.solution.lith_block
            unique_ids, counts = np.unique(lith_block, return_counts=True)
            
            print("\nğŸ“Š æ¨¡å‹ç»Ÿè®¡ä¿¡æ¯:")
            print(f"  ç½‘æ ¼å•å…ƒæ€»æ•°: {len(lith_block):,}")
            print(f"  å²©æ€§å•å…ƒæ•°é‡: {len(unique_ids)}")
            
            for lith_id, count in zip(unique_ids, counts):
                percentage = (count / len(lith_block)) * 100
                print(f"    å²©æ€§ {int(lith_id)}: {count:,} å•å…ƒ ({percentage:.1f}%)")
            
        except Exception as e:
            print(f"âŒ ç»Ÿè®¡ä¿¡æ¯ç”Ÿæˆå¤±è´¥: {str(e)}")
    
    def _log_workflow_step(self, step_name: str, details: Dict[str, Any]):
        """è®°å½•å·¥ä½œæµæ­¥éª¤"""
        step = {
            'step': step_name,
            'timestamp': pd.Timestamp.now(),
            'details': details
        }
        self.workflow_history.append(step)
    
    def get_workflow_summary(self) -> str:
        """è·å–å·¥ä½œæµæ‘˜è¦"""
        if not self.workflow_history:
            return "æš‚æ— å·¥ä½œæµè®°å½•"
        
        summary = f"ğŸ”„ å·¥ä½œæµæ‘˜è¦ (å…± {len(self.workflow_history)} æ­¥):\n"
        
        for i, step in enumerate(self.workflow_history, 1):
            timestamp = step['timestamp'].strftime('%H:%M:%S')
            summary += f"  {i}. [{timestamp}] {step['step']}\n"
        
        return summary

# å·¥ä½œæµå¿«æ·åŠŸèƒ½
class GemPyQuickWorkflow:
    """GemPyå¿«æ·å·¥ä½œæµ"""
    
    @staticmethod
    def create_tutorial_model() -> GemPyWorkflowManager:
        """åˆ›å»ºæ•™ç¨‹ç¤ºä¾‹æ¨¡å‹"""
        print("ğŸ“ åˆ›å»ºGemPyæ•™ç¨‹ç¤ºä¾‹æ¨¡å‹...")
        
        manager = GemPyWorkflowManager()
        
        # åˆ›å»ºé¡¹ç›®
        extent = [0, 2000, 0, 2000, 0, 1000]
        resolution = [50, 50, 50]
        
        if manager.create_new_project("Tutorial_Model", extent, resolution):
            # åˆ›å»ºç¤ºä¾‹æ•°æ®
            surface_points = pd.DataFrame({
                'X': [250, 750, 1250, 1750, 500, 1000, 1500],
                'Y': [1000, 1000, 1000, 1000, 500, 500, 500],
                'Z': [800, 600, 400, 200, 900, 700, 500],
                'formation': ['Layer_1', 'Layer_1', 'Layer_2', 'Layer_2', 'Layer_3', 'Layer_3', 'Basement']
            })
            
            orientations = pd.DataFrame({
                'X': [1000, 1000, 1000],
                'Y': [1000, 1000, 1000],
                'Z': [600, 400, 200],
                'formation': ['Layer_1', 'Layer_2', 'Layer_3'],
                'azimuth': [90, 90, 90],
                'dip': [15, 15, 15],
                'polarity': [1, 1, 1]
            })
            
            # è®¾ç½®æ•°æ®
            manager.data_registry['surface_points'] = surface_points
            manager.data_registry['orientations'] = orientations
            
            # é…ç½®åœ°å±‚åºåˆ—
            stratigraphy = {
                'Strata_Series': ['Layer_1', 'Layer_2', 'Layer_3', 'Basement']
            }
            
            if manager.setup_geological_model(stratigraphy):
                print("âœ… æ•™ç¨‹æ¨¡å‹åˆ›å»ºæˆåŠŸï¼Œå¯ä»¥å¼€å§‹è®¡ç®—")
                return manager
        
        return None

if __name__ == "__main__":
    # æµ‹è¯•å·¥ä½œæµç®¡ç†å™¨
    print("=== GemPyå·¥ä½œæµç®¡ç†å™¨æµ‹è¯• ===")
    
    # åˆ›å»ºæ•™ç¨‹æ¨¡å‹
    manager = GemPyQuickWorkflow.create_tutorial_model()
    
    if manager and GEMPY_AVAILABLE:
        # è®¡ç®—æ¨¡å‹
        if manager.compute_geological_model():
            # æå–å‰–é¢
            sections = manager.extract_model_sections({
                'XY': [25],  # ä¸­é—´å±‚æ°´å¹³åˆ‡ç‰‡
                'XZ': [25],  # ä¸­é—´çº¿å—åŒ—å‘åˆ‡ç‰‡
            })
            
            print(f"æå–åˆ° {len(sections)} ä¸ªå‰–é¢")
            
            # æ˜¾ç¤ºå·¥ä½œæµæ‘˜è¦
            print("\n" + manager.get_workflow_summary())
    
    print("=== æµ‹è¯•å®Œæˆ ===")